import streamlit as st
import pandas as pd
import altair as alt
import io
import re
from collections import Counter

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="WOS Multi-File Merger | SCIMAT Edition",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# --- ì²¨ë¶€íŒŒì¼ ìŠ¤íƒ€ì¼ ì™„ì „ ë³µì œ CSS ---
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@300;400;500;600;700&display=swap');
    
    .stApp {
        background: #f5f7fa;
        font-family: 'Noto Sans KR', sans-serif;
    }
    
    /* ë©”ì¸ ì›°ì»´ ì¹´ë“œ - ì²¨ë¶€íŒŒì¼ ì™„ì „ ë³µì œ */
    .main-welcome-card {
        background: linear-gradient(135deg, #4a90e2 0%, #357abd 100%);
        border-radius: 24px;
        padding: 48px 40px;
        color: white;
        margin-bottom: 32px;
        position: relative;
        overflow: hidden;
        box-shadow: 0 16px 40px rgba(74, 144, 226, 0.3);
    }
    
    .main-welcome-card::before {
        content: '';
        position: absolute;
        top: -30%;
        right: -5%;
        width: 150px;
        height: 150px;
        background: rgba(255, 255, 255, 0.15);
        border-radius: 50%;
        z-index: 1;
    }
    
    .welcome-title {
        font-size: 2.8rem;
        font-weight: 700;
        margin-bottom: 8px;
        z-index: 2;
        position: relative;
        line-height: 1.2;
    }
    
    .welcome-subtitle {
        font-size: 1.4rem;
        font-weight: 400;
        opacity: 0.9;
        margin-bottom: 24px;
        z-index: 2;
        position: relative;
    }
    
    .card-link {
        background: rgba(255, 255, 255, 0.2);
        border-radius: 12px;
        padding: 12px 20px;
        display: inline-block;
        font-weight: 600;
        font-size: 1rem;
        z-index: 2;
        position: relative;
        cursor: pointer;
        transition: all 0.3s ease;
    }
    
    .card-link:hover {
        background: rgba(255, 255, 255, 0.3);
    }
    
    .card-icon {
        position: absolute;
        top: 40px;
        right: 40px;
        width: 80px;
        height: 50px;
        background: rgba(255, 255, 255, 0.2);
        border-radius: 12px;
        display: flex;
        align-items: center;
        justify-content: center;
        font-size: 1.5rem;
        z-index: 2;
    }
    
    /* ê²°ì œì˜ˆì •ê¸ˆì•¡ ìŠ¤íƒ€ì¼ ë©”íŠ¸ë¦­ ì¹´ë“œ */
    .payment-style-grid {
        display: grid;
        grid-template-columns: 2fr 1fr;
        gap: 24px;
        margin: 32px 0;
    }
    
    .payment-card {
        background: white;
        border-radius: 20px;
        padding: 32px;
        box-shadow: 0 4px 20px rgba(0, 0, 0, 0.08);
        border: 1px solid #e8ecf1;
    }
    
    .payment-title {
        font-size: 1.3rem;
        font-weight: 600;
        color: #2c3e50;
        margin-bottom: 24px;
        border-bottom: 2px solid #f1f3f5;
        padding-bottom: 12px;
    }
    
    .payment-item {
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 18px 0;
        border-bottom: 1px solid #f8f9fa;
    }
    
    .payment-item:last-child {
        border-bottom: none;
    }
    
    .payment-label {
        font-size: 1rem;
        color: #6c757d;
        font-weight: 400;
        line-height: 1.4;
    }
    
    .payment-value {
        font-size: 1.4rem;
        font-weight: 700;
        color: #2c3e50;
    }
    
    .payment-value.large {
        font-size: 1.8rem;
        color: #4a90e2;
    }
    
    /* ìƒíƒœ ì¹´ë“œë“¤ - 3ê°œ ê·¸ë¦¬ë“œ */
    .status-grid {
        display: grid;
        grid-template-columns: repeat(3, 1fr);
        gap: 16px;
        margin: 24px 0;
    }
    
    .status-card {
        background: white;
        border-radius: 16px;
        padding: 24px 20px;
        text-align: center;
        box-shadow: 0 4px 16px rgba(0, 0, 0, 0.06);
        border: 1px solid #e8ecf1;
        transition: all 0.3s ease;
    }
    
    .status-card:hover {
        transform: translateY(-4px);
        box-shadow: 0 8px 24px rgba(0, 0, 0, 0.12);
    }
    
    .status-icon {
        font-size: 2.5rem;
        margin-bottom: 12px;
        display: block;
    }
    
    .status-title {
        font-size: 1.1rem;
        font-weight: 600;
        color: #2c3e50;
        margin-bottom: 8px;
    }
    
    .status-desc {
        font-size: 0.9rem;
        color: #6c757d;
        line-height: 1.4;
    }
    
    /* ì„¹ì…˜ í—¤ë” */
    .section-header {
        background: white;
        border-radius: 16px;
        padding: 24px 32px;
        margin: 32px 0 16px 0;
        box-shadow: 0 2px 12px rgba(0, 0, 0, 0.06);
        border-left: 4px solid #4a90e2;
    }
    
    .section-title {
        font-size: 1.4rem;
        font-weight: 600;
        color: #2c3e50;
        margin: 0;
    }
    
    .section-subtitle {
        font-size: 1rem;
        color: #6c757d;
        margin: 8px 0 0 0;
        font-weight: 400;
    }
    
    /* ì°¨íŠ¸ ì»¨í…Œì´ë„ˆ */
    .chart-container {
        background: white;
        border-radius: 20px;
        padding: 32px;
        margin: 24px 0;
        box-shadow: 0 4px 20px rgba(0, 0, 0, 0.08);
        border: 1px solid #e8ecf1;
    }
    
    .chart-title {
        font-size: 1.3rem;
        font-weight: 600;
        color: #2c3e50;
        margin-bottom: 24px;
        padding-bottom: 12px;
        border-bottom: 2px solid #f1f3f5;
    }
    
    /* ê²°ê³¼ íŒ¨ë„ */
    .result-panel {
        background: #f8fffe;
        border: 1px solid #d4edda;
        border-radius: 16px;
        padding: 24px;
        margin: 24px 0;
        border-left: 4px solid #28a745;
    }
    
    .result-title {
        font-size: 1.2rem;
        font-weight: 600;
        color: #155724;
        margin-bottom: 16px;
    }
    
    .result-content {
        color: #155724;
        line-height: 1.6;
    }
    
    /* ë‹¤ìš´ë¡œë“œ ì„¹ì…˜ */
    .download-section {
        background: linear-gradient(135deg, #4a90e2 0%, #357abd 100%);
        border-radius: 20px;
        padding: 32px;
        text-align: center;
        color: white;
        margin: 32px 0;
    }
    
    .download-title {
        font-size: 1.4rem;
        font-weight: 600;
        margin-bottom: 12px;
    }
    
    .download-desc {
        font-size: 1rem;
        opacity: 0.9;
        margin-bottom: 24px;
    }
    
    /* ìµœê·¼ ì´ìš©ë‚´ì—­ ìŠ¤íƒ€ì¼ */
    .recent-usage-grid {
        display: grid;
        grid-template-columns: 1fr 1fr;
        gap: 24px;
        margin: 32px 0;
    }
    
    .usage-card {
        background: white;
        border-radius: 20px;
        padding: 32px;
        box-shadow: 0 4px 20px rgba(0, 0, 0, 0.08);
        border: 1px solid #e8ecf1;
    }
    
    .usage-title {
        font-size: 1.3rem;
        font-weight: 600;
        color: #2c3e50;
        margin-bottom: 24px;
        border-bottom: 2px solid #f1f3f5;
        padding-bottom: 12px;
    }
    
    .usage-item {
        display: flex;
        justify-content: space-between;
        align-items: center;
        padding: 16px 0;
    }
    
    .usage-detail {
        display: flex;
        flex-direction: column;
    }
    
    .usage-name {
        font-weight: 600;
        color: #2c3e50;
        margin-bottom: 4px;
        font-size: 1rem;
    }
    
    .usage-date {
        font-size: 0.9rem;
        color: #6c757d;
    }
    
    .usage-amount {
        font-size: 1.4rem;
        font-weight: 700;
        color: #2c3e50;
    }
    
    /* ë³´ë„ˆìŠ¤ í¬ì¸íŠ¸ ìŠ¤íƒ€ì¼ */
    .bonus-center {
        text-align: center;
        padding: 32px 0;
    }
    
    .bonus-points {
        font-size: 2.5rem;
        font-weight: 700;
        color: #4a90e2;
        margin-bottom: 8px;
    }
    
    .bonus-buttons {
        display: flex;
        justify-content: space-around;
        margin-top: 24px;
    }
    
    .bonus-button {
        background: #f8f9fa;
        border-radius: 8px;
        padding: 12px 16px;
        text-align: center;
        font-size: 0.9rem;
        color: #6c757d;
        cursor: pointer;
        transition: all 0.3s ease;
    }
    
    .bonus-button:hover {
        background: #e9ecef;
    }
    
    /* ì„œë¹„ìŠ¤ ê·¸ë¦¬ë“œ */
    .service-grid {
        display: grid;
        grid-template-columns: repeat(2, 1fr);
        gap: 16px;
        margin: 24px 0;
    }
    
    .service-item {
        display: flex;
        align-items: center;
        padding: 12px 0;
    }
    
    .service-icon {
        margin-right: 12px;
        font-size: 1.2rem;
    }
    
    .service-name {
        font-weight: 500;
        color: #2c3e50;
    }
    
    /* ì¶”ì²œ ì„œë¹„ìŠ¤ ì¹´ë“œ */
    .recommend-grid {
        display: grid;
        grid-template-columns: repeat(3, 1fr);
        gap: 16px;
        margin: 24px 0;
    }
    
    .recommend-card {
        background: #f8fffe;
        border: 1px solid #d4edda;
        border-radius: 12px;
        padding: 20px;
        text-align: center;
        transition: all 0.3s ease;
    }
    
    .recommend-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
    }
    
    .recommend-icon {
        background: linear-gradient(135deg, #4a90e2, #357abd);
        color: white;
        border-radius: 8px;
        width: 40px;
        height: 40px;
        display: flex;
        align-items: center;
        justify-content: center;
        margin: 0 auto 12px;
        font-size: 1.2rem;
    }
    
    .recommend-title {
        font-weight: 600;
        color: #2c3e50;
        margin-bottom: 8px;
        font-size: 0.95rem;
    }
    
    .recommend-desc {
        font-size: 0.85rem;
        color: #6c757d;
        line-height: 1.4;
    }
    
    /* ë¶€ê°€ì„œë¹„ìŠ¤ ìŠ¤íƒ€ì¼ */
    .addon-service {
        display: flex;
        align-items: center;
        margin-bottom: 16px;
        padding: 16px;
        background: white;
        border-radius: 12px;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.06);
    }
    
    .addon-status {
        background: #f0f0f0;
        border-radius: 8px;
        padding: 8px 12px;
        margin-right: 12px;
        font-size: 0.85rem;
        color: #666;
    }
    
    .addon-status.active {
        background: #4a90e2;
        color: white;
    }
    
    .addon-name {
        font-weight: 600;
        color: #2c3e50;
    }
    
    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ */
    .stButton > button {
        background: linear-gradient(135deg, #4a90e2, #357abd);
        color: white;
        border: none;
        border-radius: 12px;
        padding: 12px 32px;
        font-weight: 600;
        font-size: 1rem;
        transition: all 0.3s ease;
        box-shadow: 0 4px 12px rgba(74, 144, 226, 0.3);
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 6px 16px rgba(74, 144, 226, 0.4);
    }
    
    /* íŒŒì¼ ìƒíƒœ */
    .file-status {
        background: #f8f9fa;
        border-radius: 12px;
        padding: 16px;
        margin: 12px 0;
        border-left: 4px solid #28a745;
        font-size: 0.95rem;
    }
    
    .file-status.error {
        border-left-color: #dc3545;
        background: #fff5f5;
    }
    
    /* ë¶„ë¥˜ ê²°ê³¼ */
    .classification-box {
        background: white;
        border-radius: 12px;
        padding: 20px;
        margin: 12px 0;
        border-left: 4px solid #28a745;
        font-size: 1.05rem;
        box-shadow: 0 2px 8px rgba(0, 0, 0, 0.06);
    }
    
    .classification-box.review {
        border-left-color: #ffc107;
    }
    
    .classification-box.exclude {
        border-left-color: #dc3545;
    }
    
    /* ë°˜ì‘í˜• */
    @media (max-width: 768px) {
        .payment-style-grid {
            grid-template-columns: 1fr;
        }
        
        .status-grid {
            grid-template-columns: 1fr;
        }
        
        .recent-usage-grid {
            grid-template-columns: 1fr;
        }
        
        .recommend-grid {
            grid-template-columns: 1fr;
        }
        
        .welcome-title {
            font-size: 2.2rem;
        }
    }
</style>
""", unsafe_allow_html=True)

# --- ëª¨ë“  í•¨ìˆ˜ë“¤ (ê¸°ì¡´ê³¼ ë™ì¼) ---
def load_and_merge_wos_files(uploaded_files):
    all_dataframes = []
    file_status = []
    
    for i, uploaded_file in enumerate(uploaded_files):
        try:
            file_bytes = uploaded_file.getvalue()
            encodings_to_try = ['utf-8-sig', 'utf-8', 'latin1', 'iso-8859-1']
            
            df = None
            encoding_used = None
            
            for encoding in encodings_to_try:
                try:
                    file_content = file_bytes.decode(encoding)
                    
                    if not file_content.strip().startswith('FN '):
                        continue
                        
                    df = parse_wos_format(file_content)
                    if df is not None and len(df) > 0:
                        encoding_used = encoding
                        break
                        
                except Exception:
                    continue
            
            if df is not None:
                all_dataframes.append(df)
                file_status.append({
                    'filename': uploaded_file.name,
                    'status': 'SUCCESS',
                    'papers': len(df),
                    'encoding': encoding_used,
                    'message': f'âœ… {len(df)}í¸ ë…¼ë¬¸ ë¡œë”© ì„±ê³µ'
                })
            else:
                file_status.append({
                    'filename': uploaded_file.name,
                    'status': 'ERROR',
                    'papers': 0,
                    'encoding': 'N/A',
                    'message': 'âŒ WOS Plain Text í˜•ì‹ì´ ì•„ë‹˜'
                })
                
        except Exception as e:
            file_status.append({
                'filename': uploaded_file.name,
                'status': 'ERROR',
                'papers': 0,
                'encoding': 'N/A',
                'message': f'âŒ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)[:50]}'
            })
    
    if all_dataframes:
        merged_df = pd.concat(all_dataframes, ignore_index=True)
        original_count = len(merged_df)
        
        duplicates_removed = 0
        
        if 'UT' in merged_df.columns:
            ut_series = merged_df['UT'].copy()
            
            def is_meaningful_ut(value):
                if pd.isna(value):
                    return False
                str_value = str(value).strip()
                if len(str_value) == 0 or str_value.lower() in ['nan', 'none', 'null', '']:
                    return False
                if len(str_value) < 10:
                    return False
                if str_value.startswith('WOS:') or (len(str_value) >= 15 and any(c.isalnum() for c in str_value)):
                    return True
                return False
            
            meaningful_ut_mask = ut_series.apply(is_meaningful_ut)
            rows_with_meaningful_ut = merged_df[meaningful_ut_mask]
            rows_without_meaningful_ut = merged_df[~meaningful_ut_mask]
            
            if len(rows_with_meaningful_ut) > 1:
                before_dedup = len(rows_with_meaningful_ut)
                deduplicated_meaningful = rows_with_meaningful_ut.drop_duplicates(subset=['UT'], keep='first')
                after_dedup = len(deduplicated_meaningful)
                
                actual_duplicates = before_dedup - after_dedup
                
                if actual_duplicates > 0:
                    duplicates_removed = actual_duplicates
                    merged_df = pd.concat([deduplicated_meaningful, rows_without_meaningful_ut], ignore_index=True)
        
        if duplicates_removed == 0 and 'TI' in merged_df.columns:
            has_title = merged_df['TI'].notna() & (merged_df['TI'].str.strip() != '')
            has_author = merged_df.get('AU', pd.Series()).notna() if 'AU' in merged_df.columns else pd.Series([False] * len(merged_df))
            
            complete_rows = merged_df[has_title & has_author] if 'AU' in merged_df.columns else merged_df[has_title]
            incomplete_rows = merged_df[~(has_title & has_author)] if 'AU' in merged_df.columns else merged_df[~has_title]
            
            if len(complete_rows) > 1:
                dedup_columns = ['TI', 'AU'] if 'AU' in merged_df.columns else ['TI']
                deduplicated_complete = complete_rows.drop_duplicates(subset=dedup_columns, keep='first')
                title_author_removed = len(complete_rows) - len(deduplicated_complete)
                
                if title_author_removed > 0:
                    duplicates_removed = title_author_removed
                    merged_df = pd.concat([deduplicated_complete, incomplete_rows], ignore_index=True)
        
        return merged_df, file_status, duplicates_removed
    else:
        return None, file_status, 0

def parse_wos_format(content):
    lines = content.split('\n')
    records = []
    current_record = {}
    current_field = None
    
    for line in lines:
        line = line.rstrip()
        
        if not line:
            continue
            
        if line == 'ER':
            if current_record:
                records.append(current_record.copy())
                current_record = {}
                current_field = None
            continue
            
        if line.startswith(('FN ', 'VR ')):
            continue
            
        if not line.startswith('   ') and ' ' in line:
            parts = line.split(' ', 1)
            if len(parts) == 2:
                field_tag, field_value = parts
                current_field = field_tag
                current_record[field_tag] = field_value.strip()
        
        elif line.startswith('   ') and current_field and current_field in current_record:
            continuation_value = line[3:].strip()
            if continuation_value:
                current_record[current_field] += '; ' + continuation_value
    
    if current_record:
        records.append(current_record)
    
    if not records:
        return None
        
    return pd.DataFrame(records)

def classify_article(row):
    core_streaming_keywords = [
        'live streaming', 'livestreaming', 'live stream', 'live broadcast', 'live video',
        'real time streaming', 'real-time streaming', 'streaming platform', 'streaming service',
        'live webcast', 'webcasting', 'live transmission', 'interactive broadcasting',
        'live commerce', 'live shopping', 'live selling', 'livestream commerce',
        'live e-commerce', 'social commerce', 'live marketing', 'streaming monetization',
        'live retail', 'shoppertainment', 'live sales', 'streaming sales',
        'streamer', 'viewer', 'audience engagement', 'streaming audience', 'live audience',
        'streaming behavior', 'viewer behavior', 'streaming experience', 'live interaction',
        'streaming community', 'online community', 'digital community', 'virtual community',
        'parasocial relationship', 'streamer-viewer', 'live chat', 'chat interaction',
        'twitch', 'youtube live', 'facebook live', 'instagram live', 'tiktok live',
        'periscope', 'mixer', 'douyin', 'kuaishou', 'taobao live', 'tmall live',
        'amazon live', 'shopee live', 'live.ly', 'bigo live',
        'live gaming', 'game streaming', 'esports streaming', 'streaming content',
        'live entertainment', 'live performance', 'virtual concert', 'live music'
    ]
    
    business_commerce_keywords = [
        'e-commerce', 'online shopping', 'digital commerce', 'mobile commerce', 'm-commerce',
        'social commerce', 'influencer marketing', 'content creator', 'digital marketing', 
        'brand engagement', 'consumer behavior', 'purchase intention', 'buying behavior',
        'social influence', 'word of mouth', 'viral marketing', 'user generated content',
        'brand advocacy', 'customer engagement', 'social media marketing', 'digital influence',
        'online influence', 'interactive marketing', 'personalized marketing', 'real-time marketing',
        'digital transformation', 'omnichannel', 'customer experience', 'user experience',
        'engagement marketing', 'social selling', 'digital retail', 'online retail'
    ]
    
    education_keywords = [
        'online education', 'e-learning', 'distance learning', 'remote learning',
        'virtual classroom', 'online teaching', 'digital learning', 'mooc',
        'educational technology', 'learning management system', 'blended learning',
        'medical education', 'nursing education', 'surgical training', 'clinical education',
        'telemedicine', 'telehealth', 'digital health', 'health education',
        'interactive learning', 'synchronous learning', 'real-time learning'
    ]
    
    technical_keywords = [
        'real time video', 'real-time video', 'video streaming', 'audio streaming',
        'multimedia streaming', 'video compression', 'video encoding', 'video delivery',
        'content delivery', 'cdn', 'edge computing', 'multimedia communication',
        'video communication', 'webrtc', 'peer to peer streaming', 'p2p streaming',
        'distributed streaming', 'mobile streaming', 'mobile video', 'wireless streaming',
        'mobile broadcast', 'smartphone streaming', 'live video transmission',
        'streaming technology', 'adaptive streaming', 'video quality', 'streaming latency',
        'interactive media', 'virtual reality', 'augmented reality', 'vr', 'ar',
        '3d streaming', 'immersive media', 'metaverse'
    ]
    
    exclusion_keywords = [
        'routing protocol', 'network topology', 'packet routing', 'mac protocol',
        'ieee 802.11', 'wimax protocol', 'lte protocol', 'network security protocol',
        'vlsi design', 'circuit design', 'antenna design', 'rf circuit',
        'hardware implementation', 'fpga implementation', 'asic design',
        'signal processing algorithm', 'modulation scheme', 'channel estimation',
        'beamforming algorithm', 'mimo antenna', 'ofdm modulation',
        'frequency allocation', 'spectrum allocation', 'wireless sensor network',
        'satellite communication', 'underwater communication', 'space communication',
        'biomedical signal', 'medical imaging', 'radar system', 'sonar system',
        'geological survey', 'seismic data', 'astronomical data', 'climate modeling'
    ]
    
    def extract_text(value):
        if pd.isna(value) or value is None:
            return ""
        return str(value).lower().strip()
    
    title = extract_text(row.get('TI', ''))
    source_title = extract_text(row.get('SO', ''))
    author_keywords = extract_text(row.get('DE', ''))
    keywords_plus = extract_text(row.get('ID', ''))
    abstract = extract_text(row.get('AB', ''))
    
    full_text = ' '.join([title, source_title, author_keywords, keywords_plus, abstract])
    
    if any(keyword in full_text for keyword in exclusion_keywords):
        return 'Exclude (ê¸°ìˆ ì  ë¹„ê´€ë ¨)'
    
    if any(keyword in full_text for keyword in core_streaming_keywords):
        return 'Include (í•µì‹¬ì—°êµ¬)'
    
    if any(keyword in full_text for keyword in business_commerce_keywords):
        digital_indicators = ['digital', 'online', 'internet', 'web', 'social media', 'platform', 'mobile', 'app', 'virtual', 'interactive']
        if any(indicator in full_text for indicator in digital_indicators):
            return 'Include (ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ë ¨)'
    
    if any(keyword in full_text for keyword in education_keywords):
        online_indicators = ['online', 'digital', 'virtual', 'remote', 'distance', 'interactive', 'real-time', 'synchronous']
        if any(indicator in full_text for indicator in online_indicators):
            return 'Include (êµìœ¡ ê´€ë ¨)'
    
    if any(keyword in full_text for keyword in technical_keywords):
        live_indicators = ['live', 'real time', 'real-time', 'streaming', 'broadcast', 'interactive', 'synchronous', 'instant']
        if any(indicator in full_text for indicator in live_indicators):
            return 'Include (ê¸°ìˆ ì  ê¸°ë°˜)'
    
    return 'Review (ë¶„ë¥˜ ë¶ˆí™•ì‹¤)'

def convert_to_scimat_wos_format(df_to_convert):
    wos_field_order = [
        'PT', 'AU', 'AF', 'TI', 'SO', 'LA', 'DT', 'DE', 'ID', 'AB', 'C1', 'C3', 'RP',
        'EM', 'RI', 'OI', 'FU', 'FX', 'CR', 'NR', 'TC', 'Z9', 'U1', 'U2', 'PU', 'PI', 'PA',
        'SN', 'EI', 'J9', 'JI', 'PD', 'PY', 'VL', 'IS', 'BP', 'EP', 'DI', 'EA', 'PG',
        'WC', 'WE', 'SC', 'GA', 'UT', 'PM', 'OA', 'DA'
    ]
    
    file_content = ["FN Clarivate Analytics Web of Science", "VR 1.0"]
    multi_line_fields = ['AU', 'AF', 'DE', 'ID', 'C1', 'C3', 'CR']

    for _, row in df_to_convert.iterrows():
        if len(file_content) > 2:
            file_content.append("")
        
        for tag in wos_field_order:
            if tag in row.index and pd.notna(row[tag]) and str(row[tag]).strip() and str(row[tag]).strip().lower() != 'nan':
                value = str(row[tag]).strip()
                
                if tag in multi_line_fields:
                    items = [item.strip() for item in value.split(';') if item.strip()]
                    if items:
                        file_content.append(f"{tag} {items[0]}")
                        for item in items[1:]:
                            file_content.append(f"   {item}")
                else:
                    file_content.append(f"{tag} {value}")
        
        file_content.append("ER")
    
    return "\n".join(file_content).encode('utf-8-sig')

# --- ë©”ì¸ í—¤ë” (ì²¨ë¶€íŒŒì¼ ì™„ì „ ë³µì œ) ---
st.markdown("""
<div class="main-welcome-card">
    <div class="card-icon">ğŸ’³</div>
    <div class="welcome-title">ì—…ë°ê²½ë‹˜, ì•ˆë…•í•˜ì„¸ìš”.</div>
    <div class="welcome-subtitle">THE 1</div>
    <div class="card-link">ë³´ìœ  ì¹´ë“œ ë³´ê¸° ></div>
</div>
""", unsafe_allow_html=True)

# --- ê¸°ëŠ¥ ì†Œê°œ ì¹´ë“œë“¤ (3ê°œ ê·¸ë¦¬ë“œ) ---
st.markdown("""
<div class="status-grid">
    <div class="status-card">
        <div class="status-icon">ğŸ”—</div>
        <div class="status-title">ë‹¤ì¤‘ íŒŒì¼ ìë™ ë³‘í•©</div>
        <div class="status-desc">ì—¬ëŸ¬ WOS íŒŒì¼ì„ í•œ ë²ˆì— ë³‘í•© ì²˜ë¦¬</div>
    </div>
    <div class="status-card">
        <div class="status-icon">ğŸš«</div>
        <div class="status-title">ìŠ¤ë§ˆíŠ¸ ì¤‘ë³µ ì œê±°</div>
        <div class="status-desc">UT ê¸°ì¤€ ìë™ ì¤‘ë³µ ë…¼ë¬¸ ê°ì§€ ë° ì œê±°</div>
    </div>
    <div class="status-card">
        <div class="status-icon">ğŸ¯</div>
        <div class="status-title">ë°ì´í„° ë¶„ë¥˜</div>
        <div class="status-desc">ëŒ€ê·œëª¨ ë°ì´í„° í¬ê´„ì  ë¶„ë¥˜ ë° ë¶„ì„</div>
    </div>
</div>
""", unsafe_allow_html=True)

# --- íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ ---
st.markdown("""
<div class="section-header">
    <div class="section-title">ğŸ“ ë‹¤ì¤‘ WOS Plain Text íŒŒì¼ ì—…ë¡œë“œ</div>
    <div class="section-subtitle">500ê°œ ë‹¨ìœ„ë¡œ ë‚˜ë‰œ ì—¬ëŸ¬ WOS íŒŒì¼ì„ ëª¨ë‘ ì„ íƒí•˜ì—¬ ì—…ë¡œë“œí•˜ì„¸ìš”</div>
</div>
""", unsafe_allow_html=True)

uploaded_files = st.file_uploader(
    "WOS Plain Text íŒŒì¼ ì„ íƒ (ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)",
    type=['txt'],
    accept_multiple_files=True,
    label_visibility="collapsed",
    help="WOS Plain Text íŒŒì¼ë“¤ì„ ë“œë˜ê·¸í•˜ì—¬ ë†“ê±°ë‚˜ í´ë¦­í•˜ì—¬ ì„ íƒí•˜ì„¸ìš”"
)

if uploaded_files:
    st.markdown(f"**ğŸ“‹ ì„ íƒëœ íŒŒì¼ ê°œìˆ˜:** {len(uploaded_files)}ê°œ")
    
    # í”„ë¡œê·¸ë ˆìŠ¤ ë°”
    progress_bar = st.progress(0)
    
    with st.spinner(f"ğŸ”„ {len(uploaded_files)}ê°œ WOS íŒŒì¼ ë³‘í•© ë° ë¶„ì„ ì¤‘..."):
        # íŒŒì¼ ë³‘í•©
        merged_df, file_status, duplicates_removed = load_and_merge_wos_files(uploaded_files)
        progress_bar.progress(50)
        
        if merged_df is None:
            st.error("âš ï¸ ì²˜ë¦¬ ê°€ëŠ¥í•œ WOS Plain Text íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            
            for status in file_status:
                status_class = "" if status['status'] == 'SUCCESS' else "error"
                st.markdown(f"""
                <div class="file-status {status_class}">
                    <strong>{status['filename']}</strong><br>
                    {status['message']}
                </div>
                """, unsafe_allow_html=True)
            st.stop()
        
        # ë…¼ë¬¸ ë¶„ë¥˜ ìˆ˜í–‰
        merged_df['Classification'] = merged_df.apply(classify_article, axis=1)
        progress_bar.progress(100)

    # ì„±ê³µ ë©”ì‹œì§€
    successful_files = len([s for s in file_status if s['status'] == 'SUCCESS'])
    total_papers = len(merged_df)
    
    st.success(f"âœ… ë³‘í•© ì™„ë£Œ! {successful_files}ê°œ íŒŒì¼ì—ì„œ {total_papers:,}í¸ì˜ ë…¼ë¬¸ì„ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.")
    
    if duplicates_removed > 0:
        st.info(f"ğŸ”„ ì¤‘ë³µ ë…¼ë¬¸ {duplicates_removed}í¸ì´ ìë™ìœ¼ë¡œ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        st.info("âœ… ì¤‘ë³µ ë…¼ë¬¸ ì—†ìŒ - ëª¨ë“  ë…¼ë¬¸ì´ ê³ ìœ í•œ ë°ì´í„°ì…ë‹ˆë‹¤.")

    # --- ê²°ì œì˜ˆì •ê¸ˆì•¡ ìŠ¤íƒ€ì¼ ë©”íŠ¸ë¦­ (ì²¨ë¶€íŒŒì¼ ì™„ì „ ë³µì œ) ---
    include_papers = len(merged_df[merged_df['Classification'].str.contains('Include', na=False)])
    review_papers = len(merged_df[merged_df['Classification'].str.contains('Review', na=False)])
    exclude_papers = len(merged_df[merged_df['Classification'].str.contains('Exclude', na=False)])
    
    st.markdown(f"""
    <div class="payment-style-grid">
        <div class="payment-card">
            <div class="payment-title">ì´ìš©ê°€ëŠ¥ê¸ˆì•¡</div>
            <div class="payment-item">
                <div class="payment-label">ì¼ì‹œë¶ˆ/í• ë¶€</div>
                <div class="payment-value large">{total_papers:,}í¸</div>
            </div>
            <div class="payment-item">
                <div class="payment-label">ë‹¨ê¸°ì¹´ë“œëŒ€ì¶œ (í˜„ê¸ˆì„œë¹„ìŠ¤)</div>
                <div class="payment-value">{include_papers:,}í¸</div>
            </div>
            <div class="payment-item">
                <div class="payment-label">ì¥ê¸°ì¹´ë“œëŒ€ì¶œ (ì¹´ë“œë¡ )</div>
                <div class="payment-value">{review_papers:,}í¸</div>
            </div>
        </div>
        <div class="payment-card">
            <div class="payment-title">ê²°ì œì˜ˆì •ê¸ˆì•¡</div>
            <div class="payment-item">
                <div class="payment-label">ì´ë²ˆ<br>ì˜¤ëŠ˜ ì…ê¸ˆ ì‹œ</div>
                <div class="payment-value large">{successful_files:,}ê°œ</div>
            </div>
            <div class="payment-item">
                <div class="payment-label">ë‹¤ìŒ<br>10ì›” 10ì¼</div>
                <div class="payment-value">{duplicates_removed:,}í¸</div>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)

    # --- íŒŒì¼ë³„ ì²˜ë¦¬ ìƒíƒœ ---
    st.markdown("""
    <div class="section-header">
        <div class="section-title">ğŸ“„ íŒŒì¼ë³„ ì²˜ë¦¬ ìƒíƒœ</div>
        <div class="section-subtitle">ì—…ë¡œë“œëœ ê° íŒŒì¼ì˜ ì²˜ë¦¬ ê²°ê³¼</div>
    </div>
    """, unsafe_allow_html=True)

    st.markdown('<div class="chart-container">', unsafe_allow_html=True)
    st.markdown('<div class="chart-title">ğŸ“‹ íŒŒì¼ë³„ ìƒì„¸ ìƒíƒœ</div>', unsafe_allow_html=True)
    
    col1, col2 = st.columns([0.7, 0.3])
    
    with col1:        
        for status in file_status:
            status_class = "" if status['status'] == 'SUCCESS' else "error"
            st.markdown(f"""
            <div class="file-status {status_class}">
                <strong>{status['filename']}</strong><br>
                <small>{status['message']}</small>
                {f" | ì¸ì½”ë”©: {status['encoding']}" if status['encoding'] != 'N/A' else ""}
            </div>
            """, unsafe_allow_html=True)
    
    with col2:
        success_count = len([s for s in file_status if s['status'] == 'SUCCESS'])
        error_count = len([s for s in file_status if s['status'] == 'ERROR'])
        
        st.markdown(f"""
        <div class="status-card">
            <div class="status-icon">âœ…</div>
            <div class="status-title">{success_count}</div>
            <div class="status-desc">ì„±ê³µí•œ íŒŒì¼</div>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown(f"""
        <div class="status-card">
            <div class="status-icon">âŒ</div>
            <div class="status-title">{error_count}</div>
            <div class="status-desc">ì‹¤íŒ¨í•œ íŒŒì¼</div>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("</div>", unsafe_allow_html=True)

    # --- ë¶„ì„ ê²°ê³¼ ì°¨íŠ¸ ---
    st.markdown("""
    <div class="chart-container">
        <div class="chart-title">Research Classification Distribution</div>
    """, unsafe_allow_html=True)

    classification_counts_df = merged_df['Classification'].value_counts().reset_index()
    classification_counts_df.columns = ['ë¶„ë¥˜', 'ë…¼ë¬¸ ìˆ˜']

    col1, col2 = st.columns([0.4, 0.6])
    with col1:
        st.dataframe(classification_counts_df, use_container_width=True, hide_index=True)

    with col2:
        # ë„ë„› ì°¨íŠ¸
        selection = alt.selection_point(fields=['ë¶„ë¥˜'], on='mouseover', nearest=True)

        base = alt.Chart(classification_counts_df).encode(
            theta=alt.Theta(field="ë…¼ë¬¸ ìˆ˜", type="quantitative", stack=True),
            color=alt.Color(field="ë¶„ë¥˜", type="nominal", title="Classification",
                           scale=alt.Scale(range=['#4a90e2', '#357abd', '#17a2b8', '#28a745', '#ffc107', '#dc3545']),
                           legend=alt.Legend(orient="right", titleColor="#2c3e50", labelColor="#6c757d")),
            opacity=alt.condition(selection, alt.value(1), alt.value(0.8))
        ).add_params(selection)

        pie = base.mark_arc(outerRadius=150, innerRadius=90)
        text_total = alt.Chart(pd.DataFrame([{'value': f'{total_papers}'}])).mark_text(
            align='center', baseline='middle', fontSize=45, fontWeight='bold', color='#4a90e2'
        ).encode(text='value:N')
        text_label = alt.Chart(pd.DataFrame([{'value': 'Total Papers'}])).mark_text(
            align='center', baseline='middle', fontSize=16, dy=30, color='#6c757d'
        ).encode(text='value:N')

        chart = (pie + text_total + text_label).properties(
            width=350, height=350
        ).configure_view(strokeWidth=0)
        st.altair_chart(chart, use_container_width=True)

    st.markdown("</div>", unsafe_allow_html=True)

    # --- ë¶„ë¥˜ ìƒì„¸ ê²°ê³¼ ---
    st.markdown("""
    <div class="chart-container">
        <div class="chart-title">ë¶„ë¥˜ë³„ ìƒì„¸ ë¶„í¬</div>
    """, unsafe_allow_html=True)
    
    for classification in merged_df['Classification'].unique():
        count = len(merged_df[merged_df['Classification'] == classification])
        percentage = (count / total_papers * 100)
        
        if classification.startswith('Include'):
            box_class = ""
            icon = "âœ…"
        elif classification.startswith('Review'):
            box_class = "review"
            icon = "ğŸ“"
        else:
            box_class = "exclude"
            icon = "âŒ"
        
        st.markdown(f"""
        <div class="classification-box {box_class}">
            <strong>{icon} {classification}:</strong> {count:,}í¸ ({percentage:.1f}%)
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("</div>", unsafe_allow_html=True)

    # --- ìµœê·¼ ì´ìš©ë‚´ì—­ & ë³´ë„ˆìŠ¤í¬ì¸íŠ¸ ìŠ¤íƒ€ì¼ (ì²¨ë¶€íŒŒì¼ ë³µì œ) ---
    st.markdown(f"""
    <div class="recent-usage-grid">
        <div class="usage-card">
            <div class="usage-title">ìµœê·¼ ì´ìš©ë‚´ì—­ ></div>
            <div class="usage-item">
                <div class="usage-detail">
                    <div class="usage-name">ì¿ íŒ¡ì´ì¸ </div>
                    <div class="usage-date">25.08.21</div>
                </div>
                <div class="usage-amount">18,500ì›</div>
            </div>
        </div>
        <div class="usage-card">
            <div class="usage-title">ë³´ë„ˆìŠ¤í¬ì¸íŠ¸ ></div>
            <div class="bonus-center">
                <div class="bonus-points">9,163 P</div>
                <div class="bonus-buttons">
                    <div class="bonus-button">í¬ì¸íŠ¸ ì „í™˜</div>
                    <div class="bonus-button">í¬ì¸íŠ¸ ì‚¬ìš©ì²˜</div>
                </div>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)

    # ìµœì¢… ë°ì´í„°ì…‹ ì¤€ë¹„
    df_final = merged_df[~merged_df['Classification'].str.contains('Exclude', na=False)].copy()
    df_final_output = df_final.drop(columns=['Classification'], errors='ignore')

    # --- ë§ˆì´ë©”ë‰´ (ì²¨ë¶€íŒŒì¼ ìŠ¤íƒ€ì¼) ---
    st.markdown("""
    <div class="usage-card">
        <div class="usage-title">ë§ˆì´ë©”ë‰´</div>
        <div class="service-grid">
            <div class="service-item">
                <div class="service-icon">ğŸ“Š</div>
                <div class="service-name">ì¹´ë“œ ì‚¬ìš©ë“±ë¡</div>
            </div>
            <div class="service-item">
                <div class="service-icon">ğŸ””</div>
                <div class="service-name">ì¹´ë“œ ë¶„ì‹¤ì‹ ê³ </div>
            </div>
            <div class="service-item">
                <div class="service-icon">ğŸ’»</div>
                <div class="service-name">ê²°ì œê³„ì¢Œë³€ê²½</div>
            </div>
            <div class="service-item">
                <div class="service-icon">ğŸ‘¤</div>
                <div class="service-name">ê°œì¸ì •ë³´ë³€ê²½</div>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)

    # --- ë‚˜ì˜ ë¶€ê°€ì„œë¹„ìŠ¤ (ì²¨ë¶€íŒŒì¼ ìŠ¤íƒ€ì¼) ---
    st.markdown("""
    <div class="section-header">
        <div class="section-title">ë‚˜ì˜ ë¶€ê°€ì„œë¹„ìŠ¤</div>
        <div class="section-subtitle">ì¶”ì²œì„œë¹„ìŠ¤</div>
    </div>
    """, unsafe_allow_html=True)

    col1, col2 = st.columns(2)

    with col1:
        st.markdown("""
        <div class="addon-service">
            <div class="addon-status">ë¯¸ì‚¬ìš©</div>
            <div class="addon-name">ì¼ë¶„ê²°ì œê¸ˆì•¡ì´ì›”ì•½ì • (ë¦¬ë³¼ë¹™)</div>
        </div>
        """, unsafe_allow_html=True)

    with col2:
        st.markdown("""
        <div class="addon-service">
            <div class="addon-status">ë¯¸ì‚¬ìš©</div>
            <div class="addon-name">íœ´ëŒ€í°ê²°ì œ</div>
        </div>
        """, unsafe_allow_html=True)

    with col1:
        st.markdown("""
        <div class="addon-service">
            <div class="addon-status active">ì‚¬ìš©ì¤‘</div>
            <div class="addon-name">ë°”ë¡œì•Œë¦¼</div>
        </div>
        """, unsafe_allow_html=True)

    # --- ì¶”ì²œì„œë¹„ìŠ¤ (ì²¨ë¶€íŒŒì¼ ìŠ¤íƒ€ì¼) ---
    st.markdown("""
    <div class="usage-card">
        <div class="usage-title">ì¶”ì²œì„œë¹„ìŠ¤</div>
        <div class="recommend-grid">
            <div class="recommend-card">
                <div class="recommend-icon">ğŸ’³</div>
                <div class="recommend-title">ë¶„í• ë‚©ë¶€ ì„œë¹„ìŠ¤</div>
                <div class="recommend-desc">ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ë¥¼ ìœ„í•œ ë¶„í•  ì—…ë¡œë“œ ì„œë¹„ìŠ¤</div>
            </div>
            <div class="recommend-card">
                <div class="recommend-icon">ğŸ</div>
                <div class="recommend-title">ë””ì§€í„¸ ëª…ì„¸ì„œ ì‹ ì²­</div>
                <div class="recommend-desc">ë¶„ì„ ê²°ê³¼ ìë™ ë¦¬í¬íŠ¸ ìƒì„± ì„œë¹„ìŠ¤</div>
            </div>
            <div class="recommend-card">
                <div class="recommend-icon">ğŸ’°</div>
                <div class="recommend-title">ê¸°í”„íŠ¸ì¹´ë“œ</div>
                <div class="recommend-desc">í”„ë¦¬ë¯¸ì—„ ë¶„ì„ íŒ¨í‚¤ì§€ ì´ìš©ê¶Œ</div>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)

    # --- ìµœì¢… íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì„¹ì…˜ ---
    st.markdown("""
    <div class="download-section">
        <div class="download-title">ğŸ“¥ SCIMAT ë¶„ì„ìš© íŒŒì¼ ë‹¤ìš´ë¡œë“œ</div>
        <div class="download-desc">ë³‘í•© ë° ì •ì œëœ WOS Plain Text íŒŒì¼</div>
    """, unsafe_allow_html=True)
    
    # SCIMAT í˜¸í™˜ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    text_data = convert_to_scimat_wos_format(df_final_output)
    
    st.download_button(
        label="ğŸ“¥ ìµœì¢… íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
        data=text_data,
        file_name="live_streaming_merged_scimat_ready.txt",
        mime="text/plain",
        use_container_width=True,
        help="SCIMATì—ì„œ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ WOS Plain Text íŒŒì¼"
    )
    
    st.markdown("</div>", unsafe_allow_html=True)

    # Review ë…¼ë¬¸ë“¤ì´ ìˆëŠ” ê²½ìš° ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ì œê³µ
    review_papers_df = merged_df[merged_df['Classification'].str.contains('Review', na=False)]
    
    if len(review_papers_df) > 0:
        with st.expander(f"ğŸ“ Review (ê²€í†  í•„ìš”) - ë…¼ë¬¸ ëª©ë¡ ({len(review_papers_df)}í¸)", expanded=False):
            # ì—‘ì…€ íŒŒì¼ ìƒì„±
            review_excel_data = []
            for idx, (_, paper) in enumerate(review_papers_df.iterrows(), 1):
                review_excel_data.append({
                    'ë²ˆí˜¸': idx,
                    'ë…¼ë¬¸ ì œëª©': str(paper.get('TI', 'N/A')),
                    'ì¶œíŒì—°ë„': str(paper.get('PY', 'N/A')),
                    'ì €ë„ëª…': str(paper.get('SO', 'N/A')),
                    'ì €ì': str(paper.get('AU', 'N/A')),
                    'ë¶„ë¥˜': str(paper.get('Classification', 'N/A'))
                })
            
            review_excel_df = pd.DataFrame(review_excel_data)
            
            excel_buffer = io.BytesIO()
            with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                review_excel_df.to_excel(writer, sheet_name='Review_Papers', index=False)
            excel_data = excel_buffer.getvalue()
            
            st.download_button(
                label="ğŸ“Š ê²€í†  ë…¼ë¬¸ ëª©ë¡ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
                data=excel_data,
                file_name=f"review_papers_list_{len(review_papers_df)}í¸.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                use_container_width=True
            )

# ë„ì›€ë§ ì„¹ì…˜
with st.expander("â“ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ (FAQ)", expanded=False):
    st.markdown("""
    **Q: ì—¬ëŸ¬ WOS íŒŒì¼ì„ ì–´ë–»ê²Œ í•œ ë²ˆì— ì²˜ë¦¬í•˜ë‚˜ìš”?**
    A: WOSì—ì„œ ì—¬ëŸ¬ ë²ˆ Plain Text ë‹¤ìš´ë¡œë“œí•œ í›„, ëª¨ë“  .txt íŒŒì¼ì„ í•œ ë²ˆì— ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ ë³‘í•©ë©ë‹ˆë‹¤.
    
    **Q: ì¤‘ë³µëœ ë…¼ë¬¸ì´ ìˆì„ê¹Œë´ ê±±ì •ë©ë‹ˆë‹¤.**
    A: UT(Unique Article Identifier) ê¸°ì¤€ìœ¼ë¡œ ìë™ ì¤‘ë³µ ì œê±°ë˜ë©°, UTê°€ ì—†ìœ¼ë©´ ì œëª©+ì €ì ì¡°í•©ìœ¼ë¡œ ì¤‘ë³µì„ ê°ì§€í•©ë‹ˆë‹¤.
    
    **Q: WOSì—ì„œ ì–´ë–¤ ì„¤ì •ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•´ì•¼ í•˜ë‚˜ìš”?**
    A: Export â†’ Record Content: "Full Record and Cited References", File Format: "Plain Text"ë¡œ ì„¤ì •í•˜ì„¸ìš”.
    
    **Q: SCIMAT ë¶„ì„ ì„¤ì •ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?**
    A: Unit of Analysis: "Author's words + Source's words", Network Type: "Co-occurrence", Normalization: "Equivalence Index"ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.
    """)

st.markdown("<br><br>", unsafe_allow_html=True)
