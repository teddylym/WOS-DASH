import streamlit as st
import pandas as pd
import altair as alt
import io
import re
from collections import Counter

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="WOS Multi-File Merger | SCIMAT Edition",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# --- í† ìŠ¤ ìŠ¤íƒ€ì¼ CSS (ìƒëµ - ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼) ---
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Pretendard:wght@400;500;600;700&display=swap');
    
    .main-container {
        background: #f2f4f6;
        min-height: 100vh;
        font-family: 'Pretendard', -apple-system, BlinkMacSystemFont, system-ui, sans-serif;
    }
    
    .metric-card {
        background: white;
        border-radius: 8px;
        padding: 20px;
        box-shadow: none;
        border: 1px solid #e5e8eb;
        margin-bottom: 12px;
        transition: all 0.2s ease;
        min-height: 160px;
        display: flex;
        flex-direction: column;
        justify-content: space-between;
    }
    
    .metric-card:hover {
        box-shadow: 0 2px 8px rgba(0,0,0,0.08);
        transform: translateY(-1px);
        border-color: #3182f6;
    }
    
    .metric-value {
        font-size: 2.2rem;
        font-weight: 700;
        color: #191f28;
        margin: 0;
        line-height: 1.2;
        letter-spacing: -0.02em;
    }
    
    .metric-label {
        font-size: 13px;
        color: #8b95a1;
        margin: 6px 0 0 0;
        font-weight: 500;
        letter-spacing: -0.01em;
    }
    
    .metric-icon {
        background: #3182f6;
        color: white;
        width: 32px;
        height: 32px;
        border-radius: 6px;
        display: flex;
        align-items: center;
        justify-content: center;
        font-size: 16px;
        margin-bottom: 12px;
    }
    
    .chart-container {
        background: white;
        border-radius: 8px;
        padding: 24px;
        box-shadow: none;
        border: 1px solid #e5e8eb;
        margin: 16px 0;
    }
    
    .chart-title {
        font-size: 16px;
        font-weight: 600;
        color: #191f28;
        margin-bottom: 16px;
        letter-spacing: -0.01em;
    }
    
    .section-header {
        background: white;
        color: #191f28;
        padding: 16px 20px;
        border-radius: 8px;
        margin: 20px 0 12px 0;
        box-shadow: none;
        border: 1px solid #e5e8eb;
        position: relative;
        overflow: hidden;
    }
    
    .section-header::before {
        content: '';
        position: absolute;
        top: 0;
        left: 0;
        width: 4px;
        height: 100%;
        background: #3182f6;
    }
    
    .section-title {
        font-size: 16px;
        font-weight: 600;
        margin: 0;
        letter-spacing: -0.01em;
        color: #191f28;
    }
    
    .section-subtitle {
        font-size: 13px;
        color: #8b95a1;
        margin: 4px 0 0 0;
        font-weight: 400;
        letter-spacing: 0;
    }
    
    .info-panel {
        background: #f8fafe;
        border: 1px solid #e1f2ff;
        border-radius: 8px;
        padding: 16px;
        margin: 12px 0;
        position: relative;
    }
    
    .success-panel {
        background: #f0fdf4;
        border: 1px solid #dcfce7;
        border-radius: 8px;
        padding: 16px;
        margin: 12px 0;
        position: relative;
    }
    
    .warning-panel {
        background: #fffbeb;
        border: 1px solid #fed7aa;
        border-radius: 8px;
        padding: 16px;
        margin: 12px 0;
        position: relative;
    }
    
    .feature-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
        gap: 12px;
        margin: 20px 0;
    }
    
    .feature-card {
        background: white;
        border-radius: 8px;
        padding: 20px;
        text-align: center;
        box-shadow: none;
        border: 1px solid #e5e8eb;
        transition: all 0.2s ease;
        position: relative;
        overflow: hidden;
    }
    
    .feature-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(0,0,0,0.08);
        border-color: #3182f6;
    }
    
    .feature-icon {
        font-size: 32px;
        margin-bottom: 12px;
        color: #3182f6;
    }
    
    .feature-title {
        font-size: 15px;
        font-weight: 600;
        color: #191f28;
        margin-bottom: 8px;
        letter-spacing: -0.01em;
    }
    
    .feature-desc {
        font-size: 13px;
        color: #8b95a1;
        line-height: 1.5;
        letter-spacing: 0;
    }
    
    .upload-zone {
        background: white;
        border: 1px dashed #d1d5db;
        border-radius: 8px;
        padding: 24px;
        text-align: center;
        margin: 16px 0;
        transition: all 0.2s ease;
    }
    
    .upload-zone:hover {
        background: #f8fafe;
        border-color: #3182f6;
    }
    
    .progress-indicator {
        background: #3182f6;
        height: 3px;
        border-radius: 2px;
        margin: 12px 0;
        animation: pulse 2s infinite;
    }
    
    .file-status {
        background: #f8fafe;
        border-radius: 6px;
        padding: 12px;
        margin: 8px 0;
        border-left: 3px solid #3182f6;
        font-family: 'Pretendard', sans-serif;
    }
    
    .stDownloadButton > button, .stButton > button {
        background: #3182f6 !important;
        color: white !important;
        border: none !important;
        border-radius: 8px !important;
        padding: 12px 24px !important;
        font-weight: 600 !important;
        font-size: 14px !important;
        letter-spacing: -0.01em !important;
        transition: all 0.2s ease !important;
        box-shadow: 0 1px 3px rgba(0,0,0,0.1) !important;
        font-family: 'Pretendard', sans-serif !important;
    }
    
    .stDownloadButton > button:hover, .stButton > button:hover {
        background: #1c64f2 !important;
        transform: translateY(-1px) !important;
        box-shadow: 0 2px 6px rgba(0,0,0,0.15) !important;
    }
    
    .streamlit-expanderHeader {
        background: white !important;
        border-radius: 8px !important;
        border: 1px solid #e5e8eb !important;
        font-weight: 500 !important;
        color: #191f28 !important;
        font-family: 'Pretendard', sans-serif !important;
        font-size: 14px !important;
    }
    
    .stDataFrame {
        border-radius: 8px !important;
        overflow: hidden !important;
        border: 1px solid #e5e8eb !important;
    }
    
    .stSpinner {
        color: #3182f6 !important;
    }
    
    @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.6; }
    }
    
    .main .block-container {
        padding-top: 1.5rem;
        padding-bottom: 1.5rem;
        max-width: 1200px;
    }
    
    .stAlert {
        border-radius: 8px !important;
        border: none !important;
        font-family: 'Pretendard', sans-serif !important;
        font-size: 14px !important;
    }
    
    .stSuccess {
        background: #f0fdf4 !important;
        color: #15803d !important;
    }
    
    .stInfo {
        background: #f8fafe !important;
        color: #1d4ed8 !important;
    }
    
    .stWarning {
        background: #fffbeb !important;
        color: #d97706 !important;
    }
    
    .stError {
        background: #fef2f2 !important;
        color: #dc2626 !important;
    }
    
    .main-text {
        font-size: 14px;
        color: #191f28;
        line-height: 1.5;
    }
    
    .sub-text {
        font-size: 13px;
        color: #8b95a1;
        line-height: 1.4;
    }
    
    .small-text {
        font-size: 12px;
        color: #8b95a1;
        line-height: 1.3;
    }
</style>
""", unsafe_allow_html=True)


# --- ë°ì´í„° ë¡œë”© ë° íŒŒì‹± í•¨ìˆ˜ (ìˆ˜ì • ì—†ìŒ) ---
def load_and_merge_wos_files(uploaded_files):
    """ë‹¤ì¤‘ WOS Plain Text íŒŒì¼ì„ ë¡œë”©í•˜ê³  ë³‘í•© - ì¤‘ë³µ ì œê±° ì™„ì „ ìˆ˜ì •"""
    all_dataframes = []
    file_status = []
    
    for i, uploaded_file in enumerate(uploaded_files):
        try:
            file_bytes = uploaded_file.getvalue()
            encodings_to_try = ['utf-8-sig', 'utf-8', 'latin1', 'iso-8859-1']
            
            df = None
            encoding_used = None
            
            for encoding in encodings_to_try:
                try:
                    file_content = file_bytes.decode(encoding)
                    
                    # WOS ì›ë³¸ í˜•ì‹ ê²€ì¦ (FNìœ¼ë¡œ ì‹œì‘í•´ì•¼ í•¨)
                    if not file_content.strip().startswith('FN '):
                        continue
                        
                    # WOS í˜•ì‹ íŒŒì‹±
                    df = parse_wos_format(file_content)
                    if df is not None and len(df) > 0:
                        encoding_used = encoding
                        break
                        
                except Exception:
                    continue
            
            if df is not None:
                all_dataframes.append(df)
                file_status.append({
                    'filename': uploaded_file.name,
                    'status': 'SUCCESS',
                    'papers': len(df),
                    'encoding': encoding_used,
                    'message': f'âœ… {len(df)}í¸ ë…¼ë¬¸ ë¡œë”© ì„±ê³µ'
                })
            else:
                file_status.append({
                    'filename': uploaded_file.name,
                    'status': 'ERROR',
                    'papers': 0,
                    'encoding': 'N/A',
                    'message': 'âŒ WOS Plain Text í˜•ì‹ì´ ì•„ë‹˜'
                })
                
        except Exception as e:
            file_status.append({
                'filename': uploaded_file.name,
                'status': 'ERROR',
                'papers': 0,
                'encoding': 'N/A',
                'message': f'âŒ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)[:50]}'
            })
    
    # ëª¨ë“  ë°ì´í„°í”„ë ˆì„ ë³‘í•©
    if all_dataframes:
        merged_df = pd.concat(all_dataframes, ignore_index=True)
        original_count = len(merged_df)
        
        # ì¤‘ë³µ ì œê±° ë¡œì§ - ì™„ì „íˆ ìƒˆë¡œ ì‘ì„±
        duplicates_removed = 0
        
        if 'UT' in merged_df.columns:
            # UT í•„ë“œì˜ ì‹¤ì œ ê°’ë“¤ í™•ì¸
            ut_series = merged_df['UT'].copy()
            
            # ìœ íš¨í•œ UT ê°’ë§Œ í•„í„°ë§ (ë” ì—„ê²©í•œ ì¡°ê±´)
            def is_meaningful_ut(value):
                if pd.isna(value):
                    return False
                str_value = str(value).strip()
                # ë¹ˆ ë¬¸ìì—´, 'nan', 'None', ë§¤ìš° ì§§ì€ ê°’ë“¤ ì œì™¸
                if len(str_value) == 0 or str_value.lower() in ['nan', 'none', 'null', '']:
                    return False
                # WOS UTëŠ” ì¼ë°˜ì ìœ¼ë¡œ 'WOS:' ë˜ëŠ” ë¬¸ì+ìˆ«ì ì¡°í•©
                # ìµœì†Œ 10ì ì´ìƒì˜ ì˜ë¯¸ìˆëŠ” ê°’ë§Œ ìœ íš¨í•œ ê²ƒìœ¼ë¡œ ê°„ì£¼
                if len(str_value) < 10:
                    return False
                # 'WOS:' ë¡œ ì‹œì‘í•˜ê±°ë‚˜ ì¶©ë¶„íˆ ê¸´ ì˜ìˆ«ì ì¡°í•©ì¸ ê²½ìš°ë§Œ ìœ íš¨
                if str_value.startswith('WOS:') or (len(str_value) >= 15 and any(c.isalnum() for c in str_value)):
                    return True
                return False
            
            # ìœ íš¨í•œ UTë¥¼ ê°€ì§„ í–‰ë“¤ë§Œ ì„ ë³„
            meaningful_ut_mask = ut_series.apply(is_meaningful_ut)
            rows_with_meaningful_ut = merged_df[meaningful_ut_mask]
            rows_without_meaningful_ut = merged_df[~meaningful_ut_mask]
            
            # ì‹¤ì œë¡œ ì˜ë¯¸ìˆëŠ” UTê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì¤‘ë³µ ê²€ì‚¬
            if len(rows_with_meaningful_ut) > 1:  # ìµœì†Œ 2ê°œ ì´ìƒ ìˆì–´ì•¼ ì¤‘ë³µ ê²€ì‚¬ ì˜ë¯¸
                # ì¤‘ë³µ ì œê±° ì „í›„ ë¹„êµ
                before_dedup = len(rows_with_meaningful_ut)
                deduplicated_meaningful = rows_with_meaningful_ut.drop_duplicates(subset=['UT'], keep='first')
                after_dedup = len(deduplicated_meaningful)
                
                actual_duplicates = before_dedup - after_dedup
                
                if actual_duplicates > 0:
                    duplicates_removed = actual_duplicates
                    
                    # ì¤‘ë³µ ì œê±°ëœ ê²°ê³¼ì™€ UT ì—†ëŠ” í–‰ë“¤ ì¬ê²°í•©
                    merged_df = pd.concat([deduplicated_meaningful, rows_without_meaningful_ut], ignore_index=True)
        
        # ëŒ€ì•ˆ: UTê°€ ì—†ê±°ë‚˜ ì‹ ë¢°í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ì œëª©+ì €ì ê¸°ì¤€ ì¤‘ë³µ ì œê±°
        if duplicates_removed == 0 and 'TI' in merged_df.columns:
            # ì œëª©ê³¼ ì²« ë²ˆì§¸ ì €ì ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ í™•ì¸ (ë§¤ìš° ë³´ìˆ˜ì )
            title_author_before = len(merged_df)
            
            # ì œëª©ì´ ìˆê³  ì €ìê°€ ìˆëŠ” í–‰ë“¤ë§Œ ëŒ€ìƒ
            has_title = merged_df['TI'].notna() & (merged_df['TI'].str.strip() != '')
            has_author = merged_df.get('AU', pd.Series()).notna() if 'AU' in merged_df.columns else pd.Series([False] * len(merged_df))
            
            complete_rows = merged_df[has_title & has_author] if 'AU' in merged_df.columns else merged_df[has_title]
            incomplete_rows = merged_df[~(has_title & has_author)] if 'AU' in merged_df.columns else merged_df[~has_title]
            
            if len(complete_rows) > 1:
                dedup_columns = ['TI', 'AU'] if 'AU' in merged_df.columns else ['TI']
                deduplicated_complete = complete_rows.drop_duplicates(subset=dedup_columns, keep='first')
                title_author_removed = len(complete_rows) - len(deduplicated_complete)
                
                if title_author_removed > 0:
                    duplicates_removed = title_author_removed
                    merged_df = pd.concat([deduplicated_complete, incomplete_rows], ignore_index=True)
        
        return merged_df, file_status, duplicates_removed
    else:
        return None, file_status, 0

def parse_wos_format(content):
    """WOS Plain Text í˜•ì‹ì„ DataFrameìœ¼ë¡œ ë³€í™˜"""
    lines = content.split('\n')
    records = []
    current_record = {}
    current_field = None
    
    for line in lines:
        line = line.rstrip()
        
        if not line:
            continue
            
        # ë ˆì½”ë“œ ì¢…ë£Œ
        if line == 'ER':
            if current_record:
                records.append(current_record.copy())
                current_record = {}
                current_field = None
            continue
            
        # í—¤ë” ë¼ì¸ ê±´ë„ˆë›°ê¸°
        if line.startswith(('FN ', 'VR ')):
            continue
            
        # ìƒˆ í•„ë“œ ì‹œì‘
        if not line.startswith('   ') and ' ' in line:
            parts = line.split(' ', 1)
            if len(parts) == 2:
                field_tag, field_value = parts
                current_field = field_tag
                current_record[field_tag] = field_value.strip()
        
        # ê¸°ì¡´ í•„ë“œ ì—°ì†
        elif line.startswith('   ') and current_field and current_field in current_record:
            continuation_value = line[3:].strip()
            if continuation_value:
                current_record[current_field] += '; ' + continuation_value
    
    # ë§ˆì§€ë§‰ ë ˆì½”ë“œ ì²˜ë¦¬
    if current_record:
        records.append(current_record)
    
    if not records:
        return None
        
    return pd.DataFrame(records)

# --- ì‹ ê·œ: ì§€ëŠ¥í˜• ë¶„ë¥˜ í•¨ìˆ˜ ---
def classify_for_review(row):
    """
    ê·€í•˜ì˜ ìˆ˜ë™ ë¶„ë¥˜ ë¡œì§ì„ í•™ìŠµí•˜ì—¬ ë…¼ë¬¸ì„ 'Include', 'Exclude (X)', 'Consider (C)'ë¡œ ìë™ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    """
    
    def extract_text(value):
        return str(value).lower().strip() if pd.notna(value) else ""

    title = extract_text(row.get('TI', ''))
    abstract = extract_text(row.get('AB', ''))
    full_text = title + ' ' + abstract

    # --- í‚¤ì›Œë“œ ì…‹ ì •ì˜ (XCëª¨ìŒ.csv ë¶„ì„ ê¸°ë°˜) ---

    # 1. 'ë¯¸í•´ë‹¹(X)' ë¶„ë¥˜ í‚¤ì›Œë“œ
    # EC1: íŠ¹ì • ì‘ìš© ë¶„ì•¼
    exclude_domains_X = [
        'surgery', 'surgical', 'medical', 'parasitology', 'anesthesiology', 'cardiac',
        'clinical', 'otolaryngology', 'thrombectomy', 'aneurysm', 'microsurgery',
        'teaching', 'education', 'learning', 'classroom', 'student',
        'legal', 'judicial', 'law', 'court', 'justice',
        'journalism', 'politics', 'political', 'authoritarianism', 'government',
        'suicide', 'trauma', 'abuse', 'trafficking', 'violence', 'terror',
        'firearm', 'buddhist', 'deities', 'ghosts', 'geological', 'seismic', 'satellite image'
    ]
    # EC2/EC5: ìˆœìˆ˜ ê¸°ìˆ  ê³µí•™
    exclude_tech_X = [
        'p2p', 'peer-to-peer', 'network', 'protocol', 'qoe', 'qos', 'latency',
        'mpeg', 'dash', 'webrtc', 'algorithm', 'caching', 'bitrate', 'codec',
        'architecture', 'system performance', 'framework', 'traffic model',
        'packet scheduling', 'resource allocation', 'server system', 'optimization'
    ]
    # EC-Other: ëª…ë°±í•œ ë²”ìœ„ ì´íƒˆ
    exclude_other_X = ['on-demand', 'ott', 'pre-recorded', 'asynchronous', 'vod']

    # 2. 'ì¬ê²€í† (C)' ë¶„ë¥˜ í‚¤ì›Œë“œ
    # ì¸ì ‘ í”Œë«í¼ ìœ í˜•
    consider_adjacent_C = ['music streaming']
    # ê¸°ìˆ ì˜ ì „ëµì  í•¨ì˜
    consider_tech_strategy_C = ['ai', 'artificial intelligence', 'blockchain', 'gamification']
    # ì‚¬íšŒë¬¸í™” í˜„ìƒ ë¶„ì„
    consider_socio_cultural_C = ['fan', 'fandom', 'community', 'bts']
    
    # 3. ìƒíƒœê³„ ê´€ë ¨ í‚¤ì›Œë“œ (Xì™€ Cë¥¼ êµ¬ë¶„í•˜ëŠ” ê¸°ì¤€)
    ecosystem_keywords = [
        'platform', 'ecosystem', 'strategy', 'governance', 'business model', 'user',
        'consumer', 'audience', 'creator', 'streamer', 'viewer', 'community',
        'monetization', 'revenue', 'commerce', 'marketing', 'adoption', 'loyalty',
        'engagement', 'interaction', 'behavior', 'perception', 'intention', 'trust',
        'policy', 'regulation', 'ethics', 'supply chain', 'value'
    ]

    # --- ë¶„ë¥˜ ë¡œì§ ì‹¤í–‰ ---

    # 1ë‹¨ê³„: ëª…ë°±í•œ 'ë¯¸í•´ë‹¹(X)' ì‚¬ë¡€ í•„í„°ë§
    if any(keyword in full_text for keyword in exclude_domains_X):
        return 'X', 'EC1: íŠ¹ì • ì‘ìš© ë¶„ì•¼'
    if any(keyword in full_text for keyword in exclude_other_X):
        return 'X', 'EC-Other: ëª…ë°±í•œ ë²”ìœ„ ì´íƒˆ'
    
    # 2ë‹¨ê³„: 'ì¬ê²€í† (C)' ì‚¬ë¡€ í•„í„°ë§
    if any(keyword in full_text for keyword in consider_adjacent_C):
        return 'C', 'ì¸ì ‘ í”Œë«í¼ ìœ í˜•'
    if any(keyword in full_text for keyword in consider_socio_cultural_C):
        return 'C', 'ì‚¬íšŒë¬¸í™” í˜„ìƒ ë¶„ì„'

    # 3ë‹¨ê³„: ê¸°ìˆ  ë…¼ë¬¸(X/C) êµ¬ë¶„
    is_tech_topic = any(keyword in full_text for keyword in exclude_tech_X + consider_tech_strategy_C)
    is_ecosystem_topic = any(keyword in full_text for keyword in ecosystem_keywords)

    if is_tech_topic:
        if is_ecosystem_topic:
            return 'C', 'ê¸°ìˆ ì˜ ì „ëµì  í•¨ì˜' # ê¸°ìˆ  + ìƒíƒœê³„ ë…¼ì˜ = ì¬ê²€í† 
        else:
            return 'X', 'EC2/EC5: ìˆœìˆ˜ ê¸°ìˆ  ê³µí•™' # ìˆœìˆ˜ ê¸°ìˆ  ë…¼ì˜ = ë¯¸í•´ë‹¹

    # 4ë‹¨ê³„: ìœ„ ì¡°ê±´ì— ëª¨ë‘ í•´ë‹¹í•˜ì§€ ì•Šìœ¼ë©´ 'í¬í•¨'
    return 'Include', 'ì—°êµ¬ ë²”ìœ„ ë¶€í•©'


# --- ì—‘ì…€ ë³€í™˜ í•¨ìˆ˜ ---
def to_excel(df):
    output = io.BytesIO()
    writer = pd.ExcelWriter(output, engine='xlsxwriter')
    df.to_excel(writer, index=False, sheet_name='Sheet1')
    writer.close()
    processed_data = output.getvalue()
    return processed_data

# --- ë©”ì¸ UI ---
st.markdown("""
<div style="position: relative; text-align: center; padding: 2.5rem 0 3rem 0; background: linear-gradient(135deg, #3182f6, #1c64f2); color: white; border-radius: 8px; margin-bottom: 1.5rem; box-shadow: 0 2px 8px rgba(49,130,246,0.15); overflow: hidden;">
    <div style="position: absolute; top: 1rem; left: 1.5rem; color: white;">
        <div style="font-size: 12px; font-weight: 600; margin-bottom: 3px; letter-spacing: 0.3px;">HANYANG UNIVERSITY</div>
        <div style="font-size: 11px; opacity: 0.9; font-weight: 500;">Technology Management Research</div>
        <div style="font-size: 10px; opacity: 0.8; margin-top: 4px; font-weight: 400;">mot.hanyang.ac.kr</div>
    </div>
    <div style="position: absolute; top: 1rem; right: 1.5rem; text-align: right; color: rgba(255,255,255,0.9); font-size: 11px;">
        <p style="margin: 0; font-weight: 500;">Developed by: ì„íƒœê²½ (Teddy Lym)</p>
    </div>
    <h1 style="font-size: 3rem; font-weight: 700; margin-bottom: 0.3rem; letter-spacing: -0.02em;">
        WOS PREP
    </h1>
    <p style="font-size: 1.1rem; margin: 0; font-weight: 500; opacity: 0.95; letter-spacing: -0.01em;">
        SCIMAT Edition (Advanced Filtering)
    </p>
    <div style="width: 80px; height: 3px; background-color: rgba(255,255,255,0.3); margin: 1.5rem auto; border-radius: 2px;"></div>
</div>
""", unsafe_allow_html=True)


st.markdown("""
<div class="section-header">
    <div class="section-title">ğŸ“‚ ë‹¤ì¤‘ WOS Plain Text íŒŒì¼ ì—…ë¡œë“œ</div>
    <div class="section-subtitle">ë¶„ì„í•  WOS Plain Text íŒŒì¼ë“¤ì„ ëª¨ë‘ ì„ íƒí•˜ì—¬ ì—…ë¡œë“œí•˜ì„¸ìš”</div>
</div>
""", unsafe_allow_html=True)

uploaded_files = st.file_uploader(
    "WOS Plain Text íŒŒì¼ ì„ íƒ (ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)",
    type=['txt'],
    accept_multiple_files=True,
    label_visibility="collapsed"
)

if uploaded_files:
    st.markdown(f"ğŸ“‹ **ì„ íƒëœ íŒŒì¼ ê°œìˆ˜:** {len(uploaded_files)}ê°œ")
    st.markdown('<div class="progress-indicator"></div>', unsafe_allow_html=True)
    
    with st.spinner(f"ğŸ”„ {len(uploaded_files)}ê°œ WOS íŒŒì¼ ë³‘í•© ë° 1ì°¨ ìŠ¤í¬ë¦¬ë‹ ì ìš© ì¤‘..."):
        merged_df, file_status, duplicates_removed = load_and_merge_wos_files(uploaded_files)
        
        if merged_df is None:
            st.error("âš ï¸ ì²˜ë¦¬ ê°€ëŠ¥í•œ WOS Plain Text íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

        # ì§€ëŠ¥í˜• ë¶„ë¥˜ ì ìš©
        classification_results = merged_df.apply(classify_for_review, axis=1)
        merged_df[['Classification', 'Reason']] = pd.DataFrame(classification_results.tolist(), index=merged_df.index)

    st.success(f"âœ… ë³‘í•© ë° 1ì°¨ ìŠ¤í¬ë¦¬ë‹ ì™„ë£Œ! ì´ {len(merged_df):,}í¸ì˜ ë…¼ë¬¸ì´ ë¶„ë¥˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
    if duplicates_removed > 0:
        st.info(f"ğŸ”„ ì¤‘ë³µ ë…¼ë¬¸ {duplicates_removed}í¸ì´ ìë™ìœ¼ë¡œ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # --- ì‹ ê·œ: 1ì°¨ ìŠ¤í¬ë¦¬ë‹ ê²°ê³¼ ì„¹ì…˜ ---
    st.markdown("""
    <div class="section-header">
        <div class="section-title">ğŸ”¬ ì—°êµ¬ ëŒ€ìƒ 1ì°¨ ìŠ¤í¬ë¦¬ë‹ ê²°ê³¼</div>
        <div class="section-subtitle">ê·€í•˜ì˜ ë¶„ë¥˜ ê¸°ì¤€ì— ë”°ë¼ ìë™ ìƒì„±ëœ 'ë¯¸í•´ë‹¹(X)' ë° 'ì¬ê²€í† (C)' ëª©ë¡</div>
    </div>
    """, unsafe_allow_html=True)

    df_included = merged_df[merged_df['Classification'] == 'Include']
    df_excluded = merged_df[merged_df['Classification'] == 'X']
    df_to_consider = merged_df[merged_df['Classification'] == 'C']

    col1, col2, col3 = st.columns(3)
    with col1:
        st.markdown(f"""
        <div class="metric-card">
            <div>
                <div class="metric-icon" style="background: #10b981;">âœ…</div>
                <div class="metric-value">{len(df_included):,}</div>
                <div class="metric-label">ì—°êµ¬ ëŒ€ìƒ í›„ë³´ (Included)</div>
            </div>
        </div>
        """, unsafe_allow_html=True)
    with col2:
        st.markdown(f"""
        <div class="metric-card">
            <div>
                <div class="metric-icon" style="background: #ef4444;">âŒ</div>
                <div class="metric-value">{len(df_excluded):,}</div>
                <div class="metric-label">ì—°êµ¬ ë¯¸í•´ë‹¹ (Exclude - X)</div>
            </div>
        </div>
        """, unsafe_allow_html=True)
    with col3:
        st.markdown(f"""
        <div class="metric-card">
            <div>
                <div class="metric-icon" style="background: #f59e0b;">âš ï¸</div>
                <div class="metric-value">{len(df_to_consider):,}</div>
                <div class="metric-label">ì¬ê²€í†  í•„ìš” (Consider - C)</div>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
    st.markdown("---")

    # ë¯¸í•´ë‹¹(X) ëª©ë¡
    st.markdown('<h4 style="color: #dc2626;">âŒ ì—°êµ¬ ë¯¸í•´ë‹¹ (Exclude - X) ëª©ë¡</h4>', unsafe_allow_html=True)
    if not df_excluded.empty:
        st.download_button(
            label="ì—‘ì…€ ë‹¤ìš´ë¡œë“œ (X ëª©ë¡)",
            data=to_excel(df_excluded[['TI', 'AU', 'PY', 'Reason']]),
            file_name=f"excluded_papers_{len(df_excluded)}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
        st.dataframe(df_excluded[['TI', 'AU', 'PY', 'Reason']].rename(columns={
            'TI': 'ì œëª©', 'AU': 'ì €ì', 'PY': 'ë°œí–‰ì—°ë„', 'Reason': 'ë¶„ë¥˜ ì‚¬ìœ '
        }), use_container_width=True, height=300)
    else:
        st.info("ë¯¸í•´ë‹¹ìœ¼ë¡œ ë¶„ë¥˜ëœ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("<br>", unsafe_allow_html=True)

    # ì¬ê²€í† (C) ëª©ë¡
    st.markdown('<h4 style="color: #d97706;">âš ï¸ ì¬ê²€í†  í•„ìš” (Consider - C) ëª©ë¡</h4>', unsafe_allow_html=True)
    if not df_to_consider.empty:
        st.download_button(
            label="ì—‘ì…€ ë‹¤ìš´ë¡œë“œ (C ëª©ë¡)",
            data=to_excel(df_to_consider[['TI', 'AU', 'PY', 'Reason']]),
            file_name=f"consider_papers_{len(df_to_consider)}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
        st.dataframe(df_to_consider[['TI', 'AU', 'PY', 'Reason']].rename(columns={
            'TI': 'ì œëª©', 'AU': 'ì €ì', 'PY': 'ë°œí–‰ì—°ë„', 'Reason': 'ë¶„ë¥˜ ì‚¬ìœ '
        }), use_container_width=True, height=300)
    else:
        st.info("ì¬ê²€í†  í•„ìš”ë¡œ ë¶„ë¥˜ëœ ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        
    st.markdown("<br><br>", unsafe_allow_html=True)


    # --- ìµœì¢… ë¶„ì„ íŒŒì¼ ìƒì„± ì„¹ì…˜ ---
    st.markdown("""
    <div class="section-header">
        <div class="section-title">ğŸ”¥ ìµœì¢… ë¶„ì„ìš© íŒŒì¼ ìƒì„±</div>
        <div class="section-subtitle">'ì—°êµ¬ ëŒ€ìƒ í›„ë³´(Included)' ë…¼ë¬¸ë§Œìœ¼ë¡œ SCIMAT ë¶„ì„ìš© íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.</div>
    </div>
    """, unsafe_allow_html=True)

    if not df_included.empty:
        df_final_output = df_included.drop(columns=['Classification', 'Reason'], errors='ignore')
        
        # SCIMAT í˜¸í™˜ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        text_data = convert_to_scimat_wos_format(df_final_output)
        
        st.download_button(
            label=f"ğŸ”¥ SCIMAT ë¶„ì„ìš© íŒŒì¼ ë‹¤ìš´ë¡œë“œ ({len(df_final_output)}í¸)",
            data=text_data,
            file_name=f"included_for_scimat_{len(df_final_output)}_papers.txt",
            mime="text/plain",
            type="primary",
            use_container_width=True,
            key="download_final_file",
            help="1ì°¨ ìŠ¤í¬ë¦¬ë‹ì„ í†µê³¼í•œ ë…¼ë¬¸ë§Œìœ¼ë¡œ SCIMAT ë¶„ì„ìš© íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤."
        )
    else:
        st.warning("ë¶„ì„ìš© íŒŒì¼ì„ ìƒì„±í•  'ì—°êµ¬ ëŒ€ìƒ í›„ë³´' ë…¼ë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")

