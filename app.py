import streamlit as st
import pandas as pd
import nltk
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords
import re
from collections import Counter
import altair as alt
import io

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="WOS Prep | Professional Edition",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# --- ì»¤ìŠ¤í…€ CSS ìŠ¤íƒ€ì¼ (ê¸°ì¡´ê³¼ ë™ì¼) ---
st.markdown("""
<style>
    .main-container {
        background: #f8f9fa;
        min-height: 100vh;
    }
    
    .metric-card {
        background: white;
        border-radius: 12px;
        padding: 24px;
        box-shadow: 0 2px 12px rgba(0,0,0,0.08);
        border: 1px solid #e9ecef;
        margin-bottom: 16px;
        transition: all 0.3s ease;
    }
    
    .metric-card:hover {
        box-shadow: 0 4px 20px rgba(0,56,117,0.15);
        border-color: #003875;
    }
    
    .metric-value {
        font-size: 2.8rem;
        font-weight: 700;
        color: #003875;
        margin: 0;
        line-height: 1;
    }
    
    .metric-label {
        font-size: 1rem;
        color: #6c757d;
        margin: 8px 0 0 0;
        font-weight: 500;
    }
    
    .metric-icon {
        background: linear-gradient(135deg, #003875, #0056b3);
        color: white;
        width: 48px;
        height: 48px;
        border-radius: 12px;
        display: flex;
        align-items: center;
        justify-content: center;
        font-size: 1.5rem;
        margin-bottom: 16px;
    }
    
    .chart-container {
        background: white;
        border-radius: 12px;
        padding: 24px;
        box-shadow: 0 2px 12px rgba(0,0,0,0.08);
        border: 1px solid #e9ecef;
        margin: 16px 0;
    }
    
    .chart-title {
        font-size: 1.2rem;
        font-weight: 600;
        color: #212529;
        margin-bottom: 16px;
        border-bottom: 2px solid #003875;
        padding-bottom: 8px;
    }
    
    .section-header {
        background: linear-gradient(135deg, #003875, #0056b3);
        color: white;
        padding: 20px 24px;
        border-radius: 12px;
        margin: 24px 0 16px 0;
        box-shadow: 0 4px 16px rgba(0,56,117,0.2);
    }
    
    .section-title {
        font-size: 1.5rem;
        font-weight: 600;
        margin: 0;
    }
    
    .section-subtitle {
        font-size: 1rem;
        opacity: 0.9;
        margin: 4px 0 0 0;
    }
    
    .info-panel {
        background: #e8f0fe;
        border: 1px solid #003875;
        border-radius: 8px;
        padding: 16px;
        margin: 16px 0;
    }
    
    .feature-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
        gap: 20px;
        margin: 24px 0;
    }
    
    .feature-card {
        background: white;
        border-radius: 12px;
        padding: 24px;
        text-align: center;
        box-shadow: 0 2px 12px rgba(0,0,0,0.08);
        border: 1px solid #e9ecef;
        transition: all 0.3s ease;
    }
    
    .feature-card:hover {
        transform: translateY(-4px);
        box-shadow: 0 8px 24px rgba(0,56,117,0.15);
        border-color: #003875;
    }
    
    .feature-icon {
        font-size: 3rem;
        margin-bottom: 16px;
        background: linear-gradient(135deg, #003875, #0056b3);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
    }
    
    .feature-title {
        font-size: 1.2rem;
        font-weight: 600;
        color: #212529;
        margin-bottom: 8px;
    }
    
    .feature-desc {
        font-size: 0.95rem;
        color: #6c757d;
        line-height: 1.5;
    }
    
    .upload-zone {
        background: white;
        border: 2px dashed #003875;
        border-radius: 12px;
        padding: 40px;
        text-align: center;
        margin: 20px 0;
        transition: all 0.3s ease;
    }
    
    .upload-zone:hover {
        background: #f8f9fa;
        border-color: #0056b3;
    }
    
    .progress-indicator {
        background: linear-gradient(90deg, #003875, #0056b3);
        height: 4px;
        border-radius: 2px;
        margin: 16px 0;
        animation: pulse 2s infinite;
    }
    
    @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.7; }
    }
    
    .comparison-panel {
        background: linear-gradient(135deg, #f8f9fa, #ffffff);
        border: 1px solid #dee2e6;
        border-radius: 12px;
        padding: 20px;
        margin: 16px 0;
    }
</style>
""", unsafe_allow_html=True)

# --- NLTK ë¦¬ì†ŒìŠ¤ ë‹¤ìš´ë¡œë“œ (ìºì‹œ ìœ ì§€) ---
@st.cache_resource
def download_nltk_resources():
    nltk.download('punkt', quiet=True)
    nltk.download('wordnet', quiet=True)
    nltk.download('stopwords', quiet=True)
download_nltk_resources()

# --- í‚¤ì›Œë“œ ì •ê·œí™” ì‚¬ì „ (í™•ì¥ëœ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ë²„ì „) ---
def build_normalization_map():
    """ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ íŠ¹í™” ì •ê·œí™” ì‚¬ì „"""
    base_map = {
        # === ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° í•µì‹¬ ìš©ì–´ ===
        "live streaming": ["live-streaming", "live_streaming", "livestreaming", "live stream", "live streams", "real time streaming"],
        "live commerce": ["live-commerce", "live_commerce", "livestream commerce", "streaming commerce", "live shopping", "live selling"],
        "live broadcasting": ["live-broadcasting", "live_broadcasting", "live broadcast", "live broadcasts"],
        "video streaming": ["video-streaming", "video_streaming", "videostreaming", "video stream"],
        "streaming platform": ["streaming-platform", "streaming_platform", "stream platform", "streaming platforms"],
        "streaming service": ["streaming-service", "streaming_service", "stream service", "streaming services"],
        
        # === ì‚¬ìš©ì í–‰ë™ ê´€ë ¨ ===
        "user behavior": ["user-behavior", "user_behavior", "userbehavior", "user behaviour"],
        "viewer behavior": ["viewer-behavior", "viewer_behavior", "viewer behaviour"],
        "consumer behavior": ["consumer-behavior", "consumer_behavior", "consumer behaviour"],
        "streaming behavior": ["streaming-behavior", "streaming_behavior"],
        "user experience": ["user-experience", "user_experience", "ux", "userexperience"],
        "user engagement": ["user-engagement", "user_engagement", "userengagement"],
        
        # === AI/ML ê´€ë ¨ ===
        "machine learning": ["machine-learning", "machine_learning", "ml", "machinelearning"],
        "artificial intelligence": ["ai", "artificial-intelligence", "artificial_intelligence", "artificialintelligence"],
        "deep learning": ["deep-learning", "deep_learning", "deep neural networks", "deep neural network", "dnn", "deeplearning"],
        "neural networks": ["neural-networks", "neural_networks", "neuralnetworks", "neural network", "nn"],
        "natural language processing": ["nlp", "natural-language-processing", "natural_language_processing"],
        "computer vision": ["computer-vision", "computer_vision", "computervision", "cv"],
        "reinforcement learning": ["reinforcement-learning", "reinforcement_learning", "rl"],

        # === ì†Œì…œ ë¯¸ë””ì–´/í”Œë«í¼ ===
        "social media": ["social-media", "social_media", "socialmedia"],
        "social platform": ["social-platform", "social_platform", "socialplatform"],
        "digital platform": ["digital-platform", "digital_platform", "digitalplatform"],
        "content creation": ["content-creation", "content_creation", "contentcreation"],
        "digital marketing": ["digital-marketing", "digital_marketing", "digitalmarketing"],
        "e commerce": ["ecommerce", "e-commerce", "e_commerce", "electronic commerce"],

        # === ì—°êµ¬ë°©ë²•ë¡  ê´€ë ¨ ===
        "data mining": ["data-mining", "data_mining", "datamining"],
        "big data": ["big-data", "big_data", "bigdata"],
        "data analysis": ["data-analysis", "data_analysis", "dataanalysis"],
        "sentiment analysis": ["sentiment-analysis", "sentiment_analysis", "sentimentanalysis"],
        "statistical analysis": ["statistical-analysis", "statistical_analysis", "statisticalanalysis"],
        "structural equation modeling": ["sem", "pls-sem", "pls sem", "structural equation model"],

        # === ê¸°ìˆ  ê´€ë ¨ ===
        "cloud computing": ["cloud-computing", "cloud_computing", "cloudcomputing"],
        "internet of things": ["iot", "internet-of-things", "internet_of_things"],
        "mobile applications": ["mobile-applications", "mobile_applications", "mobile apps", "mobile app"],
        "web development": ["web-development", "web_development", "webdevelopment"],
        "software engineering": ["software-engineering", "software_engineering", "softwareengineering"]
    }

    # ì—­ë°©í–¥ ë§¤í•‘ ìƒì„± (variation -> standard_form)
    reverse_map = {}
    for standard_form, variations in base_map.items():
        for variation in variations:
            reverse_map[variation.lower()] = standard_form
        # í‘œì¤€ í˜•íƒœë„ ìê¸° ìì‹ ìœ¼ë¡œ ë§¤í•‘
        reverse_map[standard_form.lower()] = standard_form

    return reverse_map

NORMALIZATION_MAP = build_normalization_map()

def normalize_keyword_phrase(phrase):
    """êµ¬ë¬¸ ë‹¨ìœ„ í‚¤ì›Œë“œ ì •ê·œí™”"""
    phrase_lower = phrase.lower().strip()
    return NORMALIZATION_MAP.get(phrase_lower, phrase_lower)

# --- ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼) ---
def load_data(uploaded_file):
    file_bytes = uploaded_file.getvalue()
    encodings_to_try = ['utf-8-sig', 'utf-8', 'latin1', 'cp949']

    for encoding in encodings_to_try:
        try:
            file_content = file_bytes.decode(encoding)
            # íƒ­ êµ¬ë¶„ì ìš°ì„  ì‹œë„
            df = pd.read_csv(io.StringIO(file_content), sep='\t', lineterminator='\n')
            if df.shape[1] > 1: return df
        except Exception:
            continue

    for encoding in encodings_to_try:
        try:
            file_content = file_bytes.decode(encoding)
            # ì½¤ë§ˆ êµ¬ë¶„ì ì‹œë„
            df = pd.read_csv(io.StringIO(file_content))
            if df.shape[1] > 1: return df
        except Exception:
            continue

    return None

# --- ê°œì„ ëœ ë…¼ë¬¸ ë¶„ë¥˜ í•¨ìˆ˜ ---
def classify_article(row):
    """
    ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ë¥¼ ìœ„í•œ ê°œì„ ëœ ë¶„ë¥˜ ì•Œê³ ë¦¬ì¦˜
    - í¬ê´„ì  ì—°êµ¬ ë²”ìœ„ ì ìš©
    - ê¸°ìˆ ì  ê¸°ë°˜ ì—°êµ¬ í¬í•¨
    - ëª…í™•í•œ ì œì™¸ ê¸°ì¤€ë§Œ ì ìš©
    """
    
    # === 1ë‹¨ê³„: í•µì‹¬ í¬í•¨ í‚¤ì›Œë“œ (í™•ì¥) ===
    core_inclusion_keywords = [
        # ì§ì ‘ì  ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë°
        'live streaming', 'livestreaming', 'live stream', 'live broadcast', 'live video',
        'real time streaming', 'real-time streaming', 'streaming platform', 'streaming service',
        
        # ë¼ì´ë¸Œ ì»¤ë¨¸ìŠ¤ ë° ìƒì—…ì  í™œìš©
        'live commerce', 'live shopping', 'live selling', 'livestream commerce',
        'social commerce', 'live marketing', 'streaming monetization',
        
        # ì‚¬ìš©ì ë° ì‚¬íšŒì  ì¸¡ë©´
        'streamer', 'viewer', 'audience engagement', 'streaming audience', 'live audience',
        'streaming behavior', 'viewer behavior', 'streaming experience', 'live interaction',
        'streaming community', 'online community', 'digital community',
        
        # í”Œë«í¼ ê´€ë ¨
        'twitch', 'youtube live', 'facebook live', 'instagram live', 'tiktok live',
        'streaming media', 'video streaming', 'audio streaming', 'multimedia streaming',
        
        # êµìœ¡ ë° ì—”í„°í…Œì¸ë¨¼íŠ¸
        'live learning', 'streaming education', 'online education', 'e-learning',
        'gaming stream', 'esports', 'live gaming', 'streaming content',
        
        # ë¹„ì¦ˆë‹ˆìŠ¤ ë° ë§ˆì¼€íŒ…
        'influencer marketing', 'content creator', 'digital marketing', 'brand engagement',
        'consumer behavior', 'purchase intention', 'social influence'
    ]
    
    # === 2ë‹¨ê³„: ê¸°ìˆ ì  í¬í•¨ í‚¤ì›Œë“œ ===
    technical_inclusion_keywords = [
        'real time video', 'real-time video', 'video compression', 'video encoding',
        'adaptive streaming', 'video quality', 'streaming quality', 'latency',
        'video delivery', 'content delivery', 'cdn', 'edge computing',
        'multimedia communication', 'video communication', 'webrtc',
        'peer to peer streaming', 'p2p streaming', 'distributed streaming',
        'mobile streaming', 'mobile video', 'wireless streaming',
        'mobile broadcast', 'smartphone streaming'
    ]
    
    # === 3ë‹¨ê³„: ëª…í™•í•œ ì œì™¸ í‚¤ì›Œë“œ (ìµœì†Œí™”) ===
    clear_exclusion_keywords = [
        # ìˆœìˆ˜ ë„¤íŠ¸ì›Œí¬ í”„ë¡œí† ì½œ
        'routing protocol', 'network topology', 'packet routing', 'mac protocol', 
        'ieee 802.11', 'wimax protocol', 'lte protocol',
        
        # í•˜ë“œì›¨ì–´ ì„¤ê³„
        'vlsi design', 'circuit design', 'antenna design', 'rf circuit',
        'hardware implementation', 'fpga implementation', 'asic design',
        
        # ë¬¼ë¦¬ê³„ì¸µ ì‹ í˜¸ì²˜ë¦¬
        'signal processing algorithm', 'modulation scheme', 'channel estimation',
        'beamforming', 'mimo antenna', 'ofdm modulation',
        
        # ë¹„ê´€ë ¨ ë„ë©”ì¸
        'satellite communication', 'underwater communication', 'space communication',
        'biomedical signal', 'medical imaging', 'radar system'
    ]
    
    # === 4ë‹¨ê³„: í…ìŠ¤íŠ¸ ì¶”ì¶œ ===
    title = str(row.get('TI', '')).lower()
    source_title = str(row.get('SO', '')).lower()
    author_keywords = str(row.get('DE', '')).lower()
    keywords_plus = str(row.get('ID', '')).lower()
    abstract = str(row.get('AB', '')).lower()
    full_text = ' '.join([title, source_title, author_keywords, keywords_plus, abstract])
    
    # === 5ë‹¨ê³„: ë¶„ë¥˜ ë¡œì§ ===
    
    # 1ì°¨: ëª…í™•í•œ ì œì™¸ ëŒ€ìƒ
    if any(keyword in full_text for keyword in clear_exclusion_keywords):
        return 'Exclude (ê¸°ìˆ ì  ë¹„ê´€ë ¨)'
    
    # 2ì°¨: í•µì‹¬ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬
    if any(keyword in full_text for keyword in core_inclusion_keywords):
        return 'Include (í•µì‹¬ì—°êµ¬)'
    
    # 3ì°¨: ê¸°ìˆ ì  ê¸°ë°˜ ì—°êµ¬
    if any(keyword in full_text for keyword in technical_inclusion_keywords):
        # ì¶”ê°€ ê²€ì¦: ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°ê´€ì„±
        live_indicators = ['live', 'real time', 'real-time', 'streaming', 'broadcast', 'interactive']
        if any(indicator in full_text for indicator in live_indicators):
            return 'Include (ê¸°ìˆ ê¸°ë°˜)'
        else:
            return 'Review (ê¸°ìˆ ê²€í† )'
    
    # 4ì°¨: ì¼ë°˜ì  ê´€ë ¨ì„±
    general_keywords = [
        'social media', 'social network', 'online platform', 'digital platform',
        'user experience', 'user behavior', 'consumer behavior', 'online behavior',
        'digital marketing', 'online marketing', 'content creation', 'content sharing',
        'video content', 'multimedia content', 'interactive media'
    ]
    
    if any(keyword in full_text for keyword in general_keywords):
        return 'Review (ì¼ë°˜ê´€ë ¨)'
    
    # 5ì°¨: ê¸°íƒ€
    return 'Review (ê²€í† í•„ìš”)'

def clean_keyword_string(keywords_str, stop_words, lemmatizer):
    """SciMAT ìµœì í™”ëœ í‚¤ì›Œë“œ ì •ì œ ì²˜ë¦¬"""
    if pd.isna(keywords_str) or not isinstance(keywords_str, str):
        return ""

    # SciMAT í˜¸í™˜ íŠ¹ìˆ˜ë¬¸ì ì²˜ë¦¬
    keywords_str = re.sub(r'[^\w\s\-;]', '', keywords_str)  # ê¸°ë³¸ íŠ¹ìˆ˜ë¬¸ì ì œê±°
    keywords_str = re.sub(r'\s+', ' ', keywords_str)        # ë‹¤ì¤‘ ê³µë°± ì •ë¦¬
    
    all_keywords = keywords_str.split(';')
    cleaned_keywords = set()

    for keyword in all_keywords:
        if not keyword.strip():
            continue

        # 1ë‹¨ê³„: ê¸°ë³¸ ì •ì œ
        keyword_clean = keyword.strip().lower()
        keyword_clean = re.sub(r'[^a-z\s\-_]', '', keyword_clean)
        keyword_clean = re.sub(r'\s+', ' ', keyword_clean).strip()
        
        # ê¸¸ì´ ì œí•œ (SciMAT ê¶Œì¥)
        if len(keyword_clean) < 3 or len(keyword_clean) > 50:
            continue

        # 2ë‹¨ê³„: êµ¬ë¬¸ ë‹¨ìœ„ ì •ê·œí™”
        normalized_phrase = normalize_keyword_phrase(keyword_clean)

        # 3ë‹¨ê³„: ë‹¨ì–´ë³„ ì²˜ë¦¬ (êµ¬ë¬¸ ì •ê·œí™”ê°€ ì•ˆëœ ê²½ìš°)
        if normalized_phrase == keyword_clean.lower():
            keyword_clean = keyword_clean.replace('-', ' ').replace('_', ' ')
            words = keyword_clean.split()

            filtered_words = []
            for word in words:
                if word and len(word) > 2 and word not in stop_words:
                    lemmatized_word = lemmatizer.lemmatize(word)
                    filtered_words.append(lemmatized_word)

            if filtered_words:
                reconstructed_phrase = " ".join(filtered_words)
                final_keyword = normalize_keyword_phrase(reconstructed_phrase)
                if final_keyword and len(final_keyword) > 2:
                    cleaned_keywords.add(final_keyword)
        else:
            if normalized_phrase and len(normalized_phrase) > 2:
                cleaned_keywords.add(normalized_phrase)

    return '; '.join(sorted(list(cleaned_keywords)))

# --- SCIMAT í˜•ì‹ ë³€í™˜ í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼) ---
def convert_df_to_scimat_format(df_to_convert):
    wos_field_order = [
        'PT', 'AU', 'AF', 'TI', 'SO', 'LA', 'DT', 'DE', 'ID', 'AB', 'C1', 'C3', 'RP',
        'EM', 'RI', 'OI', 'FU', 'FX', 'CR', 'NR', 'TC', 'Z9', 'U1', 'U2', 'PU', 'PI', 'PA',
        'SN', 'EI', 'J9', 'JI', 'PD', 'PY', 'VL', 'IS', 'BP', 'EP', 'DI', 'EA', 'PG',
        'WC', 'WE', 'SC', 'GA', 'UT', 'PM', 'OA', 'DA'
    ]
    file_content = ["FN Clarivate Analytics Web of Science", "VR 1.0"]
    multi_line_fields = ['AU', 'AF', 'DE', 'ID', 'C1', 'C3', 'CR']

    for _, row in df_to_convert.iterrows():
        if len(file_content) > 2:
            file_content.append("")
        sorted_tags = [tag for tag in wos_field_order if tag in row.index and pd.notna(row[tag])]

        for tag in sorted_tags:
            value = row[tag]
            if pd.isna(value) or not str(value).strip():
                continue
            if not isinstance(value, str):
                value = str(value)

            if tag in multi_line_fields:
                items = [item.strip() for item in value.split(';') if item.strip()]
                if items:
                    file_content.append(f"{tag} {items[0]}")
                    for item in items[1:]:
                        file_content.append(f"  {item}")
            else:
                file_content.append(f"{tag} {value}")

        file_content.append("ER")
    return "\n".join(file_content).encode('utf-8')

# --- ë©”ì¸ í—¤ë” (ê¸°ì¡´ê³¼ ë™ì¼) ---
st.markdown("""
<div style="position: relative; text-align: center; padding: 2rem 0 3rem 0; background: linear-gradient(135deg, #003875, #0056b3); color: white; border-radius: 16px; margin-bottom: 2rem; box-shadow: 0 8px 32px rgba(0,56,117,0.3);">
    <div style="position: absolute; top: 1rem; left: 2rem; color: white;">
        <div style="font-size: 14px; font-weight: 600; margin-bottom: 2px;">HANYANG UNIVERSITY</div>
        <div style="font-size: 12px; opacity: 0.9;">Technology Management Research</div>
        <div style="font-size: 11px; opacity: 0.8; margin-top: 4px;">mot.hanyang.ac.kr</div>
    </div>
    <div style="position: absolute; top: 1rem; right: 2rem; text-align: right; color: rgba(255,255,255,0.9); font-size: 0.85rem;">
        <p style="margin: 0;"><strong>Developed by:</strong> ì„íƒœê²½ (Teddy Lym)</p>
    </div>
    <h1 style="font-size: 3.5rem; font-weight: 700; margin-bottom: 0.5rem; letter-spacing: -0.02em;">
        WOS Prep
    </h1>
    <p style="font-size: 1.3rem; margin: 0; font-weight: 400; opacity: 0.95;">
        Professional Tool for Web of Science Data Pre-processing (Live Streaming Research Optimized)
    </p>
    <div style="width: 100px; height: 4px; background-color: rgba(255,255,255,0.3); margin: 2rem auto; border-radius: 2px;"></div>
</div>
""", unsafe_allow_html=True)

# --- ì£¼ìš” ê¸°ëŠ¥ ì†Œê°œ ---
st.markdown("""
<div class="feature-grid">
    <div class="feature-card">
        <div class="feature-icon">ğŸ”</div>
        <div class="feature-title">ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° íŠ¹í™” ë¶„ë¥˜</div>
        <div class="feature-desc">29ë…„ ì§„í™” ì—°êµ¬ë¥¼ ìœ„í•œ í¬ê´„ì  ë…¼ë¬¸ ì„ ë³„</div>
    </div>
    <div class="feature-card">
        <div class="feature-icon">ğŸ·ï¸</div>
        <div class="feature-title">SciMAT ìµœì í™”</div>
        <div class="feature-desc">ì•ˆì •ì ì¸ ë¶„ì„ì„ ìœ„í•œ í‚¤ì›Œë“œ ì „ì²˜ë¦¬</div>
    </div>
    <div class="feature-card">
        <div class="feature-icon">ğŸ”—</div>
        <div class="feature-title">ê³„ëŸ‰ì„œì§€í•™ ì§€ì›</div>
        <div class="feature-desc">ì§€ì‹ êµ¬ì¡° ì§„í™” ë¶„ì„ ì™„ë²½ ì§€ì›</div>
    </div>
</div>
""", unsafe_allow_html=True)

# --- í‚¤ì›Œë“œ ì •ê·œí™” ê¸°ì¤€ ì„¤ëª… ---
with st.expander("â„¹ï¸ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° íŠ¹í™” ì •ê·œí™” ê¸°ì¤€", expanded=False):
    st.markdown("""
    <div class="info-panel">
        <h4 style="color: #003875; margin-bottom: 16px;">ì ìš©ë˜ëŠ” ì •ê·œí™” ê·œì¹™:</h4>
        <ul style="line-height: 1.8; color: #495057;">
            <li><strong>ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë°:</strong> live streaming â† live-streaming, livestreaming, real time streaming</li>
            <li><strong>ë¼ì´ë¸Œ ì»¤ë¨¸ìŠ¤:</strong> live commerce â† live-commerce, livestream commerce, live shopping</li>
            <li><strong>ìŠ¤íŠ¸ë¦¬ë° í”Œë«í¼:</strong> streaming platform â† streaming-platform, stream platform</li>
            <li><strong>ì‚¬ìš©ì í–‰ë™:</strong> user behavior â† user-behavior, userbehavior, user behaviour</li>
            <li><strong>AI/ML ìš©ì–´:</strong> machine learning â† machine-learning, ML, machinelearning</li>
            <li><strong>ì—°êµ¬ë°©ë²•ë¡ :</strong> structural equation modeling â† SEM, PLS-SEM</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)

# --- ê°œì„ ëœ ë¶„ë¥˜ ê¸°ì¤€ ì„¤ëª… ---
with st.expander("ğŸ¯ ê°œì„ ëœ ë¶„ë¥˜ ê¸°ì¤€ (ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ íŠ¹í™”)", expanded=False):
    st.markdown("""
    <div class="info-panel">
        <h4 style="color: #003875; margin-bottom: 16px;">í¬ê´„ì  ì—°êµ¬ ë²”ìœ„:</h4>
        <div style="display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 16px;">
            <div>
                <h5 style="color: #28a745; margin-bottom: 8px;">âœ… Include (í•µì‹¬ì—°êµ¬)</h5>
                <p style="font-size: 0.9rem; color: #495057;">ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë°, ë¼ì´ë¸Œ ì»¤ë¨¸ìŠ¤, ì‚¬ìš©ì í–‰ë™, ìŠ¤íŠ¸ë¦¬ë° í”Œë«í¼ ë“±</p>
            </div>
            <div>
                <h5 style="color: #17a2b8; margin-bottom: 8px;">ğŸ”§ Include (ê¸°ìˆ ê¸°ë°˜)</h5>
                <p style="font-size: 0.9rem; color: #495057;">ì‹¤ì‹œê°„ ë¹„ë””ì˜¤, ì ì‘í˜• ìŠ¤íŠ¸ë¦¬ë°, CDN, WebRTC ë“±</p>
            </div>
            <div>
                <h5 style="color: #ffc107; margin-bottom: 8px;">ğŸ“ Review (ì¼ë°˜ê´€ë ¨)</h5>
                <p style="font-size: 0.9rem; color: #495057;">ì†Œì…œ ë¯¸ë””ì–´, ë””ì§€í„¸ ë§ˆì¼€íŒ…, ì˜¨ë¼ì¸ í”Œë«í¼ ë“±</p>
            </div>
            <div>
                <h5 style="color: #dc3545; margin-bottom: 8px;">âŒ Exclude (ê¸°ìˆ ì  ë¹„ê´€ë ¨)</h5>
                <p style="font-size: 0.9rem; color: #495057;">ìˆœìˆ˜ í•˜ë“œì›¨ì–´, ë„¤íŠ¸ì›Œí¬ í”„ë¡œí† ì½œ, ì‹ í˜¸ì²˜ë¦¬ ë“±</p>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)

# ë‚˜ë¨¸ì§€ ì½”ë“œëŠ” ê¸°ì¡´ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€...
# (íŒŒì¼ ì—…ë¡œë“œ, ë¶„ì„ ë¡œì§, ì°¨íŠ¸ ìƒì„±, ë‹¤ìš´ë¡œë“œ ë“±)
