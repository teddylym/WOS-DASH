import streamlit as st
import pandas as pd
import altair as alt
import io
import re
from collections import Counter

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="WOS Multi-File Merger | SCIMAT Edition",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# --- í† ìŠ¤ ìŠ¤íƒ€ì¼ CSS ---
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Pretendard:wght@400;500;600;700&display=swap');
    
    .main-container {
        background: #f2f4f6;
        min-height: 100vh;
        font-family: 'Pretendard', -apple-system, BlinkMacSystemFont, system-ui, sans-serif;
    }
    
    .metric-card {
        background: white;
        border-radius: 8px;
        padding: 20px;
        box-shadow: none;
        border: 1px solid #e5e8eb;
        margin-bottom: 12px;
        transition: all 0.2s ease;
    }
    
    .metric-card:hover {
        box-shadow: 0 2px 8px rgba(0,0,0,0.08);
        transform: translateY(-1px);
        border-color: #3182f6;
    }
    
    .metric-value {
        font-size: 2.2rem;
        font-weight: 700;
        color: #191f28;
        margin: 0;
        line-height: 1.2;
        letter-spacing: -0.02em;
    }
    
    .metric-label {
        font-size: 13px;
        color: #8b95a1;
        margin: 6px 0 0 0;
        font-weight: 500;
        letter-spacing: -0.01em;
    }
    
    .metric-icon {
        background: #3182f6;
        color: white;
        width: 32px;
        height: 32px;
        border-radius: 6px;
        display: flex;
        align-items: center;
        justify-content: center;
        font-size: 16px;
        margin-bottom: 12px;
    }
    
    .chart-container {
        background: white;
        border-radius: 8px;
        padding: 24px;
        box-shadow: none;
        border: 1px solid #e5e8eb;
        margin: 16px 0;
    }
    
    .chart-title {
        font-size: 16px;
        font-weight: 600;
        color: #191f28;
        margin-bottom: 16px;
        letter-spacing: -0.01em;
    }
    
    .section-header {
        background: white;
        color: #191f28;
        padding: 16px 20px;
        border-radius: 8px;
        margin: 20px 0 12px 0;
        box-shadow: none;
        border: 1px solid #e5e8eb;
        position: relative;
        overflow: hidden;
    }
    
    .section-header::before {
        content: '';
        position: absolute;
        top: 0;
        left: 0;
        width: 4px;
        height: 100%;
        background: #3182f6;
    }
    
    .section-title {
        font-size: 16px;
        font-weight: 600;
        margin: 0;
        letter-spacing: -0.01em;
        color: #191f28;
    }
    
    .section-subtitle {
        font-size: 13px;
        color: #8b95a1;
        margin: 4px 0 0 0;
        font-weight: 400;
        letter-spacing: 0;
    }
    
    .info-panel {
        background: #f8fafe;
        border: 1px solid #e1f2ff;
        border-radius: 8px;
        padding: 16px;
        margin: 12px 0;
        position: relative;
    }
    
    .success-panel {
        background: #f0fdf4;
        border: 1px solid #dcfce7;
        border-radius: 8px;
        padding: 16px;
        margin: 12px 0;
        position: relative;
    }
    
    .warning-panel {
        background: #fffbeb;
        border: 1px solid #fed7aa;
        border-radius: 8px;
        padding: 16px;
        margin: 12px 0;
        position: relative;
    }
    
    .feature-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
        gap: 12px;
        margin: 20px 0;
    }
    
    .feature-card {
        background: white;
        border-radius: 8px;
        padding: 20px;
        text-align: center;
        box-shadow: none;
        border: 1px solid #e5e8eb;
        transition: all 0.2s ease;
        position: relative;
        overflow: hidden;
    }
    
    .feature-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(0,0,0,0.08);
        border-color: #3182f6;
    }
    
    .feature-icon {
        font-size: 32px;
        margin-bottom: 12px;
        color: #3182f6;
    }
    
    .feature-title {
        font-size: 15px;
        font-weight: 600;
        color: #191f28;
        margin-bottom: 8px;
        letter-spacing: -0.01em;
    }
    
    .feature-desc {
        font-size: 13px;
        color: #8b95a1;
        line-height: 1.5;
        letter-spacing: 0;
    }
    
    .upload-zone {
        background: white;
        border: 1px dashed #d1d5db;
        border-radius: 8px;
        padding: 24px;
        text-align: center;
        margin: 16px 0;
        transition: all 0.2s ease;
    }
    
    .upload-zone:hover {
        background: #f8fafe;
        border-color: #3182f6;
    }
    
    .progress-indicator {
        background: #3182f6;
        height: 3px;
        border-radius: 2px;
        margin: 12px 0;
        animation: pulse 2s infinite;
    }
    
    .file-status {
        background: #f8fafe;
        border-radius: 6px;
        padding: 12px;
        margin: 8px 0;
        border-left: 3px solid #3182f6;
        font-family: 'Pretendard', sans-serif;
    }
    
    .stDownloadButton > button {
        background: #3182f6 !important;
        color: white !important;
        border: none !important;
        border-radius: 8px !important;
        padding: 12px 24px !important;
        font-weight: 600 !important;
        font-size: 14px !important;
        letter-spacing: -0.01em !important;
        transition: all 0.2s ease !important;
        box-shadow: 0 1px 3px rgba(0,0,0,0.1) !important;
        font-family: 'Pretendard', sans-serif !important;
    }
    
    .stDownloadButton > button:hover {
        background: #1c64f2 !important;
        transform: translateY(-1px) !important;
        box-shadow: 0 2px 6px rgba(0,0,0,0.15) !important;
    }
    
    .streamlit-expanderHeader {
        background: white !important;
        border-radius: 8px !important;
        border: 1px solid #e5e8eb !important;
        font-weight: 500 !important;
        color: #191f28 !important;
        font-family: 'Pretendard', sans-serif !important;
        font-size: 14px !important;
    }
    
    .stDataFrame {
        border-radius: 8px !important;
        overflow: hidden !important;
        border: 1px solid #e5e8eb !important;
    }
    
    .stSpinner {
        color: #3182f6 !important;
    }
    
    @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.6; }
    }
    
    .main .block-container {
        padding-top: 1.5rem;
        padding-bottom: 1.5rem;
        max-width: 1200px;
    }
    
    .stAlert {
        border-radius: 8px !important;
        border: none !important;
        font-family: 'Pretendard', sans-serif !important;
        font-size: 14px !important;
    }
    
    .stSuccess {
        background: #f0fdf4 !important;
        color: #15803d !important;
    }
    
    .stInfo {
        background: #f8fafe !important;
        color: #1d4ed8 !important;
    }
    
    .stWarning {
        background: #fffbeb !important;
        color: #d97706 !important;
    }
    
    .stError {
        background: #fef2f2 !important;
        color: #dc2626 !important;
    }
    
    .main-text {
        font-size: 14px;
        color: #191f28;
        line-height: 1.5;
    }
    
    .sub-text {
        font-size: 13px;
        color: #8b95a1;
        line-height: 1.4;
    }
    
    .small-text {
        font-size: 12px;
        color: #8b95a1;
        line-height: 1.3;
    }
</style>
""", unsafe_allow_html=True)

# --- ë‹¤ì¤‘ WOS Plain Text íŒŒì¼ ë¡œë”© ë° ë³‘í•© í•¨ìˆ˜ ---
def load_and_merge_wos_files(uploaded_files):
    """ë‹¤ì¤‘ WOS Plain Text íŒŒì¼ì„ ë¡œë”©í•˜ê³  ë³‘í•© - ì¤‘ë³µ ì œê±° ì™„ì „ ìˆ˜ì •"""
    all_dataframes = []
    file_status = []
    
    for i, uploaded_file in enumerate(uploaded_files):
        try:
            file_bytes = uploaded_file.getvalue()
            encodings_to_try = ['utf-8-sig', 'utf-8', 'latin1', 'iso-8859-1']
            
            df = None
            encoding_used = None
            
            for encoding in encodings_to_try:
                try:
                    file_content = file_bytes.decode(encoding)
                    
                    # WOS ì›ë³¸ í˜•ì‹ ê²€ì¦ (FNìœ¼ë¡œ ì‹œì‘í•´ì•¼ í•¨)
                    if not file_content.strip().startswith('FN '):
                        continue
                        
                    # WOS í˜•ì‹ íŒŒì‹±
                    df = parse_wos_format(file_content)
                    if df is not None and len(df) > 0:
                        encoding_used = encoding
                        break
                        
                except Exception:
                    continue
            
            if df is not None:
                all_dataframes.append(df)
                file_status.append({
                    'filename': uploaded_file.name,
                    'status': 'SUCCESS',
                    'papers': len(df),
                    'encoding': encoding_used,
                    'message': f'âœ… {len(df)}í¸ ë…¼ë¬¸ ë¡œë”© ì„±ê³µ'
                })
            else:
                file_status.append({
                    'filename': uploaded_file.name,
                    'status': 'ERROR',
                    'papers': 0,
                    'encoding': 'N/A',
                    'message': 'âŒ WOS Plain Text í˜•ì‹ì´ ì•„ë‹˜'
                })
                
        except Exception as e:
            file_status.append({
                'filename': uploaded_file.name,
                'status': 'ERROR',
                'papers': 0,
                'encoding': 'N/A',
                'message': f'âŒ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)[:50]}'
            })
    
    # ëª¨ë“  ë°ì´í„°í”„ë ˆì„ ë³‘í•©
    if all_dataframes:
        merged_df = pd.concat(all_dataframes, ignore_index=True)
        original_count = len(merged_df)
        
        # ì¤‘ë³µ ì œê±° ë¡œì§ - ì™„ì „íˆ ìƒˆë¡œ ì‘ì„±
        duplicates_removed = 0
        
        if 'UT' in merged_df.columns:
            # UT í•„ë“œì˜ ì‹¤ì œ ê°’ë“¤ í™•ì¸
            ut_series = merged_df['UT'].copy()
            
            # ìœ íš¨í•œ UT ê°’ë§Œ í•„í„°ë§ (ë” ì—„ê²©í•œ ì¡°ê±´)
            def is_meaningful_ut(value):
                if pd.isna(value):
                    return False
                str_value = str(value).strip()
                # ë¹ˆ ë¬¸ìì—´, 'nan', 'None', ë§¤ìš° ì§§ì€ ê°’ë“¤ ì œì™¸
                if len(str_value) == 0 or str_value.lower() in ['nan', 'none', 'null', '']:
                    return False
                # WOS UTëŠ” ì¼ë°˜ì ìœ¼ë¡œ 'WOS:' ë˜ëŠ” ë¬¸ì+ìˆ«ì ì¡°í•©
                # ìµœì†Œ 10ì ì´ìƒì˜ ì˜ë¯¸ìˆëŠ” ê°’ë§Œ ìœ íš¨í•œ ê²ƒìœ¼ë¡œ ê°„ì£¼
                if len(str_value) < 10:
                    return False
                # 'WOS:' ë¡œ ì‹œì‘í•˜ê±°ë‚˜ ì¶©ë¶„íˆ ê¸´ ì˜ìˆ«ì ì¡°í•©ì¸ ê²½ìš°ë§Œ ìœ íš¨
                if str_value.startswith('WOS:') or (len(str_value) >= 15 and any(c.isalnum() for c in str_value)):
                    return True
                return False
            
            # ìœ íš¨í•œ UTë¥¼ ê°€ì§„ í–‰ë“¤ë§Œ ì„ ë³„
            meaningful_ut_mask = ut_series.apply(is_meaningful_ut)
            rows_with_meaningful_ut = merged_df[meaningful_ut_mask]
            rows_without_meaningful_ut = merged_df[~meaningful_ut_mask]
            
            # ì‹¤ì œë¡œ ì˜ë¯¸ìˆëŠ” UTê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì¤‘ë³µ ê²€ì‚¬
            if len(rows_with_meaningful_ut) > 1:  # ìµœì†Œ 2ê°œ ì´ìƒ ìˆì–´ì•¼ ì¤‘ë³µ ê²€ì‚¬ ì˜ë¯¸
                # ì¤‘ë³µ ì œê±° ì „í›„ ë¹„êµ
                before_dedup = len(rows_with_meaningful_ut)
                deduplicated_meaningful = rows_with_meaningful_ut.drop_duplicates(subset=['UT'], keep='first')
                after_dedup = len(deduplicated_meaningful)
                
                actual_duplicates = before_dedup - after_dedup
                
                if actual_duplicates > 0:
                    duplicates_removed = actual_duplicates
                    
                    # ì¤‘ë³µ ì œê±°ëœ ê²°ê³¼ì™€ UT ì—†ëŠ” í–‰ë“¤ ì¬ê²°í•©
                    merged_df = pd.concat([deduplicated_meaningful, rows_without_meaningful_ut], ignore_index=True)
        
        # ëŒ€ì•ˆ: UTê°€ ì—†ê±°ë‚˜ ì‹ ë¢°í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ì œëª©+ì €ì ê¸°ì¤€ ì¤‘ë³µ ì œê±°
        if duplicates_removed == 0 and 'TI' in merged_df.columns:
            # ì œëª©ê³¼ ì²« ë²ˆì§¸ ì €ì ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ í™•ì¸ (ë§¤ìš° ë³´ìˆ˜ì )
            title_author_before = len(merged_df)
            
            # ì œëª©ì´ ìˆê³  ì €ìê°€ ìˆëŠ” í–‰ë“¤ë§Œ ëŒ€ìƒ
            has_title = merged_df['TI'].notna() & (merged_df['TI'].str.strip() != '')
            has_author = merged_df.get('AU', pd.Series()).notna() if 'AU' in merged_df.columns else pd.Series([False] * len(merged_df))
            
            complete_rows = merged_df[has_title & has_author] if 'AU' in merged_df.columns else merged_df[has_title]
            incomplete_rows = merged_df[~(has_title & has_author)] if 'AU' in merged_df.columns else merged_df[~has_title]
            
            if len(complete_rows) > 1:
                dedup_columns = ['TI', 'AU'] if 'AU' in merged_df.columns else ['TI']
                deduplicated_complete = complete_rows.drop_duplicates(subset=dedup_columns, keep='first')
                title_author_removed = len(complete_rows) - len(deduplicated_complete)
                
                if title_author_removed > 0:
                    duplicates_removed = title_author_removed
                    merged_df = pd.concat([deduplicated_complete, incomplete_rows], ignore_index=True)
        
        return merged_df, file_status, duplicates_removed
    else:
        return None, file_status, 0

def parse_wos_format(content):
    """WOS Plain Text í˜•ì‹ì„ DataFrameìœ¼ë¡œ ë³€í™˜"""
    lines = content.split('\n')
    records = []
    current_record = {}
    current_field = None
    
    for line in lines:
        line = line.rstrip()
        
        if not line:
            continue
            
        # ë ˆì½”ë“œ ì¢…ë£Œ
        if line == 'ER':
            if current_record:
                records.append(current_record.copy())
                current_record = {}
                current_field = None
            continue
            
        # í—¤ë” ë¼ì¸ ê±´ë„ˆë›°ê¸°
        if line.startswith(('FN ', 'VR ')):
            continue
            
        # ìƒˆ í•„ë“œ ì‹œì‘
        if not line.startswith('   ') and ' ' in line:
            parts = line.split(' ', 1)
            if len(parts) == 2:
                field_tag, field_value = parts
                current_field = field_tag
                current_record[field_tag] = field_value.strip()
        
        # ê¸°ì¡´ í•„ë“œ ì—°ì†
        elif line.startswith('   ') and current_field and current_field in current_record:
            continuation_value = line[3:].strip()
            if continuation_value:
                current_record[current_field] += '; ' + continuation_value
    
    # ë§ˆì§€ë§‰ ë ˆì½”ë“œ ì²˜ë¦¬
    if current_record:
        records.append(current_record)
    
    if not records:
        return None
        
    return pd.DataFrame(records)

# --- ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ ë¬¸í—Œ ì„ ì • ê¸°ì¤€ ë¶„ë¥˜ í•¨ìˆ˜ ---
def classify_article(row):
    """ì—°êµ¬ëŒ€ìƒ ë…¼ë¬¸ ê¸°ì¤€(í¬í•¨ê¸°ì¤€ 1-5, ë°°ì œê¸°ì¤€ 1-5)ì„ ì ìš©í•œ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ ë¶„ë¥˜"""
    
    # í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜
    def extract_text(value):
        if pd.isna(value) or value is None:
            return ""
        return str(value).lower().strip()
    
    # í…ìŠ¤íŠ¸ í•„ë“œë³„ ì¶”ì¶œ
    title = extract_text(row.get('TI', ''))
    source_title = extract_text(row.get('SO', ''))
    author_keywords = extract_text(row.get('DE', ''))
    keywords_plus = extract_text(row.get('ID', ''))
    abstract = extract_text(row.get('AB', ''))
    document_type = extract_text(row.get('DT', ''))
    language = extract_text(row.get('LA', ''))
    year = extract_text(row.get('PY', ''))
    
    # ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©
    full_text = ' '.join([title, source_title, author_keywords, keywords_plus, abstract])
    
    # === ë°°ì œ ê¸°ì¤€ ìš°ì„  ì ìš© ===
    
    # ë°°ì œê¸°ì¤€ 3: ë¦¬ë·°, ì‚¬ì„¤, í•™íšŒ í”„ë¡œì‹œë”©
    excluded_doc_types = [
        'review', 'editorial', 'letter', 'proceedings paper', 'book chapter',
        'correction', 'erratum', 'retracted publication', 'meeting abstract',
        'conference paper', 'conference review', 'note', 'short survey'
    ]
    if any(doc_type in document_type for doc_type in excluded_doc_types):
        return 'EX3 - ë¦¬ë·°/ì‚¬ì„¤/í”„ë¡œì‹œë”©'
    
    # ë°°ì œê¸°ì¤€ 4: ë¹„ì˜ì–´ ë…¼ë¬¸
    if language and language not in ['english', 'en', '']:
        return 'EX4 - ë¹„ì˜ì–´ ë…¼ë¬¸'
    
    # ë°°ì œê¸°ì¤€ 1: ìˆœìˆ˜ ê¸°ìˆ  í”„ë¡œí† ì½œë§Œ ë‹¤ë£¬ ì—°êµ¬
    pure_technical_keywords = [
        'routing protocol', 'network protocol', 'mac protocol', 'tcp/ip', 'udp protocol',
        'video codec', 'audio codec', 'compression algorithm', 'encoding optimization',
        'network topology', 'packet routing', 'bandwidth allocation', 'buffer management',
        'cdn architecture', 'server load balancing', 'latency optimization',
        'vlsi design', 'circuit design', 'hardware implementation', 'fpga',
        'signal processing algorithm', 'channel estimation', 'modulation scheme'
    ]
    
    # ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ë§¥ë½ í‚¤ì›Œë“œ
    live_streaming_context = [
        'live streaming', 'livestreaming', 'live stream', 'live broadcast', 'live video',
        'real time streaming', 'real-time streaming', 'streaming platform', 'streaming service',
        'streamer', 'viewer', 'audience', 'interactive', 'chat', 'engagement'
    ]
    
    has_pure_technical = any(keyword in full_text for keyword in pure_technical_keywords)
    has_streaming_context = any(keyword in full_text for keyword in live_streaming_context)
    
    if has_pure_technical and not has_streaming_context:
        return 'EX1 - ìˆœìˆ˜ ê¸°ìˆ  í”„ë¡œí† ì½œ'
    
    # === í¬í•¨ ê¸°ì¤€ ì ìš© ===
    
    # í¬í•¨ê¸°ì¤€ 1: ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë°ì´ ì œëª©ì— ëª…ì‹œëœ í•µì‹¬ ì—°êµ¬
    title_streaming_keywords = [
        'live streaming', 'livestreaming', 'live stream', 'live broadcast', 'live video',
        'real time streaming', 'real-time streaming', 'streaming platform'
    ]
    
    if any(keyword in title for keyword in title_streaming_keywords):
        return 'IN1 - ì œëª© í•µì‹¬ì—°êµ¬'
    
    # í¬í•¨ê¸°ì¤€ 2: ì‹¤ì‹œê°„ ì–‘ë°©í–¥ ìƒí˜¸ì‘ìš©ì„ ë‹¤ë£¨ëŠ” ì—°êµ¬
    realtime_interaction_keywords = [
        'real-time interaction', 'real time interaction', 'interactive streaming',
        'live interaction', 'viewer interaction', 'audience interaction',
        'bidirectional', 'two-way communication', 'synchronous interaction',
        'live chat', 'live feedback', 'instant response', 'live engagement',
        'streaming engagement', 'viewer engagement', 'audience participation'
    ]
    
    streaming_general_keywords = [
        'live streaming', 'livestreaming', 'live stream', 'live broadcast',
        'streaming platform', 'streaming service', 'live video'
    ]
    
    has_realtime_interaction = any(keyword in full_text for keyword in realtime_interaction_keywords)
    has_streaming_general = any(keyword in full_text for keyword in streaming_general_keywords)
    
    if has_realtime_interaction and has_streaming_general:
        return 'IN2 - ì‹¤ì‹œê°„ ì–‘ë°©í–¥ ìƒí˜¸ì‘ìš©'
    
    # ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ê´€ë ¨ í”Œë«í¼ ë° ì„œë¹„ìŠ¤
    platform_keywords = [
        'twitch', 'youtube live', 'facebook live', 'instagram live', 'tiktok live',
        'live commerce', 'live shopping', 'live selling', 'social commerce',
        'streaming community', 'streamer', 'viewer behavior', 'streaming behavior'
    ]
    
    if any(keyword in full_text for keyword in platform_keywords):
        return 'IN2 - í”Œë«í¼ ê¸°ë°˜ ì—°êµ¬'
    
    # ë°°ì œê¸°ì¤€ 2: ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë°ì´ ì£¼ë³€ì ìœ¼ë¡œë§Œ ì–¸ê¸‰ëœ ì—°êµ¬
    # ë‹¨ìˆœ ì–¸ê¸‰ ì§€í‘œ
    peripheral_mention_indicators = [
        'for example', 'such as', 'including', 'among others',
        'future work', 'future research', 'recommendation'
    ]
    
    streaming_mentions = sum(1 for keyword in streaming_general_keywords if keyword in full_text)
    peripheral_mentions = sum(1 for indicator in peripheral_mention_indicators if indicator in full_text)
    
    # ìŠ¤íŠ¸ë¦¬ë° ì–¸ê¸‰ì´ ìˆì§€ë§Œ ì£¼ë³€ì ìœ¼ë¡œë§Œ ì–¸ê¸‰ëœ ê²½ìš°
    if streaming_mentions > 0 and peripheral_mentions >= streaming_mentions:
        return 'EX2 - ì£¼ë³€ì  ì–¸ê¸‰'
    
    # ìŠ¤íŠ¸ë¦¬ë° ê´€ë ¨ í‚¤ì›Œë“œê°€ ìˆì§€ë§Œ ëª…í™•í•˜ì§€ ì•Šì€ ê²½ìš°
    if has_streaming_general and not has_realtime_interaction:
        return 'REVIEW - ê´€ë ¨ì„± ê²€í† í•„ìš”'
    
    # ê¸°íƒ€ ë””ì§€í„¸ ë¯¸ë””ì–´ ê´€ë ¨ ì—°êµ¬ (í¬í•¨ ê°€ëŠ¥ì„± ê²€í† )
    digital_media_keywords = [
        'social media', 'digital platform', 'online video', 'video sharing',
        'user generated content', 'content creator', 'influencer marketing'
    ]
    
    if any(keyword in full_text for keyword in digital_media_keywords):
        return 'REVIEW - ë””ì§€í„¸ë¯¸ë””ì–´ ê²€í† '
    
    # ìŠ¤íŠ¸ë¦¬ë° ì–¸ê¸‰ì´ ì—†ëŠ” ê²½ìš°
    if not has_streaming_general:
        return 'EX2 - ë¼ì´ë¸ŒìŠ¤íŠ¸ë¦¬ë° ë¯¸ì–¸ê¸‰'
    
    # ê¸°íƒ€ ë¶ˆë¶„ëª…í•œ ê²½ìš°
    return 'REVIEW - ë¶„ë¥˜ ë¶ˆí™•ì‹¤' communication', 'online interaction',
        'digital identity', 'virtual identity', 'online presence', 'digital participation',
        'cultural transmission', 'digital religion', 'online religion', 'virtual religion',
        'digital migration', 'online migration', 'digital diaspora', 'virtual diaspora',
        'social cohesion', 'community building', 'social capital', 'digital divide'
    ]
    
    # COVID-19 ë° íŒ¬ë°ë¯¹ ê´€ë ¨ í‚¤ì›Œë“œ
    pandemic_keywords = [
        'covid-19', 'pandemic', 'coronavirus', 'sars-cov-2', 'lockdown', 'quarantine',
        'social distancing', 'remote work', 'work from home', 'digital adaptation',
        'pandemic response', 'crisis communication', 'emergency response'
    ]
    
    # ì†Œì…œ ë¯¸ë””ì–´ í‚¤ì›Œë“œ
    social_media_keywords = [
        'social media', 'social network', 'online platform', 'digital platform',
        'user experience', 'user behavior', 'online behavior', 'digital behavior',
        'social interaction', 'online interaction', 'digital interaction',
        'user engagement', 'digital engagement', 'platform economy', 'network effects',
        'viral content', 'content sharing', 'social sharing', 'online community'
    ]

    # í…ìŠ¤íŠ¸ ì¶”ì¶œ í•¨ìˆ˜
    def extract_text(value):
        if pd.isna(value) or value is None:
            return ""
        return str(value).lower().strip()
    
    # í…ìŠ¤íŠ¸ í•„ë“œë³„ ì¶”ì¶œ
    title = extract_text(row.get('TI', ''))
    source_title = extract_text(row.get('SO', ''))
    author_keywords = extract_text(row.get('DE', ''))
    keywords_plus = extract_text(row.get('ID', ''))
    abstract = extract_text(row.get('AB', ''))
    document_type = extract_text(row.get('DT', ''))
    
    # ì „ì²´ í…ìŠ¤íŠ¸ ê²°í•©
    full_text = ' '.join([title, source_title, author_keywords, keywords_plus, abstract])
    
    # === ì—„ê²©í•œ ë°°ì œ ê¸°ì¤€ ì ìš© (ìš°ì„ ìˆœìœ„) ===
    
    # EC6. ë¬¸ì„œ ìœ í˜• ë°°ì œ - ìµœìš°ì„  ì ìš©
    if any(doc_type in document_type for doc_type in excluded_document_types):
        return 'EC6 - ë¬¸ì„œìœ í˜• ë°°ì œ (ë¹„í•™ìˆ ë…¼ë¬¸)'
    
    # EC1. ê¸°ìˆ ì  ì „ì†¡ ë°©ì‹ì—ë§Œ êµ­í•œ - ëª…í™•í•œ ë°°ì œ
    if any(keyword in full_text for keyword in technical_only_exclusions):
        # ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ë§¥ë½ ì—†ì´ ìˆœìˆ˜ ê¸°ìˆ ë§Œ ë‹¤ë£¨ëŠ” ê²½ìš°
        has_streaming_context = any(keyword in full_text for keyword in core_streaming_keywords)
        if not has_streaming_context:
            return 'EC1 - ê¸°ìˆ ì  ì „ì†¡ë°©ì‹ë§Œ ë‹¤ë£¸'
    
    # EC7. ì¤‘ë³µ ê²Œì¬ ë…¼ë¬¸ ë°°ì œ
    if any(indicator in full_text for indicator in duplicate_indicators):
        return 'EC7 - ì¤‘ë³µê²Œì¬ ì˜ì‹¬'
    
    # EC4. ì‹¤ì‹œê°„ ì–‘ë°©í–¥ ìƒí˜¸ì‘ìš© í•„ìˆ˜ ì¡°ê±´ í™•ì¸
    has_core_streaming = any(keyword in full_text for keyword in core_streaming_keywords)
    if has_core_streaming:
        # í•µì‹¬ ìŠ¤íŠ¸ë¦¬ë° í‚¤ì›Œë“œê°€ ìˆì„ ë•Œë§Œ ìƒí˜¸ì‘ìš©ì„± ê²€ì¦
        has_interactive_element = any(keyword in full_text for keyword in interactive_realtime_keywords)
        
        if has_interactive_element:
            return 'Include - í•µì‹¬ì—°êµ¬ (ë¼ì´ë¸ŒìŠ¤íŠ¸ë¦¬ë°+ìƒí˜¸ì‘ìš©)'
        else:
            # EC5. ëª…í™•í•œ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ë§¥ë½ ë¶€ì¬ - VOD/ì¼ë°˜ ë¹„ë””ì˜¤ì™€ êµ¬ë¶„ ë¶ˆê°€
            vod_indicators = ['video on demand', 'vod', 'recorded video', 'offline video', 
                            'pre-recorded', 'asynchronous', 'non-live', 'stored video']
            if any(indicator in full_text for indicator in vod_indicators):
                return 'EC5 - ë¼ì´ë¸ŒìŠ¤íŠ¸ë¦¬ë° ë§¥ë½ ë¶€ì¬ (VOD/ì¼ë°˜ë¹„ë””ì˜¤)'
            else:
                return 'Review - ìƒí˜¸ì‘ìš©ì„± ê²€í† í•„ìš”'
    
    # EC2. í”¼ìƒì  ì–¸ê¸‰ íƒì§€
    streaming_mentions = sum(1 for keyword in core_streaming_keywords if keyword in full_text)
    superficial_mentions = sum(1 for indicator in superficial_mention_indicators if indicator in full_text)
    
    if streaming_mentions > 0 and superficial_mentions >= streaming_mentions:
        return 'EC2 - í”¼ìƒì  ì–¸ê¸‰ (í˜•ìš©ì‚¬ ìˆ˜ì¤€)'
    
    # === í¬ìš©ì  í¬í•¨ ê¸°ì¤€ ===
    
    # ë¹„ì¦ˆë‹ˆìŠ¤/ì»¤ë¨¸ìŠ¤ + ë””ì§€í„¸ ì§€í‘œ
    if any(keyword in full_text for keyword in business_commerce_keywords):
        digital_indicators = ['digital', 'online', 'internet', 'web', 'social media', 'platform', 'mobile', 'app', 'virtual', 'interactive']
        if any(indicator in full_text for indicator in digital_indicators):
            return 'Include - ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ë ¨'
    
    # êµìœ¡ + ì˜¨ë¼ì¸/ë””ì§€í„¸ ì§€í‘œ
    if any(keyword in full_text for keyword in education_keywords):
        online_indicators = ['online', 'digital', 'virtual', 'remote', 'distance', 'interactive', 'real-time', 'synchronous']
        if any(indicator in full_text for indicator in online_indicators):
            return 'Include - êµìœ¡ ê´€ë ¨'
    
    # ê¸°ìˆ ì  ê¸°ë°˜ + ë¼ì´ë¸Œ/ì‹¤ì‹œê°„ ì§€í‘œ
    if any(keyword in full_text for keyword in technical_keywords):
        live_indicators = ['live', 'real time', 'real-time', 'streaming', 'broadcast', 'interactive', 'synchronous', 'instant']
        if any(indicator in full_text for indicator in live_indicators):
            return 'Include - ê¸°ìˆ ì  ê¸°ë°˜'
    
    # ì‚¬íšŒë¬¸í™”ì  + ë””ì§€í„¸ ì§€í‘œ
    if any(keyword in full_text for keyword in sociocultural_keywords):
        digital_indicators = ['digital', 'online', 'virtual', 'internet', 'web', 'platform', 'social media']
        if any(indicator in full_text for indicator in digital_indicators):
            return 'Include - ì‚¬íšŒë¬¸í™” ê´€ë ¨'
    
    # íŒ¬ë°ë¯¹ ê´€ë ¨ + ë””ì§€í„¸ ì§€í‘œ
    if any(keyword in full_text for keyword in pandemic_keywords):
        digital_indicators = ['digital', 'online', 'virtual', 'remote', 'streaming', 'platform', 'technology']
        if any(indicator in full_text for indicator in digital_indicators):
            return 'Include - íŒ¬ë°ë¯¹ ë””ì§€í„¸í™”'
    
    # ì†Œì…œ ë¯¸ë””ì–´ ì¼ë°˜ - ì¡°ê±´ë¶€ í¬í•¨
    if any(keyword in full_text for keyword in social_media_keywords):
        interaction_indicators = ['interaction', 'engagement', 'community', 'sharing', 'content', 'creator', 'influencer']
        if any(indicator in full_text for indicator in interaction_indicators):
            return 'Include - ì†Œì…œë¯¸ë””ì–´ ê´€ë ¨'
        else:
            return 'Review - ì†Œì…œë¯¸ë””ì–´ ê²€í† '
    
    # EC3. ë¯¸ë˜ ì—°êµ¬ ì œì•ˆì—ë§Œ ì–¸ê¸‰ - ê¸°íƒ€ë¡œ ë¶„ë¥˜í•˜ì—¬ ìˆ˜ë™ ê²€í† 
    future_only_indicators = ['future work', 'future research', 'future study', 'recommendation', 'suggestion']
    if any(indicator in full_text for indicator in future_only_indicators) and streaming_mentions > 0:
        return 'EC3 - ë¯¸ë˜ì—°êµ¬ ì œì•ˆì—ë§Œ ì–¸ê¸‰'
    
    # ê¸°íƒ€ - ë¶„ë¥˜ ë¶ˆí™•ì‹¤
    return 'Review - ë¶„ë¥˜ ë¶ˆí™•ì‹¤'

# --- ë°ì´í„° í’ˆì§ˆ ì§„ë‹¨ í•¨ìˆ˜ ---
def diagnose_merged_quality(df, file_count, duplicates_removed):
    """ë³‘í•©ëœ WOS ë°ì´í„°ì˜ í’ˆì§ˆ ì§„ë‹¨ - ìˆ˜ì •ëœ ë²„ì „"""
    issues = []
    recommendations = []
    
    # í•„ìˆ˜ í•„ë“œ í™•ì¸
    required_fields = ['TI', 'AU', 'SO', 'PY']
    keyword_fields = ['DE', 'ID']
    
    for field in required_fields:
        if field not in df.columns:
            issues.append(f"âŒ í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}")
        else:
            valid_count = df[field].notna().sum()
            total_count = len(df)
            missing_rate = (total_count - valid_count) / total_count * 100
            
            if missing_rate > 10:
                issues.append(f"âš ï¸ {field} í•„ë“œì˜ {missing_rate:.1f}%ê°€ ëˆ„ë½ë¨")
    
    # í‚¤ì›Œë“œ í•„ë“œ í’ˆì§ˆ í™•ì¸
    has_keywords = False
    for field in keyword_fields:
        if field in df.columns:
            has_keywords = True
            valid_keywords = df[field].notna() & (df[field] != '') & (df[field] != 'nan')
            valid_count = valid_keywords.sum()
            total_count = len(df)
            
            if valid_count < total_count * 0.7:
                issues.append(f"âš ï¸ {field} í•„ë“œì˜ {((total_count-valid_count)/total_count*100):.1f}%ê°€ ë¹„ì–´ìˆìŒ")
    
    if not has_keywords:
        issues.append("âŒ í‚¤ì›Œë“œ í•„ë“œ ì—†ìŒ: DE ë˜ëŠ” ID í•„ë“œ í•„ìš”")
    
    # ë³‘í•© ê´€ë ¨ ì •ë³´ - ì‹¤ì œ ê²°ê³¼ë§Œ ë°˜ì˜ (ì™„ì „ ìˆ˜ì •)
    recommendations.append(f"âœ… {file_count}ê°œ íŒŒì¼ ì„±ê³µì ìœ¼ë¡œ ë³‘í•©ë¨")
    
    # ì¤‘ë³µ ì œê±° ê²°ê³¼ë§Œ ì‹¤ì œ ë°ì´í„°ì— ë”°ë¼ í‘œì‹œ
    if duplicates_removed > 0:
        recommendations.append(f"ğŸ”„ ì¤‘ë³µ ë…¼ë¬¸ {duplicates_removed}í¸ ìë™ ì œê±°ë¨")
    else:
        recommendations.append("âœ… ì¤‘ë³µ ë…¼ë¬¸ ì—†ìŒ - ëª¨ë“  ë…¼ë¬¸ì´ ê³ ìœ  ë°ì´í„°")
    
    recommendations.append("âœ… WOS Plain Text í˜•ì‹ - SCIMAT ìµœì  í˜¸í™˜ì„± í™•ë³´")
    
    return issues, recommendations

# --- WOS Plain Text í˜•ì‹ ë³€í™˜ í•¨ìˆ˜ ---
def convert_to_scimat_wos_format(df_to_convert):
    """SCIMAT ì™„ì „ í˜¸í™˜ WOS Plain Text í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    wos_field_order = [
        'PT', 'AU', 'AF', 'TI', 'SO', 'LA', 'DT', 'DE', 'ID', 'AB', 'C1', 'C3', 'RP',
        'EM', 'RI', 'OI', 'FU', 'FX', 'CR', 'NR', 'TC', 'Z9', 'U1', 'U2', 'PU', 'PI', 'PA',
        'SN', 'EI', 'J9', 'JI', 'PD', 'PY', 'VL', 'IS', 'BP', 'EP', 'DI', 'EA', 'PG',
        'WC', 'WE', 'SC', 'GA', 'UT', 'PM', 'OA', 'DA'
    ]
    
    file_content = ["FN Clarivate Analytics Web of Science", "VR 1.0"]
    multi_line_fields = ['AU', 'AF', 'DE', 'ID', 'C1', 'C3', 'CR']

    for _, row in df_to_convert.iterrows():
        if len(file_content) > 2:
            file_content.append("")
        
        for tag in wos_field_order:
            if tag in row.index and pd.notna(row[tag]) and str(row[tag]).strip() and str(row[tag]).strip().lower() != 'nan':
                value = str(row[tag]).strip()
                
                if tag in multi_line_fields:
                    items = [item.strip() for item in value.split(';') if item.strip()]
                    if items:
                        file_content.append(f"{tag} {items[0]}")
                        for item in items[1:]:
                            file_content.append(f"   {item}")
                else:
                    file_content.append(f"{tag} {value}")
        
        file_content.append("ER")
    
    return "\n".join(file_content).encode('utf-8-sig')

# --- ë©”ì¸ í—¤ë” ---
st.markdown("""
<div style="position: relative; text-align: center; padding: 2.5rem 0 3rem 0; background: linear-gradient(135deg, #3182f6, #1c64f2); color: white; border-radius: 8px; margin-bottom: 1.5rem; box-shadow: 0 2px 8px rgba(49,130,246,0.15); overflow: hidden;">
    <div style="position: absolute; top: 1rem; left: 1.5rem; color: white;">
        <div style="font-size: 12px; font-weight: 600; margin-bottom: 3px; letter-spacing: 0.3px;">HANYANG UNIVERSITY</div>
        <div style="font-size: 11px; opacity: 0.9; font-weight: 500;">Technology Management Research</div>
        <div style="font-size: 10px; opacity: 0.8; margin-top: 4px; font-weight: 400;">mot.hanyang.ac.kr</div>
    </div>
    <div style="position: absolute; top: 1rem; right: 1.5rem; text-align: right; color: rgba(255,255,255,0.9); font-size: 11px;">
        <p style="margin: 0; font-weight: 500;">Developed by: ì„íƒœê²½ (Teddy Lym)</p>
    </div>
    <h1 style="font-size: 3rem; font-weight: 700; margin-bottom: 0.3rem; letter-spacing: -0.02em;">
        WOS PREP
    </h1>
    <p style="font-size: 1.1rem; margin: 0; font-weight: 500; opacity: 0.95; letter-spacing: -0.01em;">
        SCIMAT Edition
    </p>
    <div style="width: 80px; height: 3px; background-color: rgba(255,255,255,0.3); margin: 1.5rem auto; border-radius: 2px;"></div>
</div>
""", unsafe_allow_html=True)

# --- í•µì‹¬ ê¸°ëŠ¥ ì†Œê°œ ---
st.markdown("""
<div class="feature-grid">
    <div class="feature-card">
        <div class="feature-icon">ğŸ”—</div>
        <div class="feature-title">ë‹¤ì¤‘ íŒŒì¼ ìë™ ë³‘í•©</div>
        <div class="feature-desc">ì—¬ëŸ¬ WOS íŒŒì¼ì„ í•œ ë²ˆì— ë³‘í•© ì²˜ë¦¬</div>
    </div>
    <div class="feature-card">
        <div class="feature-icon">ğŸš«</div>
        <div class="feature-title">ìŠ¤ë§ˆíŠ¸ ì¤‘ë³µ ì œê±°</div>
        <div class="feature-desc">UT ê¸°ì¤€ ìë™ ì¤‘ë³µ ë…¼ë¬¸ ê°ì§€ ë° ì œê±°</div>
    </div>
    <div class="feature-card">
        <div class="feature-icon">ğŸ¯</div>
        <div class="feature-title">í•™ìˆ ì  ì—„ë°€ì„±</div>
        <div class="feature-desc">EC1-EC7 ë°°ì œ ê¸°ì¤€ ì²´ê³„ì  ì ìš©</div>
    </div>
</div>
""", unsafe_allow_html=True)

# --- íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ ---
st.markdown("""
<div class="section-header">
    <div class="section-title">ğŸ“‚ ë‹¤ì¤‘ WOS Plain Text íŒŒì¼ ì—…ë¡œë“œ</div>
    <div class="section-subtitle">500ê°œ ë‹¨ìœ„ë¡œ ë‚˜ë‰œ ì—¬ëŸ¬ WOS íŒŒì¼ì„ ëª¨ë‘ ì„ íƒí•˜ì—¬ ì—…ë¡œë“œí•˜ì„¸ìš”</div>
</div>
""", unsafe_allow_html=True)

uploaded_files = st.file_uploader(
    "WOS Plain Text íŒŒì¼ ì„ íƒ (ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)",
    type=['txt'],
    accept_multiple_files=True,
    label_visibility="collapsed",
    help="WOS Plain Text íŒŒì¼ë“¤ì„ ë“œë˜ê·¸í•˜ì—¬ ë†“ê±°ë‚˜ í´ë¦­í•˜ì—¬ ì„ íƒí•˜ì„¸ìš”"
)

if uploaded_files:
    st.markdown(f"ğŸ“‹ **ì„ íƒëœ íŒŒì¼ ê°œìˆ˜:** {len(uploaded_files)}ê°œ")
    
    # í”„ë¡œê·¸ë ˆìŠ¤ ì¸ë””ì¼€ì´í„°
    st.markdown('<div class="progress-indicator"></div>', unsafe_allow_html=True)
    
    with st.spinner(f"ğŸ”„ {len(uploaded_files)}ê°œ WOS íŒŒì¼ ë³‘í•© ë° í•™ìˆ ì  ì—„ë°€ì„± ì ìš© ì¤‘..."):
        # íŒŒì¼ ë³‘í•©
        merged_df, file_status, duplicates_removed = load_and_merge_wos_files(uploaded_files)
        
        if merged_df is None:
            st.error("âš ï¸ ì²˜ë¦¬ ê°€ëŠ¥í•œ WOS Plain Text íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ë“¤ì´ Web of Scienceì—ì„œ ë‹¤ìš´ë¡œë“œí•œ ì •í’ˆ Plain Text íŒŒì¼ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
            
            # íŒŒì¼ë³„ ìƒíƒœ í‘œì‹œ
            st.markdown("### ğŸ“„ íŒŒì¼ë³„ ì²˜ë¦¬ ìƒíƒœ")
            for status in file_status:
                st.markdown(f"""
                <div class="file-status">
                    <strong>{status['filename']}</strong><br>
                    {status['message']}
                </div>
                """, unsafe_allow_html=True)
            st.stop()
        
        # ë…¼ë¬¸ ë¶„ë¥˜ ìˆ˜í–‰ - EC1-EC7 ë°°ì œ ê¸°ì¤€ ì ìš©
        merged_df['Classification'] = merged_df.apply(classify_article, axis=1)

    # ì„±ê³µì ì¸ íŒŒì¼ ê°œìˆ˜ ê³„ì‚°
    successful_files = len([s for s in file_status if s['status'] == 'SUCCESS'])
    total_papers = len(merged_df)
    
    st.success(f"âœ… ë³‘í•© ë° í•™ìˆ ì  ì •ì œ ì™„ë£Œ! {successful_files}ê°œ íŒŒì¼ì—ì„œ {total_papers:,}í¸ì˜ ë…¼ë¬¸ì„ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.")
    
    # ì¤‘ë³µ ì œê±° ê²°ê³¼ í‘œì‹œ - ì‹¤ì œ ê²°ê³¼ë§Œ
    if duplicates_removed > 0:
        st.info(f"ğŸ”„ ì¤‘ë³µ ë…¼ë¬¸ {duplicates_removed}í¸ì´ ìë™ìœ¼ë¡œ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤. (ì›ë³¸ ì´ {total_papers + duplicates_removed:,}í¸ â†’ ì •ì œ í›„ {total_papers:,}í¸)")
    else:
        st.info("âœ… ì¤‘ë³µ ë…¼ë¬¸ ì—†ìŒ - ëª¨ë“  ë…¼ë¬¸ì´ ê³ ìœ í•œ ë°ì´í„°ì…ë‹ˆë‹¤.")

    # --- íŒŒì¼ë³„ ì²˜ë¦¬ ìƒíƒœ ---
    st.markdown("""
    <div class="section-header">
        <div class="section-title">ğŸ“„ íŒŒì¼ë³„ ì²˜ë¦¬ ìƒíƒœ</div>
        <div class="section-subtitle">ì—…ë¡œë“œëœ ê° íŒŒì¼ì˜ ì²˜ë¦¬ ê²°ê³¼</div>
    </div>
    """, unsafe_allow_html=True)

    st.markdown("""
    <div class="chart-container">
        <div class="chart-title">ğŸ“‹ íŒŒì¼ë³„ ìƒì„¸ ìƒíƒœ</div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns([0.6, 0.4])
    
    with col1:        
        for status in file_status:
            color = "#10b981" if status['status'] == 'SUCCESS' else "#ef4444"
            icon = "âœ…" if status['status'] == 'SUCCESS' else "âŒ"
            
            st.markdown(f"""
            <div style="margin: 12px 0; padding: 16px; background: white; border-left: 4px solid {color}; border-radius: 12px; box-shadow: 0 1px 3px rgba(0,0,0,0.04);">
                <strong>{icon} {status['filename']}</strong><br>
                <small style="color: #8b95a1;">{status['message']}</small>
                {f" | ì¸ì½”ë”©: {status['encoding']}" if status['encoding'] != 'N/A' else ""}
            </div>
            """, unsafe_allow_html=True)
    
    with col2:
        # íŒŒì¼ ì²˜ë¦¬ í†µê³„
        success_count = len([s for s in file_status if s['status'] == 'SUCCESS'])
        error_count = len([s for s in file_status if s['status'] == 'ERROR'])
        
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon">âœ…</div>
            <div class="metric-value">{success_count}</div>
            <div class="metric-label">ì„±ê³µí•œ íŒŒì¼</div>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon">âŒ</div>
            <div class="metric-value">{error_count}</div>
            <div class="metric-label">ì‹¤íŒ¨í•œ íŒŒì¼</div>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("</div>", unsafe_allow_html=True)

    # --- ë°ì´í„° í’ˆì§ˆ ì§„ë‹¨ ê²°ê³¼ ---
    st.markdown("""
    <div class="section-header">
        <div class="section-title">ğŸ” ë³‘í•© ë°ì´í„° í’ˆì§ˆ ì§„ë‹¨</div>
        <div class="section-subtitle">ë³‘í•©ëœ WOS ë°ì´í„°ì˜ í’ˆì§ˆê³¼ SCIMAT í˜¸í™˜ì„± ê²€ì¦</div>
    </div>
    """, unsafe_allow_html=True)

    with st.spinner("ğŸ” ë³‘í•© ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ì¤‘..."):
        issues, recommendations = diagnose_merged_quality(merged_df, successful_files, duplicates_removed)

    st.markdown("""
    <div class="chart-container">
        <div class="chart-title">ğŸ” ë³‘í•© ë°ì´í„° í’ˆì§ˆ ì§„ë‹¨ ê²°ê³¼</div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown('<h5 style="color: #ef4444; margin-bottom: 16px;">ğŸš¨ ë°œê²¬ëœ ë¬¸ì œì </h5>', unsafe_allow_html=True)
        
        if issues:
            for issue in issues:
                st.markdown(f"- {issue}")
        else:
            st.markdown("âœ… **ë¬¸ì œì  ì—†ìŒ** - ë³‘í•© ë°ì´í„° í’ˆì§ˆ ìš°ìˆ˜")
    
    with col2:
        st.markdown('<h5 style="color: #10b981; margin-bottom: 16px;">ğŸ’¡ ë³‘í•© ê²°ê³¼</h5>', unsafe_allow_html=True)
        
        if recommendations:
            for rec in recommendations:
                st.markdown(f"- {rec}")
        else:
            st.markdown("ğŸ¯ **ìµœì  ìƒíƒœ** - SCIMAT ì™„ë²½ í˜¸í™˜")
    
    st.markdown("</div>", unsafe_allow_html=True)

    # ë³‘í•© ì„±ê³µ ì•Œë¦¼
    st.markdown("""
    <div class="success-panel">
        <h4 style="color: #065f46; margin-bottom: 20px; font-weight: 700;">ğŸ¯ ë‹¤ì¤‘ íŒŒì¼ ë³‘í•© ë° í•™ìˆ ì  ì •ì œ ì„±ê³µ!</h4>
        <p style="color: #065f46; margin: 6px 0; font-weight: 500;">ì—¬ëŸ¬ WOS Plain Text íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ í•˜ë‚˜ë¡œ ë³‘í•©ë˜ì—ˆìŠµë‹ˆë‹¤.</p>
        <p style="color: #065f46; margin: 6px 0; font-weight: 500;"><strong>í•™ìˆ ì  ì—„ë°€ì„±:</strong> EC1-EC7 ë°°ì œ ê¸°ì¤€ì„ ì²´ê³„ì ìœ¼ë¡œ ì ìš©í•˜ì—¬ ì—°êµ¬ì˜ ì‹ ë¢°ì„±ì„ í™•ë³´í–ˆìŠµë‹ˆë‹¤.</p>
        <p style="color: #065f46; margin: 6px 0; font-weight: 500;"><strong>SCIMAT í˜¸í™˜ì„±:</strong> ë³‘í•©ëœ íŒŒì¼ì€ SCIMATì—ì„œ 100% ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.</p>
    </div>
    """, unsafe_allow_html=True)

    # --- ë¶„ì„ ê²°ê³¼ ìš”ì•½ ---
    st.markdown("""
    <div class="section-header">
        <div class="section-title">ğŸ“ˆ í•™ìˆ ì  ì •ì œ ê²°ê³¼</div>
        <div class="section-subtitle">EC1-EC7 ë°°ì œ ê¸°ì¤€ ì ìš© í›„ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ ë¶„ë¥˜ ê²°ê³¼</div>
    </div>
    """, unsafe_allow_html=True)

    # ìµœì¢… ë°ì´í„°ì…‹ ì¤€ë¹„ - ìƒˆë¡œìš´ ë°°ì œ ê¸°ì¤€ ë°˜ì˜
    # EC ì½”ë“œë¡œ ì‹œì‘í•˜ëŠ” ë…¼ë¬¸ë“¤ê³¼ EXCLUDEë¡œ ì‹œì‘í•˜ëŠ” ë…¼ë¬¸ë“¤ ì™„ì „íˆ ì œì™¸
    df_excluded = merged_df[
        (merged_df['Classification'].str.startswith('EC', na=False)) |
        (merged_df['Classification'].str.startswith('EXCLUDE', na=False))
    ]
    df_for_analysis = merged_df[
        ~((merged_df['Classification'].str.startswith('EC', na=False)) |
          (merged_df['Classification'].str.startswith('EXCLUDE', na=False)))
    ].copy()
    
    # ì´ ë°°ì œëœ ë…¼ë¬¸ ìˆ˜ ê³„ì‚°
    total_excluded = len(df_excluded)
    
    # Classification ì»¬ëŸ¼ë§Œ ì œê±° (ì›ë³¸ WOS í˜•ì‹ ìœ ì§€)
    df_final_output = df_for_analysis.drop(columns=['Classification'], errors='ignore')
    
    # ë©”íŠ¸ë¦­ ì¹´ë“œë“¤
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon">ğŸ“‹</div>
            <div class="metric-value">{len(df_final_output):,}</div>
            <div class="metric-label">ìµœì¢… ë¶„ì„ ëŒ€ìƒ<br><small style="color: #8b95a1;">(ë¬¸í—Œì„ ì •ê¸°ì¤€ ì ìš©)</small></div>
        </div>
        """, unsafe_allow_html=True)
    
    include_papers = len(df_for_analysis[df_for_analysis['Classification'].str.contains('INCLUDE', na=False)])
    
    with col2:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon">âœ…</div>
            <div class="metric-value">{include_papers:,}</div>
            <div class="metric-label">í¬í•¨ ê¸°ì¤€ ì¶©ì¡±</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        processing_rate = (include_papers / len(df_final_output) * 100) if len(df_final_output) > 0 else 0
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon">ğŸ“Š</div>
            <div class="metric-value">{processing_rate:.1f}%</div>
            <div class="metric-label">í¬í•¨ ë¹„ìœ¨</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        # ë°°ì œëœ ë…¼ë¬¸ë“¤ì„ ìœ„í•œ í† ê¸€ ë²„íŠ¼ì´ ìˆëŠ” ë°•ìŠ¤
        col4_inner1, col4_inner2 = st.columns([3, 1])
        
        with col4_inner1:
            st.markdown(f"""
            <div class="metric-card">
                <div class="metric-icon">â›”</div>
                <div class="metric-value">{total_excluded:,}</div>
                <div class="metric-label">ë°°ì œ ê¸°ì¤€ ì ìš©</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col4_inner2:
            st.markdown("<div style='height: 20px;'></div>", unsafe_allow_html=True)
            if st.button(
                "ğŸ“‹", 
                key="exclude_details_button",
                help="ë°°ì œëœ ë…¼ë¬¸ ìƒì„¸ ë³´ê¸°"
            ):
                st.session_state['show_exclude_details'] = not st.session_state.get('show_exclude_details', False)

    # ë°°ì œëœ ë…¼ë¬¸ ìƒì„¸ ì •ë³´ í† ê¸€ í‘œì‹œ
    if st.session_state.get('show_exclude_details', False) and total_excluded > 0:
        st.markdown("""
        <div style="background: #fef2f2; padding: 20px; border-radius: 16px; margin: 20px 0; border: 1px solid #ef4444;">
            <h4 style="color: #dc2626; margin-bottom: 16px; font-weight: 700;">â›” ë¬¸í—Œ ì„ ì • ê¸°ì¤€ì— ë”°ë¥¸ ë°°ì œ ë…¼ë¬¸</h4>
        </div>
        """, unsafe_allow_html=True)
        
        # ë°°ì œ ê¸°ì¤€ë³„ ë¶„ë¥˜ ë° í‘œì‹œ
        exclusion_categories = {
            'EC1': 'ì‚¬íšŒ-ê¸°ìˆ ì  ë§¥ë½ ë¶€ì¬',
            'EC2': 'í•µì‹¬ ì£¼ì œì„± ë¯¸ì¶©ì¡±', 
            'EC3': 'ì¤‘ë³µ ë° ì ‘ê·¼ ë¶ˆê°€',
            'EXCLUDE': 'ê¸°íƒ€ ë°°ì œ ê¸°ì¤€'
        }
        
        # ë°°ì œ ê¸°ì¤€ë³„ í˜„í™©
        for code, description in exclusion_categories.items():
            if code == 'EXCLUDE':
                papers = merged_df[merged_df['Classification'].str.startswith('EXCLUDE', na=False)]
            else:
                papers = merged_df[merged_df['Classification'].str.startswith(code, na=False)]
            
            if len(papers) > 0:
                st.markdown(f"""
                <div style="margin: 12px 0; padding: 16px; background: white; border-left: 4px solid #ef4444; border-radius: 12px;">
                    <strong style="color: #dc2626;">{code}: {description}</strong> 
                    <span style="color: #8b95a1;">({len(papers)}í¸)</span>
                </div>
                """, unsafe_allow_html=True)
                
                # ìƒìœ„ 3í¸ë§Œ ìƒ˜í”Œë¡œ í‘œì‹œ
                for idx, (_, paper) in enumerate(papers.head(3).iterrows(), 1):
                    title = str(paper.get('TI', 'N/A'))[:80] + "..." if len(str(paper.get('TI', 'N/A'))) > 80 else str(paper.get('TI', 'N/A'))
                    year = str(paper.get('PY', 'N/A'))
                    source = str(paper.get('SO', 'N/A'))[:40] + "..." if len(str(paper.get('SO', 'N/A'))) > 40 else str(paper.get('SO', 'N/A'))
                    
                    st.markdown(f"""
                    <div style="margin: 8px 0 8px 20px; padding: 12px; background: #f9fafb; border-radius: 8px; font-size: 14px;">
                        <div style="font-weight: 500; color: #374151; margin-bottom: 4px;">{title}</div>
                        <div style="color: #6b7280; font-size: 12px;">{year} | {source}</div>
                    </div>
                    """, unsafe_allow_html=True)
                
                if len(papers) > 3:
                    st.markdown(f"<p style='color: #8b95a1; text-align: right; margin: 8px 20px 16px 20px; font-size: 12px;'>... ì™¸ {len(papers) - 3}í¸ ë”</p>", unsafe_allow_html=True)

    # ë¬¸í—Œ ì„ ì • ê¸°ì¤€ ì ìš© ê²°ê³¼ ìš”ì•½
    st.markdown(f"""
    <div class="info-panel">
        <h4 style="color: #0064ff; margin-bottom: 16px; font-weight: 700;">ğŸ“Š ë¬¸í—Œ ì„ ì • ê¸°ì¤€ ì ìš© ê²°ê³¼</h4>
        <p style="color: #0064ff; margin: 6px 0; font-weight: 500;"><strong>ì´ ì…ë ¥:</strong> {total_papers:,}í¸ì˜ ë…¼ë¬¸</p>
        <p style="color: #0064ff; margin: 6px 0; font-weight: 500;"><strong>ë°°ì œ ì ìš©:</strong> {total_excluded:,}í¸ ì œì™¸ ({(total_excluded/total_papers*100):.1f}%)</p>
        <p style="color: #0064ff; margin: 6px 0; font-weight: 500;"><strong>ìµœì¢… ë¶„ì„:</strong> {len(df_final_output):,}í¸ìœ¼ë¡œ ì •ì œëœ ê³ í’ˆì§ˆ ë°ì´í„°ì…‹</p>
        <p style="color: #0064ff; margin: 6px 0; font-weight: 500;"><strong>í¬í•¨ ê¸°ì¤€ ì¶©ì¡±:</strong> {include_papers:,}í¸ì˜ ì§ì ‘ ê´€ë ¨ ë¼ì´ë¸ŒìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬</p>
        <div style="margin-top: 12px; padding: 12px; background: rgba(0,100,255,0.1); border-radius: 8px;">
            <p style='color: #0064ff; margin: 0; font-weight: 500; font-size: 14px;'>
            ğŸ’¡ <strong>ì£¼ì œì  ê´€ë ¨ì„±, ë°©ë²•ë¡ ì  ì—„ê²©ì„±, ì‹œê°„ì  ë²”ìœ„</strong>ë¥¼ ëª¨ë‘ ì¶©ì¡±í•˜ëŠ” ì²´ê³„ì  ë¬¸í—Œ ì„ ì • ì™„ë£Œ
            </p>
        </div>
    </div>
    """, unsafe_allow_html=True)-value">{processing_rate:.1f}%</div>
            <div class="metric-label">í¬í•¨ ë¹„ìœ¨</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        # ë°°ì œëœ ë…¼ë¬¸ë“¤ì„ ìœ„í•œ í† ê¸€ ë²„íŠ¼ì´ ìˆëŠ” ë°•ìŠ¤
        col4_inner1, col4_inner2 = st.columns([3, 1])
        
        with col4_inner1:
            st.markdown(f"""
            <div class="metric-card">
                <div class="metric-icon">â›”</div>
                <div class="metric-value">{total_excluded:,}</div>
                <div class="metric-label">í•™ìˆ ì  ë°°ì œ</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col4_inner2:
            st.markdown("<div style='height: 20px;'></div>", unsafe_allow_html=True)
            if st.button(
                "ğŸ“‹", 
                key="exclude_details_button",
                help="ë°°ì œëœ ë…¼ë¬¸ ìƒì„¸ ë³´ê¸°"
            ):
                st.session_state['show_exclude_details'] = not st.session_state.get('show_exclude_details', False)

    # ë°°ì œëœ ë…¼ë¬¸ ìƒì„¸ ì •ë³´ í† ê¸€ í‘œì‹œ
    if st.session_state.get('show_exclude_details', False) and total_excluded > 0:
        st.markdown("""
        <div style="background: #fef2f2; padding: 20px; border-radius: 16px; margin: 20px 0; border: 1px solid #ef4444;">
            <h4 style="color: #dc2626; margin-bottom: 16px; font-weight: 700;">â›” í•™ìˆ ì  ë°°ì œ ê¸°ì¤€ì— ë”°ë¥¸ ì œì™¸ ë…¼ë¬¸</h4>
        </div>
        """, unsafe_allow_html=True)
        
        # ë°°ì œ ê¸°ì¤€ë³„ ë¶„ë¥˜ ë° í‘œì‹œ
        exclusion_categories = {
            'EC1': 'ê¸°ìˆ ì  ì „ì†¡ë°©ì‹ë§Œ ë‹¤ë£¸',
            'EC2': 'í”¼ìƒì  ì–¸ê¸‰ (í˜•ìš©ì‚¬ ìˆ˜ì¤€)',
            'EC3': 'ë¯¸ë˜ì—°êµ¬ ì œì•ˆì—ë§Œ ì–¸ê¸‰',
            'EC4': 'ì‹¤ì‹œê°„ ì–‘ë°©í–¥ ìƒí˜¸ì‘ìš© ë¯¸ê³ ë ¤',
            'EC5': 'ë¼ì´ë¸ŒìŠ¤íŠ¸ë¦¬ë° ë§¥ë½ ë¶€ì¬',
            'EC6': 'ë¬¸ì„œìœ í˜• ë°°ì œ (ë¹„í•™ìˆ ë…¼ë¬¸)',
            'EC7': 'ì¤‘ë³µê²Œì¬ ì˜ì‹¬'
        }
        
        # EC ê¸°ì¤€ë³„ ë°°ì œ í˜„í™©
        for ec_code, description in exclusion_categories.items():
            ec_papers = merged_df[merged_df['Classification'].str.startswith(ec_code, na=False)]
            if len(ec_papers) > 0:
                st.markdown(f"""
                <div style="margin: 12px 0; padding: 16px; background: white; border-left: 4px solid #ef4444; border-radius: 12px;">
                    <strong style="color: #dc2626;">{ec_code}: {description}</strong> 
                    <span style="color: #8b95a1;">({len(ec_papers)}í¸)</span>
                </div>
                """, unsafe_allow_html=True)
                
                # ìƒìœ„ 5í¸ë§Œ ìƒ˜í”Œë¡œ í‘œì‹œ
                for idx, (_, paper) in enumerate(ec_papers.head(5).iterrows(), 1):
                    title = str(paper.get('TI', 'N/A'))[:80] + "..." if len(str(paper.get('TI', 'N/A'))) > 80 else str(paper.get('TI', 'N/A'))
                    year = str(paper.get('PY', 'N/A'))
                    source = str(paper.get('SO', 'N/A'))[:40] + "..." if len(str(paper.get('SO', 'N/A'))) > 40 else str(paper.get('SO', 'N/A'))
                    
                    st.markdown(f"""
                    <div style="margin: 8px 0 8px 20px; padding: 12px; background: #f9fafb; border-radius: 8px; font-size: 14px;">
                        <div style="font-weight: 500; color: #374151; margin-bottom: 4px;">{title}</div>
                        <div style="color: #6b7280; font-size: 12px;">{year} | {source}</div>
                    </div>
                    """, unsafe_allow_html=True)
                
                if len(ec_papers) > 5:
                    st.markdown(f"<p style='color: #8b95a1; text-align: right; margin: 8px 20px 16px 20px; font-size: 12px;'>... ì™¸ {len(ec_papers) - 5}í¸ ë”</p>", unsafe_allow_html=True)

    # ë°°ì œ ê¸°ì¤€ ì ìš© ê²°ê³¼ ìš”ì•½
    st.markdown(f"""
    <div class="info-panel">
        <h4 style="color: #0064ff; margin-bottom: 16px; font-weight: 700;">ğŸ“Š í•™ìˆ ì  ì—„ë°€ì„± í™•ë³´</h4>
        <p style="color: #0064ff; margin: 6px 0; font-weight: 500;"><strong>ì´ ì…ë ¥:</strong> {total_papers:,}í¸ì˜ ë…¼ë¬¸</p>
        <p style="color: #0064ff; margin: 6px 0; font-weight: 500;"><strong>ë°°ì œ ì ìš©:</strong> {total_excluded:,}í¸ ì œì™¸ ({(total_excluded/total_papers*100):.1f}%)</p>
        <p style="color: #0064ff; margin: 6px 0; font-weight: 500;"><strong>ìµœì¢… ë¶„ì„:</strong> {len(df_final_output):,}í¸ìœ¼ë¡œ ì •ì œëœ ê³ í’ˆì§ˆ ë°ì´í„°ì…‹</p>
        <p style="color: #0064ff; margin: 6px 0; font-weight: 500;"><strong>í•µì‹¬ ì—°êµ¬:</strong> {include_papers:,}í¸ì˜ ì§ì ‘ ê´€ë ¨ ë¼ì´ë¸ŒìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ í™•ë³´</p>
    </div>
    """, unsafe_allow_html=True)

    # --- ë…¼ë¬¸ ë¶„ë¥˜ í˜„í™© ---
    st.markdown("""
    <div class="chart-container">
        <div class="chart-title">ë¬¸í—Œ ì„ ì • ê¸°ì¤€ ì ìš© í›„ ì—°êµ¬ ë¶„ë¥˜ ë¶„í¬</div>
    """, unsafe_allow_html=True)

    classification_counts_df = df_for_analysis['Classification'].value_counts().reset_index()
    classification_counts_df.columns = ['ë¶„ë¥˜', 'ë…¼ë¬¸ ìˆ˜']

    col1, col2 = st.columns([0.4, 0.6])
    with col1:
        st.dataframe(classification_counts_df, use_container_width=True, hide_index=True)

    with col2:
        # ë„ë„› ì°¨íŠ¸
        selection = alt.selection_point(fields=['ë¶„ë¥˜'], on='mouseover', nearest=True)

        base = alt.Chart(classification_counts_df).encode(
            theta=alt.Theta(field="ë…¼ë¬¸ ìˆ˜", type="quantitative", stack=True),
            color=alt.Color(field="ë¶„ë¥˜", type="nominal", title="Classification",
                           scale=alt.Scale(range=['#0064ff', '#0050cc', '#10b981', '#f59e0b', '#8b5cf6']),
                           legend=alt.Legend(orient="right", titleColor="#191f28", labelColor="#8b95a1")),
            opacity=alt.condition(selection, alt.value(1), alt.value(0.8))
        ).add_params(selection)

        pie = base.mark_arc(outerRadius=150, innerRadius=90)
        text_total = alt.Chart(pd.DataFrame([{'value': f'{len(df_final_output)}'}])).mark_text(
            align='center', baseline='middle', fontSize=45, fontWeight='bold', color='#0064ff'
        ).encode(text='value:N')
        text_label = alt.Chart(pd.DataFrame([{'value': 'Selected Papers'}])).mark_text(
            align='center', baseline='middle', fontSize=16, dy=30, color='#8b95a1'
        ).encode(text='value:N')

        chart = (pie + text_total + text_label).properties(
            width=350, height=350
        ).configure_view(strokeWidth=0)
        st.altair_chart(chart, use_container_width=True)

    st.markdown("</div>", unsafe_allow_html=True)

    # --- ë¶„ë¥˜ ìƒì„¸ ê²°ê³¼ ---
    st.markdown("""
    <div class="chart-container">
        <div class="chart-title">ë¶„ë¥˜ë³„ ìƒì„¸ ë¶„í¬ (ë¬¸í—Œ ì„ ì • ê¸°ì¤€ ì ìš© í›„)</div>
    """, unsafe_allow_html=True)
    
    # ë¶„ë¥˜ë³„ ìƒì„¸ í†µê³„ (ë°°ì œ ì œì™¸)
    for classification in df_for_analysis['Classification'].unique():
        count = len(df_for_analysis[df_for_analysis['Classification'] == classification])
        percentage = (count / len(df_final_output) * 100) if len(df_final_output) > 0 else 0
        
        if classification.startswith('INCLUDE'):
            color = "#10b981"
            icon = "âœ…"
        elif classification.startswith('REVIEW'):
            color = "#f59e0b"
            icon = "ğŸ”"
        else:
            color = "#8b5cf6"
            icon = "â“"
        
        st.markdown(f"""
        <div style="margin: 16px 0; padding: 20px; background: white; border-left: 4px solid {color}; border-radius: 12px; font-size: 16px; box-shadow: 0 1px 3px rgba(0,0,0,0.04);">
            <strong>{icon} {classification}:</strong> {count:,}í¸ ({percentage:.1f}%)
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("</div>", unsafe_allow_html=True)

    # --- ì—°ë„ë³„ ì—°êµ¬ ë™í–¥ ---
    if 'PY' in df_final_output.columns:
        st.markdown("""
        <div class="chart-container">
            <div class="chart-title">ì„ ì •ëœ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ ë™í–¥ (1996-2024)</div>
        """, unsafe_allow_html=True)
        
        df_trend = df_final_output.copy()
        df_trend['PY'] = pd.to_numeric(df_trend['PY'], errors='coerce')
        df_trend.dropna(subset=['PY'], inplace=True)
        df_trend['PY'] = df_trend['PY'].astype(int)
        
        yearly_counts = df_trend['PY'].value_counts().reset_index()
        yearly_counts.columns = ['Year', 'Count']
        yearly_counts = yearly_counts[(yearly_counts['Year'] >= 1996) & (yearly_counts['Year'] <= 2024)].sort_values('Year')

        if len(yearly_counts) > 0:
            line_chart = alt.Chart(yearly_counts).mark_line(
                point={'size': 80, 'filled': True}, strokeWidth=3, color='#0064ff'
            ).encode(
                x=alt.X('Year:O', title='ë°œí–‰ ì—°ë„'),
                y=alt.Y('Count:Q', title='ë…¼ë¬¸ ìˆ˜'),
                tooltip=['Year', 'Count']
            ).properties(height=300)
            
            st.altair_chart(line_chart, use_container_width=True)
        
        st.markdown("</div>", unsafe_allow_html=True)

    # --- í‚¤ì›Œë“œ ìƒ˜í”Œ í™•ì¸ ---
    st.markdown("""
    <div class="chart-container">
        <div class="chart-title">ì„ ì •ëœ ì—°êµ¬ì˜ í‚¤ì›Œë“œ í’ˆì§ˆ í™•ì¸</div>
    """, unsafe_allow_html=True)
    
    sample_data = []
    sample_rows = df_for_analysis[df_for_analysis['Classification'].str.contains('INCLUDE', na=False)].head(3)
    
    for idx, row in sample_rows.iterrows():
        title = str(row.get('TI', 'N/A'))[:80] + "..." if len(str(row.get('TI', 'N/A'))) > 80 else str(row.get('TI', 'N/A'))
        de_keywords = str(row.get('DE', 'N/A')) if pd.notna(row.get('DE')) else 'N/A'
        id_keywords = str(row.get('ID', 'N/A')) if pd.notna(row.get('ID')) else 'N/A'
        
        # í‚¤ì›Œë“œ ê°œìˆ˜ ê³„ì‚°
        de_count = len([k.strip() for k in de_keywords.split(';') if k.strip()]) if de_keywords != 'N/A' else 0
        id_count = len([k.strip() for k in id_keywords.split(';') if k.strip()]) if id_keywords != 'N/A' else 0
        
        sample_data.append({
            'ë…¼ë¬¸ ì œëª©': title,
            'DE í‚¤ì›Œë“œ': de_keywords[:100] + "..." if len(de_keywords) > 100 else de_keywords,
            'ID í‚¤ì›Œë“œ': id_keywords[:100] + "..." if len(id_keywords) > 100 else id_keywords,
            'DE ê°œìˆ˜': de_count,
            'ID ê°œìˆ˜': id_count
        })
    
    if sample_data:
        sample_df = pd.DataFrame(sample_data)
        st.dataframe(sample_df, use_container_width=True, hide_index=True)
        
        # í‚¤ì›Œë“œ í’ˆì§ˆ í‰ê°€
        avg_de = sum([d['DE ê°œìˆ˜'] for d in sample_data]) / len(sample_data) if sample_data else 0
        avg_id = sum([d['ID ê°œìˆ˜'] for d in sample_data]) / len(sample_data) if sample_data else 0
        
        if avg_de >= 3 and avg_id >= 3:
            st.success("âœ… í‚¤ì›Œë“œ í’ˆì§ˆ ìš°ìˆ˜ - SCIMATì—ì„œ ì›í™œí•œ ê·¸ë£¨í•‘ ì˜ˆìƒ")
        elif avg_de >= 2 or avg_id >= 2:
            st.warning("âš ï¸ í‚¤ì›Œë“œ í’ˆì§ˆ ë³´í†µ - SCIMATì—ì„œ ì¼ë¶€ ì œí•œ ê°€ëŠ¥")
        else:
            st.error("âŒ í‚¤ì›Œë“œ í’ˆì§ˆ ë¶€ì¡± - ì›ë³¸ WOS ë‹¤ìš´ë¡œë“œ ì„¤ì • í™•ì¸ í•„ìš”")

    st.markdown("</div>", unsafe_allow_html=True)

    # ë¶„ë¥˜ë³„ ë…¼ë¬¸ ìƒì„¸ ëª©ë¡ - Reviewë§Œ í† ê¸€ë¡œ ìœ ì§€
    review_papers = df_for_analysis[df_for_analysis['Classification'].str.contains('REVIEW', na=False)]
    
    if len(review_papers) > 0:
        with st.expander(f"ğŸ” REVIEW (ì¶”ê°€ ê²€í†  í•„ìš”) - ë…¼ë¬¸ ëª©ë¡ ({len(review_papers)}í¸)", expanded=False):
            st.markdown("""
            <div style="background: #fffbeb; padding: 16px; border-radius: 12px; margin-bottom: 20px; border: 1px solid #f59e0b;">
                <strong style="color: #92400e;">ğŸ“‹ ê²€í†  ì•ˆë‚´:</strong> ì•„ë˜ ë…¼ë¬¸ë“¤ì€ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ì™€ì˜ ê´€ë ¨ì„±ì„ ì¶”ê°€ ê²€í† ê°€ í•„ìš”í•œ ë…¼ë¬¸ë“¤ì…ë‹ˆë‹¤.
                ì œëª©ê³¼ ì´ˆë¡ì„ í™•ì¸í•˜ì—¬ í¬í•¨ê¸°ì¤€ ì¶©ì¡± ì—¬ë¶€ë¥¼ ìµœì¢… íŒë‹¨í•˜ì„¸ìš”.
            </div>
            """, unsafe_allow_html=True)
            
            # Review ë…¼ë¬¸ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            review_excel_data = []
            for idx, (_, paper) in enumerate(review_papers.iterrows(), 1):
                review_excel_data.append({
                    'ë²ˆí˜¸': idx,
                    'ë…¼ë¬¸ ì œëª©': str(paper.get('TI', 'N/A')),
                    'ì¶œíŒì—°ë„': str(paper.get('PY', 'N/A')),
                    'ì €ë„ëª…': str(paper.get('SO', 'N/A')),
                    'ì €ì': str(paper.get('AU', 'N/A')),
                    'ë¶„ë¥˜': str(paper.get('Classification', 'N/A')),
                    'ì €ì í‚¤ì›Œë“œ': str(paper.get('DE', 'N/A')),
                    'WOS í‚¤ì›Œë“œ': str(paper.get('ID', 'N/A')),
                    'ì´ˆë¡': str(paper.get('AB', 'N/A')),
                    'ë¬¸ì„œìœ í˜•': str(paper.get('DT', 'N/A'))
                })
            
            review_excel_df = pd.DataFrame(review_excel_data)
            
            # ì—‘ì…€ íŒŒì¼ ìƒì„±
            excel_buffer = io.BytesIO()
            with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                review_excel_df.to_excel(writer, sheet_name='Review_Papers', index=False)
            excel_data = excel_buffer.getvalue()
            
            st.download_button(
                label="ğŸ“Š ê²€í†  ë…¼ë¬¸ ëª©ë¡ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
                data=excel_data,
                file_name=f"review_papers_systematic_{len(review_papers)}í¸.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                type="secondary",
                use_container_width=True
            )
            
            st.markdown("<br>", unsafe_allow_html=True)
            
            for idx, (_, paper) in enumerate(review_papers.iterrows(), 1):
                title = str(paper.get('TI', 'N/A'))
                year = str(paper.get('PY', 'N/A'))
                source = str(paper.get('SO', 'N/A'))
                classification = str(paper.get('Classification', 'N/A'))
                
                # ë¶„ë¥˜ë³„ ìƒ‰ìƒ ì„¤ì •
                if 'ìƒí˜¸ì‘ìš©ì„±' in classification:
                    badge_color = "#f97316"
                    badge_text = "ìƒí˜¸ì‘ìš©ì„± ê²€í† "
                elif 'ê´€ë ¨ì„±' in classification:
                    badge_color = "#06b6d4"
                    badge_text = "ê´€ë ¨ì„± ê²€í† "
                elif 'ë¶ˆí™•ì‹¤' in classification:
                    badge_color = "#8b5cf6"
                    badge_text = "ë¶„ë¥˜ ë¶ˆí™•ì‹¤"
                else:
                    badge_color = "#f59e0b"
                    badge_text = "ê¸°íƒ€ ê²€í† "
                
                st.markdown(f"""
                <div style="margin: 12px 0; padding: 16px; background: white; border-left: 4px solid #f59e0b; border-radius: 12px; box-shadow: 0 1px 3px rgba(0,0,0,0.04);">
                    <div style="display: flex; align-items: center; margin-bottom: 8px;">
                        <span style="background: {badge_color}; color: white; padding: 4px 12px; border-radius: 16px; font-size: 12px; margin-right: 12px; font-weight: 600;">{badge_text}</span>
                        <span style="color: #8b95a1; font-size: 14px;">#{idx}</span>
                    </div>
                    <div style="font-weight: 600; color: #191f28; margin-bottom: 6px; line-height: 1.5;">
                        {title}
                    </div>
                    <div style="font-size: 14px; color: #8b95a1;">
                        <strong>ì—°ë„:</strong> {year} | <strong>ì €ë„:</strong> {source}
                    </div>
                </div>
                """, unsafe_allow_html=True)

    # ë¬¸í—Œ ì„ ì • ì„±ê³¼ ê°•ì¡°
    success_info = []
    success_info.append(f"<strong>íŒŒì¼ í†µí•©:</strong> {successful_files}ê°œì˜ WOS íŒŒì¼ì„ í•˜ë‚˜ë¡œ ë³‘í•©")
    
    if duplicates_removed > 0:
        success_info.append(f"<strong>ì¤‘ë³µ ì œê±°:</strong> {duplicates_removed}í¸ì˜ ì¤‘ë³µ ë…¼ë¬¸ ìë™ ê°ì§€ ë° ì œê±°")
    
    success_info.append(f"<strong>ì²´ê³„ì  ë¬¸í—Œ ì„ ì •:</strong> ì£¼ì œì  ê´€ë ¨ì„±, ë°©ë²•ë¡ ì  ì—„ê²©ì„±, ì‹œê°„ì  ë²”ìœ„ ê¸°ì¤€ ì ìš©ìœ¼ë¡œ {total_excluded}í¸ ë°°ì œ")
    success_info.append(f"<strong>ìµœì¢… ê·œëª¨:</strong> {len(df_final_output):,}í¸ì˜ ê³ í’ˆì§ˆ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ë¡œ ì •ì œ")
    success_info.append(f"<strong>í¬í•¨ ê¸°ì¤€ ì¶©ì¡±:</strong> {include_papers}í¸ì˜ ì§ì ‘ ê´€ë ¨ ì—°êµ¬ í™•ë³´")
    success_info.append("<strong>SCIMAT í˜¸í™˜:</strong> ì™„ë²½í•œ WOS Plain Text í˜•ì‹ìœ¼ë¡œ 100% í˜¸í™˜ì„± ë³´ì¥")
    
    success_content = "".join([f"<p style='color: #0064ff; margin: 6px 0; font-weight: 500;'>{info}</p>" for info in success_info])
    
    st.markdown(f"""
    <div class="info-panel">
        <h4 style="color: #0064ff; margin-bottom: 16px; font-weight: 700;">ğŸ¯ ì²´ê³„ì  ë¬¸í—Œ ì„ ì • ì™„ë£Œ</h4>
        {success_content}
        <div style="margin-top: 16px; padding: 12px; background: rgba(0,100,255,0.1); border-radius: 8px;">
            <p style='color: #0064ff; margin: 0; font-weight: 600; font-size: 14px;'>
            ğŸ’¡ <strong>ë°°ì œìœ¨:</strong> {(total_excluded/total_papers*100):.1f}% 
            - 1996ë…„ RealAudio ì´í›„ ì‹¤ì‹œê°„ ì–‘ë°©í–¥ ìƒí˜¸ì‘ìš© íŠ¹ì„±ì„ ê°–ì¶˜ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ë§Œì„ ì²´ê³„ì ìœ¼ë¡œ ì„ ì •í–ˆìŠµë‹ˆë‹¤.
            </p>
        </div>
    </div>
    """, unsafe_allow_html=True)

    # --- ìµœì¢… íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì„¹ì…˜ ---
    st.markdown("""
    <div class="section-header">
        <div class="section-title">ğŸ“¥ ì²´ê³„ì  ë¬¸í—Œ ì„ ì • ì™„ë£Œ - SCIMAT ë¶„ì„ìš© íŒŒì¼ ë‹¤ìš´ë¡œë“œ</div>
        <div class="section-subtitle">ë¬¸í—Œ ì„ ì • ê¸°ì¤€ ì ìš© í›„ ì •ì œëœ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ WOS Plain Text íŒŒì¼</div>
    </div>
    """, unsafe_allow_html=True)
    
    # SCIMAT í˜¸í™˜ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    text_data = convert_to_scimat_wos_format(df_final_output)
    
    download_clicked = st.download_button(
        label="ğŸ“¥ ë‹¤ìš´ë¡œë“œ",
        data=text_data,
        file_name=f"live_streaming_systematic_selection_{len(df_final_output)}papers.txt",
        mime="text/plain",
        type="primary",
        use_container_width=True,
        key="download_final_file",
        help="ì²´ê³„ì  ë¬¸í—Œ ì„ ì • ê¸°ì¤€ ì ìš© í›„ SCIMATì—ì„œ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ WOS Plain Text íŒŒì¼"
    )

# --- í•˜ë‹¨ ì—¬ë°± ë° ì¶”ê°€ ì •ë³´ ---
st.markdown("<br>", unsafe_allow_html=True)

# ë„ì›€ë§ ì„¹ì…˜ - í•­ìƒ í‘œì‹œ
with st.expander("â“ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ (FAQ)", expanded=False):
    st.markdown("""
    **Q: ë¬¸í—Œ ì„ ì • ê¸°ì¤€ì€ ì–´ë–»ê²Œ ì ìš©ë˜ë‚˜ìš”?**
    A: í¬í•¨ê¸°ì¤€(ì£¼ì œì  ê´€ë ¨ì„±, ë°©ë²•ë¡ ì  ì—„ê²©ì„±, ì‹œê°„ì  ë²”ìœ„)ê³¼ ë°°ì œê¸°ì¤€(ì‚¬íšŒ-ê¸°ìˆ ì  ë§¥ë½ ë¶€ì¬, í•µì‹¬ ì£¼ì œì„± ë¯¸ì¶©ì¡±, ì¤‘ë³µ ë° ì ‘ê·¼ ë¶ˆê°€)ì„ ì²´ê³„ì ìœ¼ë¡œ ì ìš©í•©ë‹ˆë‹¤.
    
    **Q: 1996ë…„ì„ ì‹œì‘ì ìœ¼ë¡œ í•˜ëŠ” ì´ìœ ëŠ”?**
    A: 1996ë…„ì€ RealAudioê°€ ìµœì´ˆë¡œ ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ì„ êµ¬í˜„í•œ í•´ë¡œ, ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ê¸°ìˆ ì˜ ì¶œë°œì ì…ë‹ˆë‹¤.
    
    **Q: ì‹¤ì‹œê°„ ì–‘ë°©í–¥ ìƒí˜¸ì‘ìš©ì´ë€?**
    A: ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë°ì˜ í•µì‹¬ íŠ¹ì§•ìœ¼ë¡œ, ìŠ¤íŠ¸ë¦¬ë¨¸ì™€ ì‹œì²­ì ê°„ì˜ ì¦‰ì‹œì  ì†Œí†µ(ì±„íŒ…, í”¼ë“œë°±, ì°¸ì—¬)ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.
    
    **Q: ë°°ì œëœ ë…¼ë¬¸ì€ ì–´ë–¤ ê²ƒë“¤ì¸ê°€ìš”?**
    A: ìˆœìˆ˜ ê¸°ìˆ  í”„ë¡œí† ì½œë§Œ ë‹¤ë£¬ ì—°êµ¬, ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë°ì´ ì˜ˆì‹œë¡œë§Œ ì–¸ê¸‰ëœ ì—°êµ¬, ì¤‘ë³µ ê²Œì¬ ë…¼ë¬¸ ë“±ì´ ë°°ì œë©ë‹ˆë‹¤.
    
    **Q: REVIEW ë¶„ë¥˜ëœ ë…¼ë¬¸ì€ ì–´ë–»ê²Œ ì²˜ë¦¬í•˜ë‚˜ìš”?**
    A: ì œëª©ê³¼ ì´ˆë¡ì„ ì§ì ‘ ê²€í† í•˜ì—¬ í¬í•¨ê¸°ì¤€ ì¶©ì¡± ì—¬ë¶€ë¥¼ ìµœì¢… íŒë‹¨í•˜ê³ , í•„ìš”ì‹œ ìˆ˜ë™ìœ¼ë¡œ í¬í•¨/ë°°ì œë¥¼ ê²°ì •í•˜ì„¸ìš”.
    
    **Q: SCIMAT ë¶„ì„ì— í•„ìš”í•œ ìµœì†Œ ë…¼ë¬¸ ìˆ˜ëŠ”?**
    A: ì˜ë¯¸ ìˆëŠ” ë¶„ì„ì„ ìœ„í•´ Periodë‹¹ ìµœì†Œ 50í¸, ì „ì²´ ìµœì†Œ 200í¸ ì´ìƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.
    
    **Q: ë³‘í•©ëœ íŒŒì¼ì´ SCIMATì—ì„œ ì œëŒ€ë¡œ ë¡œë”©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.**
    A: ì›ë³¸ WOS íŒŒì¼ë“¤ì´ 'FN Clarivate Analytics Web of Science'ë¡œ ì‹œì‘í•˜ëŠ” ì •í’ˆ Plain Text íŒŒì¼ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.
    
    **Q: ì¤‘ë³µ ë…¼ë¬¸ ì œê±°ëŠ” ì–´ë–»ê²Œ ì´ë£¨ì–´ì§€ë‚˜ìš”?**
    A: UT(Unique Article Identifier) ê¸°ì¤€ìœ¼ë¡œ ìë™ ì¤‘ë³µ ì œê±°ë˜ë©°, UTê°€ ì—†ìœ¼ë©´ ì œëª©+ì €ì ì¡°í•©ìœ¼ë¡œ ì¤‘ë³µì„ ê°ì§€í•©ë‹ˆë‹¤.
    """)

# SciMAT ë¶„ì„ ê°€ì´ë“œ - í•­ìƒ í‘œì‹œ
with st.expander("ğŸ“Š ì²´ê³„ì  ë¬¸í—Œ ì„ ì • â†’ SciMAT ë¶„ì„ ê°€ì´ë“œ", expanded=False):
    st.markdown("""
    ### 1. ë¬¸í—Œ ì„ ì •ì˜ ì˜ì˜
    
    **ì²´ê³„ì  ì ‘ê·¼ì˜ ì¤‘ìš”ì„±**
    - ì£¼ì œì  ê´€ë ¨ì„±: ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë°ì´ í•µì‹¬ ì—°êµ¬ ëŒ€ìƒì¸ ë…¼ë¬¸ë§Œ ì„ ì •
    - ë°©ë²•ë¡ ì  ì—„ê²©ì„±: ë™ë£Œì‹¬ì‚¬ ê±°ì¹œ í•™ìˆ ë…¼ë¬¸ìœ¼ë¡œ í’ˆì§ˆ ë³´ì¥
    - ì‹œê°„ì  ë²”ìœ„: 1996ë…„ RealAudio ì´í›„ ê¸°ìˆ  ë°œì „ì‚¬ ë°˜ì˜
    
    **ë°°ì œ ê¸°ì¤€ì˜ í•„ìš”ì„±**
    - EC1: ì‚¬íšŒ-ê¸°ìˆ ì  ë§¥ë½ì´ ì—†ëŠ” ìˆœìˆ˜ ê¸°ìˆ  ì—°êµ¬ ë°°ì œ
    - EC2: ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë°ì´ ë¶€ì°¨ì ìœ¼ë¡œë§Œ ì–¸ê¸‰ëœ ì—°êµ¬ ë°°ì œ  
    - EC3: ì¤‘ë³µ ê²Œì¬ë‚˜ ì ‘ê·¼ ë¶ˆê°€ëŠ¥í•œ ë…¼ë¬¸ ë°°ì œ
    
    ### 2. SCIMAT ë¶„ì„ ì¤€ë¹„
    
    **Period ì„¤ì • ê¶Œì¥ì•ˆ**
    ```
    Period 1: 1996-2005 (ê¸°ìˆ  íƒœë™ê¸°)
    Period 2: 2006-2012 (í”Œë«í¼ ë“±ì¥ê¸°) 
    Period 3: 2013-2018 (ëŒ€ì¤‘í™” ì‹œê¸°)
    Period 4: 2019-2024 (ì„±ìˆ™ ë° ë‹¤ì–‘í™”)
    ```
    
    **í‚¤ì›Œë“œ ì •ë¦¬ ì „ëµ**
    - ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ê´€ë ¨ ìš©ì–´ í†µí•© (live streaming, livestreaming ë“±)
    - í”Œë«í¼ë³„ ìš©ì–´ ì •ë¦¬ (Twitch, YouTube Live ë“±)
    - ê¸°ìˆ -ì‚¬íšŒì  í‚¤ì›Œë“œ ë¶„ë¦¬ (ê¸°ìˆ  vs ì‚¬ìš©ì í–‰ë™)
    
    ### 3. ë¶„ì„ íŒŒë¼ë¯¸í„° ìµœì í™”
    
    **ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ íŠ¹ì„± ë°˜ì˜**
    - Minimum frequency: 2-3 (ì‹ í¥ ë¶„ì•¼ íŠ¹ì„±ìƒ)
    - Maximum network size: 30-50 (ëª…í™•í•œ í´ëŸ¬ìŠ¤í„° í˜•ì„±)
    - Normalization: Equivalence Index (í‚¤ì›Œë“œ ê°„ ì—°ê´€ì„± ì •í™• ì¸¡ì •)
    
    ### 4. ê²°ê³¼ í•´ì„ ê°€ì´ë“œ
    
    **Motor Themes ì‹ë³„**
    - ê° ì‹œê¸°ë³„ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ì˜ í•µì‹¬ ì£¼ì œ
    - ê¸°ìˆ  ë°œì „ê³¼ ì‚¬íšŒì  ìˆ˜ìš©ì˜ ìƒí˜¸ì‘ìš© íŒ¨í„´
    
    **Emerging Themes ì£¼ëª©**
    - ì°¨ì„¸ëŒ€ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ ë°©í–¥ ì˜ˆì¸¡
    - ë©”íƒ€ë²„ìŠ¤, AI ë“± ìœµí•© ê¸°ìˆ  ì˜ì—­
    
    ### 5. ì—°êµ¬ì˜ í•œê³„ì™€ ì˜ì˜
    
    **ì²´ê³„ì  ì„ ì •ì˜ ì¥ì **
    - ì—°êµ¬ í’ˆì§ˆ ë³´ì¥: ë™ë£Œì‹¬ì‚¬ ê±°ì¹œ í•™ìˆ ë…¼ë¬¸ë§Œ í¬í•¨
    - ì£¼ì œ ì¼ê´€ì„±: ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° í•µì‹¬ íŠ¹ì„± ë°˜ì˜ ì—°êµ¬ë§Œ ì„ ì •
    - ì‹œê°„ì  ì™„ì „ì„±: ê¸°ìˆ  ì¶œí˜„ë¶€í„° í˜„ì¬ê¹Œì§€ ì „ ê¸°ê°„ í¬ê´„
    
    **ê³ ë ¤ì‚¬í•­**
    - ì˜ì–´ ë…¼ë¬¸ ì¤‘ì‹¬ìœ¼ë¡œ ì¸í•œ ì§€ì—­ì  í¸í–¥ ê°€ëŠ¥ì„±
    - ì‹ ê¸°ìˆ  ì˜ì—­ì˜ ë¹ ë¥¸ ë³€í™”ë¡œ ì¸í•œ ìµœì‹ ì„± í•œê³„
    - í•™ì œê°„ ì—°êµ¬ ì¦ê°€ë¡œ ì¸í•œ ê²½ê³„ ì„¤ì •ì˜ ì–´ë ¤ì›€
    """)

st.markdown("<br><br>", unsafe_allow_html=True)

    # --- ì—°ë„ë³„ ì—°êµ¬ ë™í–¥ ---
    if 'PY' in df_final_output.columns:
        st.markdown("""
        <div class="chart-container">
            <div class="chart-title">ì •ì œëœ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ ë™í–¥ (í•™ìˆ ì  ë°°ì œ ê¸°ì¤€ ì ìš© í›„)</div>
        """, unsafe_allow_html=True)
        
        df_trend = df_final_output.copy()
        df_trend['PY'] = pd.to_numeric(df_trend['PY'], errors='coerce')
        df_trend.dropna(subset=['PY'], inplace=True)
        df_trend['PY'] = df_trend['PY'].astype(int)
        
        yearly_counts = df_trend['PY'].value_counts().reset_index()
        yearly_counts.columns = ['Year', 'Count']
        yearly_counts = yearly_counts[yearly_counts['Year'] <= 2025].sort_values('Year')

        if len(yearly_counts) > 0:
            line_chart = alt.Chart(yearly_counts).mark_line(
                point={'size': 80, 'filled': True}, strokeWidth=3, color='#0064ff'
            ).encode(
                x=alt.X('Year:O', title='ë°œí–‰ ì—°ë„'),
                y=alt.Y('Count:Q', title='ë…¼ë¬¸ ìˆ˜'),
                tooltip=['Year', 'Count']
            ).properties(height=300)
            
            st.altair_chart(line_chart, use_container_width=True)
        
        st.markdown("</div>", unsafe_allow_html=True)

    # --- í‚¤ì›Œë“œ ìƒ˜í”Œ í™•ì¸ ---
    st.markdown("""
    <div class="chart-container">
        <div class="chart-title">ì •ì œëœ ë°ì´í„° í‚¤ì›Œë“œ í’ˆì§ˆ í™•ì¸</div>
    """, unsafe_allow_html=True)
    
    sample_data = []
    sample_rows = df_for_analysis[df_for_analysis['Classification'].str.contains('Include', na=False)].head(3)
    
    for idx, row in sample_rows.iterrows():
        title = str(row.get('TI', 'N/A'))[:80] + "..." if len(str(row.get('TI', 'N/A'))) > 80 else str(row.get('TI', 'N/A'))
        de_keywords = str(row.get('DE', 'N/A')) if pd.notna(row.get('DE')) else 'N/A'
        id_keywords = str(row.get('ID', 'N/A')) if pd.notna(row.get('ID')) else 'N/A'
        
        # í‚¤ì›Œë“œ ê°œìˆ˜ ê³„ì‚°
        de_count = len([k.strip() for k in de_keywords.split(';') if k.strip()]) if de_keywords != 'N/A' else 0
        id_count = len([k.strip() for k in id_keywords.split(';') if k.strip()]) if id_keywords != 'N/A' else 0
        
        sample_data.append({
            'ë…¼ë¬¸ ì œëª©': title,
            'DE í‚¤ì›Œë“œ': de_keywords[:100] + "..." if len(de_keywords) > 100 else de_keywords,
            'ID í‚¤ì›Œë“œ': id_keywords[:100] + "..." if len(id_keywords) > 100 else id_keywords,
            'DE ê°œìˆ˜': de_count,
            'ID ê°œìˆ˜': id_count
        })
    
    if sample_data:
        sample_df = pd.DataFrame(sample_data)
        st.dataframe(sample_df, use_container_width=True, hide_index=True)
        
        # í‚¤ì›Œë“œ í’ˆì§ˆ í‰ê°€
        avg_de = sum([d['DE ê°œìˆ˜'] for d in sample_data]) / len(sample_data) if sample_data else 0
        avg_id = sum([d['ID ê°œìˆ˜'] for d in sample_data]) / len(sample_data) if sample_data else 0
        
        if avg_de >= 3 and avg_id >= 3:
            st.success("âœ… í‚¤ì›Œë“œ í’ˆì§ˆ ìš°ìˆ˜ - SCIMATì—ì„œ ì›í™œí•œ ê·¸ë£¨í•‘ ì˜ˆìƒ")
        elif avg_de >= 2 or avg_id >= 2:
            st.warning("âš ï¸ í‚¤ì›Œë“œ í’ˆì§ˆ ë³´í†µ - SCIMATì—ì„œ ì¼ë¶€ ì œí•œ ê°€ëŠ¥")
        else:
            st.error("âŒ í‚¤ì›Œë“œ í’ˆì§ˆ ë¶€ì¡± - ì›ë³¸ WOS ë‹¤ìš´ë¡œë“œ ì„¤ì • í™•ì¸ í•„ìš”")

    st.markdown("</div>", unsafe_allow_html=True)

    # ë¶„ë¥˜ë³„ ë…¼ë¬¸ ìƒì„¸ ëª©ë¡ - Reviewë§Œ í† ê¸€ë¡œ ìœ ì§€
    review_papers = df_for_analysis[df_for_analysis['Classification'].str.contains('Review', na=False)]
    
    if len(review_papers) > 0:
        with st.expander(f"ğŸ” Review (ê²€í†  í•„ìš”) - ë…¼ë¬¸ ëª©ë¡ ({len(review_papers)}í¸)", expanded=False):
            st.markdown("""
            <div style="background: #fffbeb; padding: 16px; border-radius: 12px; margin-bottom: 20px; border: 1px solid #f59e0b;">
                <strong style="color: #92400e;">ğŸ“‹ ê²€í†  ì•ˆë‚´:</strong> ì•„ë˜ ë…¼ë¬¸ë“¤ì€ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ì™€ì˜ ê´€ë ¨ì„±ì„ ì¶”ê°€ ê²€í† ê°€ í•„ìš”í•œ ë…¼ë¬¸ë“¤ì…ë‹ˆë‹¤.
                ì œëª©ê³¼ ì¶œíŒ ì •ë³´ë¥¼ í™•ì¸í•˜ì—¬ ì—°êµ¬ ë²”ìœ„ì— í¬í•¨í• ì§€ ê²°ì •í•˜ì„¸ìš”. ì—„ê²©í•œ ë°°ì œ ê¸°ì¤€(EC1-EC7)ì€ ì´ë¯¸ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.
            </div>
            """, unsafe_allow_html=True)
            
            # Review ë…¼ë¬¸ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            review_excel_data = []
            for idx, (_, paper) in enumerate(review_papers.iterrows(), 1):
                review_excel_data.append({
                    'ë²ˆí˜¸': idx,
                    'ë…¼ë¬¸ ì œëª©': str(paper.get('TI', 'N/A')),
                    'ì¶œíŒì—°ë„': str(paper.get('PY', 'N/A')),
                    'ì €ë„ëª…': str(paper.get('SO', 'N/A')),
                    'ì €ì': str(paper.get('AU', 'N/A')),
                    'ë¶„ë¥˜': str(paper.get('Classification', 'N/A')),
                    'ì €ì í‚¤ì›Œë“œ': str(paper.get('DE', 'N/A')),
                    'WOS í‚¤ì›Œë“œ': str(paper.get('ID', 'N/A')),
                    'ì´ˆë¡': str(paper.get('AB', 'N/A')),
                    'ë¬¸ì„œìœ í˜•': str(paper.get('DT', 'N/A'))
                })
            
            review_excel_df = pd.DataFrame(review_excel_data)
            
            # ì—‘ì…€ íŒŒì¼ ìƒì„±
            excel_buffer = io.BytesIO()
            with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                review_excel_df.to_excel(writer, sheet_name='Review_Papers', index=False)
            excel_data = excel_buffer.getvalue()
            
            st.download_button(
                label="ğŸ“Š ê²€í†  ë…¼ë¬¸ ëª©ë¡ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
                data=excel_data,
                file_name=f"review_papers_ec_filtered_{len(review_papers)}í¸.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                type="secondary",
                use_container_width=True
            )
            
            st.markdown("<br>", unsafe_allow_html=True)
            
            for idx, (_, paper) in enumerate(review_papers.iterrows(), 1):
                title = str(paper.get('TI', 'N/A'))
                year = str(paper.get('PY', 'N/A'))
                source = str(paper.get('SO', 'N/A'))
                classification = str(paper.get('Classification', 'N/A'))
                doc_type = str(paper.get('DT', 'N/A'))
                
                # ë¶„ë¥˜ë³„ ìƒ‰ìƒ ì„¤ì •
                if 'ë¶ˆí™•ì‹¤' in classification:
                    badge_color = "#8b5cf6"
                    badge_text = "ë¶„ë¥˜ ë¶ˆí™•ì‹¤"
                elif 'ì†Œì…œë¯¸ë””ì–´' in classification:
                    badge_color = "#06b6d4"
                    badge_text = "ì†Œì…œë¯¸ë””ì–´"
                elif 'ìƒí˜¸ì‘ìš©ì„±' in classification:
                    badge_color = "#f97316"
                    badge_text = "ìƒí˜¸ì‘ìš©ì„± ê²€í† "
                else:
                    badge_color = "#f59e0b"
                    badge_text = "ê¸°íƒ€ ê²€í† "
                
                st.markdown(f"""
                <div style="margin: 12px 0; padding: 16px; background: white; border-left: 4px solid #f59e0b; border-radius: 12px; box-shadow: 0 1px 3px rgba(0,0,0,0.04);">
                    <div style="display: flex; align-items: center; margin-bottom: 8px;">
                        <span style="background: {badge_color}; color: white; padding: 4px 12px; border-radius: 16px; font-size: 12px; margin-right: 12px; font-weight: 600;">{badge_text}</span>
                        <span style="color: #8b95a1; font-size: 14px;">#{idx}</span>
                        <span style="color: #8b95a1; font-size: 12px; margin-left: 8px;">[{doc_type}]</span>
                    </div>
                    <div style="font-weight: 600; color: #191f28; margin-bottom: 6px; line-height: 1.5;">
                        {title}
                    </div>
                    <div style="font-size: 14px; color: #8b95a1;">
                        <strong>ì—°ë„:</strong> {year} | <strong>ì €ë„:</strong> {source}
                    </div>
                </div>
                """, unsafe_allow_html=True)

    # ë³‘í•© ì„±ê³¼ ê°•ì¡° - í•™ìˆ ì  ì—„ë°€ì„± ë°˜ì˜
    success_info = []
    success_info.append(f"<strong>íŒŒì¼ í†µí•©:</strong> {successful_files}ê°œì˜ WOS íŒŒì¼ì„ í•˜ë‚˜ë¡œ ë³‘í•©")
    
    if duplicates_removed > 0:
        success_info.append(f"<strong>ì¤‘ë³µ ì œê±°:</strong> {duplicates_removed}í¸ì˜ ì¤‘ë³µ ë…¼ë¬¸ ìë™ ê°ì§€ ë° ì œê±°")
    
    success_info.append(f"<strong>í•™ìˆ ì  ì—„ë°€ì„±:</strong> EC1-EC7 ë°°ì œ ê¸°ì¤€ ì ìš©ìœ¼ë¡œ {total_excluded}í¸ ì œì™¸")
    success_info.append(f"<strong>ìµœì¢… ê·œëª¨:</strong> {len(df_final_output):,}í¸ì˜ ê³ í’ˆì§ˆ ë…¼ë¬¸ìœ¼ë¡œ ì •ì œëœ ë°ì´í„°ì…‹")
    success_info.append(f"<strong>í•µì‹¬ ì—°êµ¬:</strong> {include_papers}í¸ì˜ ì§ì ‘ ê´€ë ¨ ë¼ì´ë¸ŒìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ í™•ë³´")
    success_info.append("<strong>SCIMAT í˜¸í™˜:</strong> ì™„ë²½í•œ WOS Plain Text í˜•ì‹ìœ¼ë¡œ 100% í˜¸í™˜ì„± ë³´ì¥")
    
    success_content = "".join([f"<p style='color: #0064ff; margin: 6px 0; font-weight: 500;'>{info}</p>" for info in success_info])
    
    st.markdown(f"""
    <div class="info-panel">
        <h4 style="color: #0064ff; margin-bottom: 16px; font-weight: 700;">ğŸ¯ í•™ìˆ ì  ë°ì´í„° ì •ì œ ì™„ë£Œ</h4>
        {success_content}
        <div style="margin-top: 16px; padding: 12px; background: rgba(0,100,255,0.1); border-radius: 8px;">
            <p style='color: #0064ff; margin: 0; font-weight: 600; font-size: 14px;'>
            ğŸ’¡ <strong>ë°°ì œ ê¸°ì¤€ ì ìš©ë¥ :</strong> {(total_excluded/total_papers*100):.1f}% 
            - í”¼ìƒì  ì–¸ê¸‰, ê¸°ìˆ ì  ì „ì†¡ë°©ì‹, ë¹„í•™ìˆ  ë¬¸ì„œ ë“±ì„ ì²´ê³„ì ìœ¼ë¡œ ì œê±°í•˜ì—¬ ì—°êµ¬ì˜ í•™ìˆ ì  ì—„ë°€ì„±ì„ í™•ë³´í–ˆìŠµë‹ˆë‹¤.
            </p>
        </div>
    </div>
    """, unsafe_allow_html=True)

    # --- ìµœì¢… íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì„¹ì…˜ ---
    st.markdown("""
    <div class="section-header">
        <div class="section-title">ğŸ“¥ í•™ìˆ ì  ì •ì œ ì™„ë£Œ - SCIMAT ë¶„ì„ìš© íŒŒì¼ ë‹¤ìš´ë¡œë“œ</div>
        <div class="section-subtitle">EC1-EC7 ë°°ì œ ê¸°ì¤€ ì ìš© í›„ ì •ì œëœ ê³ í’ˆì§ˆ WOS Plain Text íŒŒì¼</div>
    </div>
    """, unsafe_allow_html=True)
    
    # SCIMAT í˜¸í™˜ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    text_data = convert_to_scimat_wos_format(df_final_output)
    
    download_clicked = st.download_button(
        label="ğŸ“¥ ë‹¤ìš´ë¡œë“œ",
        data=text_data,
        file_name=f"live_streaming_academic_filtered_scimat_{len(df_final_output)}papers.txt",
        mime="text/plain",
        type="primary",
        use_container_width=True,
        key="download_final_file",
        help="í•™ìˆ ì  ë°°ì œ ê¸°ì¤€ ì ìš© í›„ SCIMATì—ì„œ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ WOS Plain Text íŒŒì¼"
    )

# --- í•˜ë‹¨ ì—¬ë°± ë° ì¶”ê°€ ì •ë³´ ---
st.markdown("<br>", unsafe_allow_html=True)

# ë„ì›€ë§ ì„¹ì…˜ - í•­ìƒ í‘œì‹œ
with st.expander("â“ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ (FAQ)", expanded=False):
    st.markdown("""
    **Q: ì—¬ëŸ¬ WOS íŒŒì¼ì„ ì–´ë–»ê²Œ í•œ ë²ˆì— ì²˜ë¦¬í•˜ë‚˜ìš”?**
    A: WOSì—ì„œ ì—¬ëŸ¬ ë²ˆ Plain Text ë‹¤ìš´ë¡œë“œí•œ í›„, ëª¨ë“  .txt íŒŒì¼ì„ í•œ ë²ˆì— ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ ë³‘í•©ë©ë‹ˆë‹¤.
    
    **Q: ì¤‘ë³µëœ ë…¼ë¬¸ì´ ìˆì„ê¹Œë´ ê±±ì •ë©ë‹ˆë‹¤.**
    A: UT(Unique Article Identifier) ê¸°ì¤€ìœ¼ë¡œ ìë™ ì¤‘ë³µ ì œê±°ë˜ë©°, UTê°€ ì—†ìœ¼ë©´ ì œëª©+ì €ì ì¡°í•©ìœ¼ë¡œ ì¤‘ë³µì„ ê°ì§€í•©ë‹ˆë‹¤.
    
    **Q: WOSì—ì„œ ì–´ë–¤ ì„¤ì •ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•´ì•¼ í•˜ë‚˜ìš”?**
    A: Export â†’ Record Content: "Full Record and Cited References", File Format: "Plain Text"ë¡œ ì„¤ì •í•˜ì„¸ìš”. ì¸ìš© ê´€ê³„ ë¶„ì„ì„ ìœ„í•´ ì°¸ê³ ë¬¸í—Œ ì •ë³´ê°€ í•„ìˆ˜ì…ë‹ˆë‹¤.
    
    **Q: ë°°ì œ ê¸°ì¤€ EC1-EC7ì€ ë¬´ì—‡ì¸ê°€ìš”?**
    A: EC1(ê¸°ìˆ ì  ì „ì†¡ë°©ì‹ë§Œ), EC2(í”¼ìƒì  ì–¸ê¸‰), EC3(ë¯¸ë˜ì—°êµ¬ ì œì•ˆ), EC4(ìƒí˜¸ì‘ìš© ë¯¸ê³ ë ¤), EC5(ë¼ì´ë¸ŒìŠ¤íŠ¸ë¦¬ë° ë§¥ë½ ë¶€ì¬), EC6(ë¹„í•™ìˆ  ë¬¸ì„œ), EC7(ì¤‘ë³µê²Œì¬) - í•™ìˆ ì  ì—„ë°€ì„±ì„ ìœ„í•œ ì²´ê³„ì  ë°°ì œ ê¸°ì¤€ì…ë‹ˆë‹¤.
    
    **Q: SCIMATì—ì„œ í‚¤ì›Œë“œ ì •ë¦¬ë¥¼ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?**
    A: Group set â†’ Word â†’ Find similar words by distances (Maximum distance: 1)ë¡œ ìœ ì‚¬ í‚¤ì›Œë“œë¥¼ ìë™ í†µí•©í•˜ê³ , Word Group manual setì—ì„œ ìˆ˜ë™ìœ¼ë¡œ ê´€ë ¨ í‚¤ì›Œë“œë“¤ì„ ê·¸ë£¹í™”í•˜ì„¸ìš”.
    
    **Q: SCIMAT ë¶„ì„ ì„¤ì •ì€ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?**
    A: Unit of Analysis: "Author's words + Source's words", Network Type: "Co-occurrence", Normalization: "Equivalence Index", Clustering: "Simple Centers Algorithm" (Maximum network size: 50)ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.
    
    **Q: ë³‘í•©ëœ íŒŒì¼ì´ SCIMATì—ì„œ ì œëŒ€ë¡œ ë¡œë”©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.**
    A: ì›ë³¸ WOS íŒŒì¼ë“¤ì´ 'FN Clarivate Analytics Web of Science'ë¡œ ì‹œì‘í•˜ëŠ” ì •í’ˆ Plain Text íŒŒì¼ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.
    
    **Q: SCIMATì—ì„œ PeriodëŠ” ì–´ë–»ê²Œ ì„¤ì •í•˜ë‚˜ìš”?**
    A: ì—°êµ¬ ë¶„ì•¼ì˜ ì§„í™” ë‹¨ê³„ë¥¼ ë°˜ì˜í•˜ì—¬ ì˜ë¯¸ ìˆê²Œ êµ¬ë¶„í•˜ë˜, ê° Periodë‹¹ ìµœì†Œ 50í¸ ì´ìƒì˜ ë…¼ë¬¸ì„ í¬í•¨í•˜ë„ë¡ ì„¤ì •í•˜ì„¸ìš”.
    
    **Q: ëª‡ ê°œì˜ íŒŒì¼ê¹Œì§€ ë™ì‹œì— ì—…ë¡œë“œí•  ìˆ˜ ìˆë‚˜ìš”?**
    A: ê¸°ìˆ ì ìœ¼ë¡œëŠ” ì œí•œì´ ì—†ì§€ë§Œ, ì•ˆì •ì„±ì„ ìœ„í•´ 10ê°œ ì´í•˜ì˜ íŒŒì¼ì„ ê¶Œì¥í•©ë‹ˆë‹¤. ë§¤ìš° í° ë°ì´í„°ì…‹ì˜ ê²½ìš° ë‚˜ëˆ„ì–´ì„œ ì²˜ë¦¬í•˜ì„¸ìš”.
    """)

# SciMAT ë¶„ì„ ê°€ì´ë“œ - í•­ìƒ í‘œì‹œ
with st.expander("ğŸ“Š WOS â†’ SciMAT ë¶„ì„ ì‹¤í–‰ ê°€ì´ë“œ", expanded=False):
    st.markdown("""
    ### í•„ìš”í•œ ê²ƒ
    - SciMAT ì†Œí”„íŠ¸ì›¨ì–´ (ë¬´ë£Œ ë‹¤ìš´ë¡œë“œ)
    - ë‹¤ìš´ë¡œë“œëœ WOS Plain Text íŒŒì¼
    - Java 1.8 ì´ìƒ
    
    ### 1ë‹¨ê³„: SciMAT ì‹œì‘í•˜ê¸°
    
    **ìƒˆ í”„ë¡œì íŠ¸ ìƒì„±**
    ```
    1. SciMAT ì‹¤í–‰ (SciMAT.jar ë”ë¸”í´ë¦­)
    2. File â†’ New Project
    3. Path: ì €ì¥í•  í´ë” ì„ íƒ
    4. File name: í”„ë¡œì íŠ¸ ì´ë¦„ ì…ë ¥
    5. Accept
    ```
    
    **ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°**
    ```
    1. File â†’ Add Files
    2. "ISI WoS" ì„ íƒ
    3. ë‹¤ìš´ë¡œë“œí•œ txt íŒŒì¼ ì„ íƒ
    4. ë¡œë”© ì™„ë£Œê¹Œì§€ ëŒ€ê¸°
    ```
    
    ### 2ë‹¨ê³„: í‚¤ì›Œë“œ ì •ë¦¬í•˜ê¸°
    
    **ìœ ì‚¬ í‚¤ì›Œë“œ ìë™ í†µí•©**
    ```
    1. Group set â†’ Word â†’ Find similar words by distances
    2. Maximum distance: 1 (í•œ ê¸€ì ì°¨ì´)
    3. ê°™ì€ ì˜ë¯¸ ë‹¨ì–´ë“¤ í™•ì¸í•˜ê³  Moveë¡œ í†µí•©
    ```
    ì˜ë¯¸: ì² ìê°€ 1ê¸€ìë§Œ ë‹¤ë¥¸ ë‹¨ì–´ë“¤ì„ ì°¾ì•„ì„œ ì œì•ˆ (ì˜ˆ: "platform" â†” "platforms")
    
    **ìˆ˜ë™ìœ¼ë¡œ í‚¤ì›Œë“œ ì •ë¦¬**
    ```
    1. Group set â†’ Word â†’ Word Group manual set
    2. Words without group ëª©ë¡ í™•ì¸
    3. ê´€ë ¨ í‚¤ì›Œë“œë“¤ ì„ íƒ í›„ New groupìœ¼ë¡œ ë¬¶ê¸°
    4. ë¶ˆí•„ìš”í•œ í‚¤ì›Œë“œ ì œê±°
    ```
    ëª©ì : ë°ì´í„° í’ˆì§ˆ í–¥ìƒ, ì˜ë¯¸ ìˆëŠ” í´ëŸ¬ìŠ¤í„° í˜•ì„±
    
    ### 3ë‹¨ê³„: ì‹œê°„ êµ¬ê°„ ì„¤ì •
    
    **Period ë§Œë“¤ê¸°**
    ```
    1. Knowledge base â†’ Periods â†’ Periods manager
    2. Add ë²„íŠ¼ìœ¼ë¡œ ì‹œê°„ êµ¬ê°„ ìƒì„±:
       - Period 1: 1996-2006 (íƒœë™ê¸°)
       - Period 2: 2007-2016 (í˜•ì„±ê¸°)
       - Period 3: 2017-2021 (í™•ì‚°ê¸°)
       - Period 4: 2022-2024 (ì„±ìˆ™ê¸°)
    ```
    ì›ë¦¬: ì—°êµ¬ ë¶„ì•¼ì˜ ì§„í™” ë‹¨ê³„ë¥¼ ë°˜ì˜í•œ ì˜ë¯¸ ìˆëŠ” êµ¬ë¶„
    
    **ê° Periodì— ë…¼ë¬¸ í• ë‹¹**
    ```
    1. Period 1 í´ë¦­ â†’ Add
    2. í•´ë‹¹ ì—°ë„ ë…¼ë¬¸ë“¤ ì„ íƒ
    3. ì˜¤ë¥¸ìª½ í™”ì‚´í‘œë¡œ ì´ë™
    4. ë‹¤ë¥¸ Periodë“¤ë„ ë™ì¼í•˜ê²Œ ë°˜ë³µ
    ```
    
    ### 4ë‹¨ê³„: ë¶„ì„ ì‹¤í–‰
    
    **ë¶„ì„ ë§ˆë²•ì‚¬ ì‹œì‘**
    ```
    1. Analysis â†’ Make Analysis
    2. ëª¨ë“  Period ì„ íƒ â†’ Next
    ```
    
    **Step 1-8: ë¶„ì„ ì„¤ì •**
    - Unit of Analysis: "Author's words + Source's words"
    - Data Reduction: Minimum frequency 2
    - Network Type: "Co-occurrence"
    - Normalization: "Equivalence Index"
    - Clustering: "Simple Centers Algorithm" (Max network size: 50)
    - Document Mapper: "Core Mapper"
    - Performance Measures: G-index, Sum Citations
    - Evolution Map: "Jaccard Index"
    
    **ë¶„ì„ ì‹¤í–‰**
    ```
    - Finish í´ë¦­
    - ì™„ë£Œê¹Œì§€ ëŒ€ê¸° (10-30ë¶„)
    ```
    
    ### 5ë‹¨ê³„: ê²°ê³¼ í•´ì„
    
    **ì „ëµì  ë‹¤ì´ì–´ê·¸ë¨ 4ì‚¬ë¶„ë©´**
    - ìš°ìƒë‹¨: Motor Themes (í•µì‹¬ ì£¼ì œ)
    - ì¢Œìƒë‹¨: Specialized Themes (ì „ë¬¸í™”ëœ ì£¼ì œ)
    - ì¢Œí•˜ë‹¨: Emerging/Declining Themes (ì‹ í¥/ì‡ í‡´ ì£¼ì œ)
    - ìš°í•˜ë‹¨: Basic Themes (ê¸°ì´ˆ ì£¼ì œ)
    
    **ì§„í™” ë§µ ë¶„ì„**
    - ë…¸ë“œ í¬ê¸° = ë…¼ë¬¸ ìˆ˜
    - ì—°ê²°ì„  ë‘ê»˜ = Jaccard ìœ ì‚¬ë„
    - ì‹œê°„ì— ë”°ë¥¸ ì£¼ì œ ë³€í™” ì¶”ì 
    
    ### ë¬¸ì œ í•´ê²°
    - í‚¤ì›Œë“œ ì •ë¦¬ë¥¼ ê¼¼ê¼¼íˆ (ë¶„ì„í’ˆì§ˆì˜ í•µì‹¬)
    - Periodë³„ ìµœì†Œ 50í¸ ì´ìƒ ê¶Œì¥
    - Java ë©”ëª¨ë¦¬ ë¶€ì¡±ì‹œ ì¬ì‹œì‘
    - ì¸ì½”ë”© ë¬¸ì œì‹œ UTF-8ë¡œ ë³€ê²½
    """)

st.markdown("<br><br>", unsafe_allow_html=True)
