import streamlit as st
import pandas as pd
import nltk
from nltk.stem import WordNetLemmatizer
from nltk.corpus import stopwords
import re
from collections import Counter
import altair as alt
import io

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="WOS Prep | SciMAT Compatible Edition",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# --- ì»¤ìŠ¤í…€ CSS ìŠ¤íƒ€ì¼ (ê¸°ì¡´ê³¼ ë™ì¼) ---
st.markdown("""
<style>
    .main-container {
        background: #f8f9fa;
        min-height: 100vh;
    }
    
    .metric-card {
        background: white;
        border-radius: 12px;
        padding: 24px;
        box-shadow: 0 2px 12px rgba(0,0,0,0.08);
        border: 1px solid #e9ecef;
        margin-bottom: 16px;
        transition: all 0.3s ease;
    }
    
    .metric-card:hover {
        box-shadow: 0 4px 20px rgba(0,56,117,0.15);
        border-color: #003875;
    }
    
    .metric-value {
        font-size: 2.8rem;
        font-weight: 700;
        color: #003875;
        margin: 0;
        line-height: 1;
    }
    
    .metric-label {
        font-size: 1rem;
        color: #6c757d;
        margin: 8px 0 0 0;
        font-weight: 500;
    }
    
    .metric-icon {
        background: linear-gradient(135deg, #003875, #0056b3);
        color: white;
        width: 48px;
        height: 48px;
        border-radius: 12px;
        display: flex;
        align-items: center;
        justify-content: center;
        font-size: 1.5rem;
        margin-bottom: 16px;
    }
    
    .chart-container {
        background: white;
        border-radius: 12px;
        padding: 24px;
        box-shadow: 0 2px 12px rgba(0,0,0,0.08);
        border: 1px solid #e9ecef;
        margin: 16px 0;
    }
    
    .chart-title {
        font-size: 1.2rem;
        font-weight: 600;
        color: #212529;
        margin-bottom: 16px;
        border-bottom: 2px solid #003875;
        padding-bottom: 8px;
    }
    
    .section-header {
        background: linear-gradient(135deg, #003875, #0056b3);
        color: white;
        padding: 20px 24px;
        border-radius: 12px;
        margin: 24px 0 16px 0;
        box-shadow: 0 4px 16px rgba(0,56,117,0.2);
    }
    
    .section-title {
        font-size: 1.5rem;
        font-weight: 600;
        margin: 0;
    }
    
    .section-subtitle {
        font-size: 1rem;
        opacity: 0.9;
        margin: 4px 0 0 0;
    }
    
    .info-panel {
        background: #e8f0fe;
        border: 1px solid #003875;
        border-radius: 8px;
        padding: 16px;
        margin: 16px 0;
    }
    
    .warning-panel {
        background: #fff3cd;
        border: 1px solid #ffc107;
        border-radius: 8px;
        padding: 16px;
        margin: 16px 0;
    }
    
    .feature-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
        gap: 20px;
        margin: 24px 0;
    }
    
    .feature-card {
        background: white;
        border-radius: 12px;
        padding: 24px;
        text-align: center;
        box-shadow: 0 2px 12px rgba(0,0,0,0.08);
        border: 1px solid #e9ecef;
        transition: all 0.3s ease;
    }
    
    .feature-card:hover {
        transform: translateY(-4px);
        box-shadow: 0 8px 24px rgba(0,56,117,0.15);
        border-color: #003875;
    }
    
    .feature-icon {
        font-size: 3rem;
        margin-bottom: 16px;
        background: linear-gradient(135deg, #003875, #0056b3);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        background-clip: text;
    }
    
    .feature-title {
        font-size: 1.2rem;
        font-weight: 600;
        color: #212529;
        margin-bottom: 8px;
    }
    
    .feature-desc {
        font-size: 0.95rem;
        color: #6c757d;
        line-height: 1.5;
    }
    
    .upload-zone {
        background: white;
        border: 2px dashed #003875;
        border-radius: 12px;
        padding: 40px;
        text-align: center;
        margin: 20px 0;
        transition: all 0.3s ease;
    }
    
    .upload-zone:hover {
        background: #f8f9fa;
        border-color: #0056b3;
    }
    
    .progress-indicator {
        background: linear-gradient(90deg, #003875, #0056b3);
        height: 4px;
        border-radius: 2px;
        margin: 16px 0;
        animation: pulse 2s infinite;
    }
    
    @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.7; }
    }
    
    .comparison-panel {
        background: linear-gradient(135deg, #f8f9fa, #ffffff);
        border: 1px solid #dee2e6;
        border-radius: 12px;
        padding: 20px;
        margin: 16px 0;
    }
</style>
""", unsafe_allow_html=True)

# --- NLTK ë¦¬ì†ŒìŠ¤ ë‹¤ìš´ë¡œë“œ (ìºì‹œ ìœ ì§€) ---
@st.cache_resource
def download_nltk_resources():
    nltk.download('punkt', quiet=True)
    nltk.download('wordnet', quiet=True)
    nltk.download('stopwords', quiet=True)
download_nltk_resources()

# --- ë°ì´í„° ë¡œë“œ í•¨ìˆ˜ ---
def load_data(uploaded_file):
    file_bytes = uploaded_file.getvalue()
    encodings_to_try = ['utf-8-sig', 'utf-8', 'latin1', 'cp949']

    for encoding in encodings_to_try:
        try:
            file_content = file_bytes.decode(encoding)
            # íƒ­ êµ¬ë¶„ì ìš°ì„  ì‹œë„
            df = pd.read_csv(io.StringIO(file_content), sep='\t', lineterminator='\n')
            if df.shape[1] > 1: return df
        except Exception:
            continue

    for encoding in encodings_to_try:
        try:
            file_content = file_bytes.decode(encoding)
            # ì½¤ë§ˆ êµ¬ë¶„ì ì‹œë„
            df = pd.read_csv(io.StringIO(file_content))
            if df.shape[1] > 1: return df
        except Exception:
            continue

    return None

# --- ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° íŠ¹í™” ë¶„ë¥˜ í•¨ìˆ˜ (ê¸°ì¡´ê³¼ ë™ì¼) ---
def classify_article(row):
    """ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ë¥¼ ìœ„í•œ í¬ê´„ì  ë¶„ë¥˜"""
    
    # í•µì‹¬ í¬í•¨ í‚¤ì›Œë“œ
    core_inclusion_keywords = [
        'live streaming', 'livestreaming', 'live stream', 'live broadcast', 'live video',
        'real time streaming', 'real-time streaming', 'streaming platform', 'streaming service',
        'live commerce', 'live shopping', 'live selling', 'livestream commerce',
        'social commerce', 'live marketing', 'streaming monetization',
        'streamer', 'viewer', 'audience engagement', 'streaming audience', 'live audience',
        'streaming behavior', 'viewer behavior', 'streaming experience', 'live interaction',
        'streaming community', 'online community', 'digital community',
        'twitch', 'youtube live', 'facebook live', 'instagram live', 'tiktok live',
        'streaming media', 'video streaming', 'audio streaming', 'multimedia streaming',
        'live learning', 'streaming education', 'online education', 'e-learning',
        'gaming stream', 'esports', 'live gaming', 'streaming content',
        'influencer marketing', 'content creator', 'digital marketing', 'brand engagement',
        'consumer behavior', 'purchase intention', 'social influence'
    ]
    
    # ê¸°ìˆ ì  í¬í•¨ í‚¤ì›Œë“œ
    technical_inclusion_keywords = [
        'real time video', 'real-time video', 'video compression', 'video encoding',
        'adaptive streaming', 'video quality', 'streaming quality', 'latency',
        'video delivery', 'content delivery', 'cdn', 'edge computing',
        'multimedia communication', 'video communication', 'webrtc',
        'peer to peer streaming', 'p2p streaming', 'distributed streaming',
        'mobile streaming', 'mobile video', 'wireless streaming',
        'mobile broadcast', 'smartphone streaming'
    ]
    
    # ëª…í™•í•œ ì œì™¸ í‚¤ì›Œë“œ (ìµœì†Œí™”)
    clear_exclusion_keywords = [
        'routing protocol', 'network topology', 'packet routing', 'mac protocol', 
        'ieee 802.11', 'wimax protocol', 'lte protocol',
        'vlsi design', 'circuit design', 'antenna design', 'rf circuit',
        'hardware implementation', 'fpga implementation', 'asic design',
        'signal processing algorithm', 'modulation scheme', 'channel estimation',
        'beamforming', 'mimo antenna', 'ofdm modulation',
        'satellite communication', 'underwater communication', 'space communication',
        'biomedical signal', 'medical imaging', 'radar system'
    ]
    
    # í…ìŠ¤íŠ¸ ì¶”ì¶œ
    title = str(row.get('TI', '')).lower()
    source_title = str(row.get('SO', '')).lower()
    author_keywords = str(row.get('DE', '')).lower()
    keywords_plus = str(row.get('ID', '')).lower()
    abstract = str(row.get('AB', '')).lower()
    full_text = ' '.join([title, source_title, author_keywords, keywords_plus, abstract])
    
    # ë¶„ë¥˜ ë¡œì§
    if any(keyword in full_text for keyword in clear_exclusion_keywords):
        return 'Exclude (ê¸°ìˆ ì  ë¹„ê´€ë ¨)'
    
    if any(keyword in full_text for keyword in core_inclusion_keywords):
        return 'Include (í•µì‹¬ì—°êµ¬)'
    
    if any(keyword in full_text for keyword in technical_inclusion_keywords):
        live_indicators = ['live', 'real time', 'real-time', 'streaming', 'broadcast', 'interactive']
        if any(indicator in full_text for indicator in live_indicators):
            return 'Include (ê¸°ìˆ ê¸°ë°˜)'
        else:
            return 'Review (ê¸°ìˆ ê²€í† )'
    
    general_keywords = [
        'social media', 'social network', 'online platform', 'digital platform',
        'user experience', 'user behavior', 'consumer behavior', 'online behavior',
        'digital marketing', 'online marketing', 'content creation', 'content sharing',
        'video content', 'multimedia content', 'interactive media'
    ]
    
    if any(keyword in full_text for keyword in general_keywords):
        return 'Review (ì¼ë°˜ê´€ë ¨)'
    
    return 'Review (ê²€í† í•„ìš”)'

# --- SciMAT í˜¸í™˜ì„± ìµœìš°ì„  í‚¤ì›Œë“œ ì²˜ë¦¬ ---
def scimat_compatible_keyword_processing(keywords_str):
    """
    SciMAT í˜¸í™˜ì„±ì„ ìœ„í•œ ìµœì†Œí•œì˜ í‚¤ì›Œë“œ ì²˜ë¦¬
    - ë‹¤ì–‘ì„± ë³´ì¡´ (ì •ê·œí™” ìµœì†Œí™”)
    - ê¸°ë³¸ ì •ë¦¬ë§Œ ìˆ˜í–‰
    - Word Group ê¸°ëŠ¥ì´ ì‘ë™í•  ìˆ˜ ìˆë„ë¡ ì›ì‹œì„± ìœ ì§€
    """
    if pd.isna(keywords_str) or not isinstance(keywords_str, str) or not keywords_str.strip():
        return ""
    
    # 1. ê¸°ë³¸ ë¶„ë¦¬
    if ';' in keywords_str:
        keywords_list = keywords_str.split(';')
    elif ',' in keywords_str:
        keywords_list = keywords_str.split(',')
    else:
        keywords_list = [keywords_str]
    
    # 2. ìµœì†Œí•œì˜ ì •ë¦¬ë§Œ ìˆ˜í–‰
    cleaned_keywords = []
    for keyword in keywords_list:
        keyword = keyword.strip()
        
        # ë¹ˆ í‚¤ì›Œë“œ ì œê±°
        if not keyword:
            continue
        
        # ê¸¸ì´ ì œí•œë§Œ ì ìš© (SciMAT ê¸°ë³¸ ìš”êµ¬ì‚¬í•­)
        if len(keyword) < 2 or len(keyword) > 100:
            continue
        
        # ê·¹ì‹¬í•œ íŠ¹ìˆ˜ë¬¸ìë§Œ ì œê±° (SciMAT íŒŒì‹± ì˜¤ë¥˜ ë°©ì§€ìš©)
        keyword = re.sub(r'[^\w\s\-\.&\(\)]', '', keyword)  # ê¸°ë³¸ ë¬¸ìë§Œ ìœ ì§€
        keyword = re.sub(r'\s+', ' ', keyword).strip()  # ë‹¤ì¤‘ ê³µë°± ì •ë¦¬
        
        if keyword:
            # ì›ë³¸ í˜•íƒœ ìµœëŒ€í•œ ë³´ì¡´ (ëŒ€ì†Œë¬¸ì, ë„ì–´ì“°ê¸° ë“±)
            cleaned_keywords.append(keyword)
    
    # 3. ì¤‘ë³µ ì œê±° (ëŒ€ì†Œë¬¸ì êµ¬ë¶„í•˜ì—¬ ë‹¤ì–‘ì„± ë³´ì¡´)
    # ì™„ì „íˆ ë™ì¼í•œ ê²ƒë§Œ ì œê±°
    seen = set()
    final_keywords = []
    for kw in cleaned_keywords:
        if kw.lower() not in seen:
            seen.add(kw.lower())
            final_keywords.append(kw)
    
    # 4. SciMAT í‘œì¤€ êµ¬ë¶„ìë¡œ ì—°ê²°
    return '; '.join(final_keywords)

# --- SCIMAT í˜•ì‹ ë³€í™˜ í•¨ìˆ˜ ---
def convert_df_to_scimat_format(df_to_convert):
    """SciMAT í˜¸í™˜ WOS í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    wos_field_order = [
        'PT', 'AU', 'AF', 'TI', 'SO', 'LA', 'DT', 'DE', 'ID', 'AB', 'C1', 'C3', 'RP',
        'EM', 'RI', 'OI', 'FU', 'FX', 'CR', 'NR', 'TC', 'Z9', 'U1', 'U2', 'PU', 'PI', 'PA',
        'SN', 'EI', 'J9', 'JI', 'PD', 'PY', 'VL', 'IS', 'BP', 'EP', 'DI', 'EA', 'PG',
        'WC', 'WE', 'SC', 'GA', 'UT', 'PM', 'OA', 'DA'
    ]
    file_content = ["FN Clarivate Analytics Web of Science", "VR 1.0"]
    multi_line_fields = ['AU', 'AF', 'DE', 'ID', 'C1', 'C3', 'CR']

    for _, row in df_to_convert.iterrows():
        if len(file_content) > 2:
            file_content.append("")
        sorted_tags = [tag for tag in wos_field_order if tag in row.index and pd.notna(row[tag])]

        for tag in sorted_tags:
            value = row[tag]
            if pd.isna(value) or not str(value).strip():
                continue
            if not isinstance(value, str):
                value = str(value)

            if tag in multi_line_fields:
                items = [item.strip() for item in value.split(';') if item.strip()]
                if items:
                    file_content.append(f"{tag} {items[0]}")
                    for item in items[1:]:
                        file_content.append(f"   {item}")
            else:
                file_content.append(f"{tag} {value}")

        file_content.append("ER")
    return "\n".join(file_content).encode('utf-8')

# --- SciMAT í˜¸í™˜ì„± ì§„ë‹¨ í•¨ìˆ˜ ---
def diagnose_scimat_readiness(df):
    """SciMAT ì¤€ë¹„ë„ ì§„ë‹¨"""
    issues = []
    recommendations = []
    
    # 1. í•„ìˆ˜ í•„ë“œ í™•ì¸
    if 'DE' not in df.columns and 'ID' not in df.columns:
        issues.append("âŒ í‚¤ì›Œë“œ í•„ë“œ ì—†ìŒ: DE ë˜ëŠ” ID í•„ë“œ í•„ìš”")
    
    # 2. í‚¤ì›Œë“œ í•„ë“œ ë¶„ì„
    for field in ['DE', 'ID']:
        if field in df.columns:
            valid_keywords = df[field].dropna()
            valid_keywords = valid_keywords[valid_keywords != '']
            
            if len(valid_keywords) == 0:
                issues.append(f"âŒ {field} í•„ë“œì— ìœ íš¨í•œ í‚¤ì›Œë“œ ì—†ìŒ")
                continue
            
            # í‚¤ì›Œë“œ ë‹¤ì–‘ì„± í™•ì¸
            all_keywords = []
            for keywords_str in valid_keywords:
                keywords_list = str(keywords_str).split(';')
                all_keywords.extend([kw.strip().lower() for kw in keywords_list if kw.strip()])
            
            unique_keywords = len(set(all_keywords))
            total_keywords = len(all_keywords)
            diversity_ratio = unique_keywords / total_keywords if total_keywords > 0 else 0
            
            if diversity_ratio < 0.3:
                issues.append(f"âš ï¸ {field} í‚¤ì›Œë“œ ë‹¤ì–‘ì„± ë¶€ì¡± ({diversity_ratio:.1%})")
                recommendations.append(f"ğŸ’¡ {field} í‚¤ì›Œë“œ ì •ê·œí™” ê°•ë„ë¥¼ ë‚®ì¶° ë‹¤ì–‘ì„± í™•ë³´")
            
            # í‰ê·  í‚¤ì›Œë“œ ìˆ˜ í™•ì¸
            keyword_counts = []
            for keywords_str in valid_keywords.head(100):  # ìƒ˜í”Œ 100ê°œ
                count = len([kw.strip() for kw in str(keywords_str).split(';') if kw.strip()])
                keyword_counts.append(count)
            
            avg_keywords = sum(keyword_counts) / len(keyword_counts) if keyword_counts else 0
            
            if avg_keywords < 2:
                issues.append(f"âš ï¸ {field} í‰ê·  í‚¤ì›Œë“œ ìˆ˜ ë¶€ì¡± ({avg_keywords:.1f}ê°œ)")
                recommendations.append(f"ğŸ’¡ {field} í‚¤ì›Œë“œ ì‚­ì œ ê¸°ì¤€ ì™„í™” í•„ìš”")
    
    return issues, recommendations

# --- ë©”ì¸ í—¤ë” ---
st.markdown("""
<div style="position: relative; text-align: center; padding: 2rem 0 3rem 0; background: linear-gradient(135deg, #003875, #0056b3); color: white; border-radius: 16px; margin-bottom: 2rem; box-shadow: 0 8px 32px rgba(0,56,117,0.3);">
    <div style="position: absolute; top: 1rem; left: 2rem; color: white;">
        <div style="font-size: 14px; font-weight: 600; margin-bottom: 2px;">HANYANG UNIVERSITY</div>
        <div style="font-size: 12px; opacity: 0.9;">Technology Management Research</div>
        <div style="font-size: 11px; opacity: 0.8; margin-top: 4px;">mot.hanyang.ac.kr</div>
    </div>
    <div style="position: absolute; top: 1rem; right: 2rem; text-align: right; color: rgba(255,255,255,0.9); font-size: 0.85rem;">
        <p style="margin: 0;"><strong>Developed by:</strong> ì„íƒœê²½ (Teddy Lym)</p>
    </div>
    <h1 style="font-size: 3.5rem; font-weight: 700; margin-bottom: 0.5rem; letter-spacing: -0.02em;">
        WOS Prep
    </h1>
    <p style="font-size: 1.3rem; margin: 0; font-weight: 400; opacity: 0.95;">
        SciMAT Compatible Edition for Live Streaming Research
    </p>
    <div style="width: 100px; height: 4px; background-color: rgba(255,255,255,0.3); margin: 2rem auto; border-radius: 2px;"></div>
</div>
""", unsafe_allow_html=True)

# --- ì£¼ìš” ê¸°ëŠ¥ ì†Œê°œ ---
st.markdown("""
<div class="feature-grid">
    <div class="feature-card">
        <div class="feature-icon">ğŸ”—</div>
        <div class="feature-title">SciMAT í˜¸í™˜ì„± ìµœìš°ì„ </div>
        <div class="feature-desc">Word Group ê¸°ëŠ¥ì´ ì •ìƒ ì‘ë™í•˜ë„ë¡ ì„¤ê³„</div>
    </div>
    <div class="feature-card">
        <div class="feature-icon">ğŸ”</div>
        <div class="feature-title">ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° íŠ¹í™”</div>
        <div class="feature-desc">29ë…„ ì—°êµ¬ ì§„í™” ë¶„ì„ì„ ìœ„í•œ í¬ê´„ì  ë¶„ë¥˜</div>
    </div>
    <div class="feature-card">
        <div class="feature-icon">âš¡</div>
        <div class="feature-title">ìµœì†Œ ì „ì²˜ë¦¬</div>
        <div class="feature-desc">í‚¤ì›Œë“œ ë‹¤ì–‘ì„± ë³´ì¡´ìœ¼ë¡œ ê·¸ë£¹í•‘ íš¨ê³¼ ê·¹ëŒ€í™”</div>
    </div>
</div>
""", unsafe_allow_html=True)

# --- SciMAT í˜¸í™˜ì„± ì•ˆë‚´ ---
st.markdown("""
<div class="warning-panel">
    <h4 style="color: #856404; margin-bottom: 16px;">ğŸ¯ SciMAT í˜¸í™˜ì„± ì „ëµ</h4>
    <ul style="line-height: 1.8; color: #856404;">
        <li><strong>í‚¤ì›Œë“œ ë‹¤ì–‘ì„± ë³´ì¡´:</strong> ì •ê·œí™”ë³´ë‹¤ëŠ” ì›ë³¸ í˜•íƒœ ìœ ì§€ ìš°ì„ </li>
        <li><strong>ìµœì†Œ ì „ì²˜ë¦¬:</strong> SciMAT íŒŒì‹± ì˜¤ë¥˜ë§Œ ë°©ì§€í•˜ëŠ” ìˆ˜ì¤€</li>
        <li><strong>Word Group ìµœì í™”:</strong> ìœ ì‚¬ í‚¤ì›Œë“œê°€ ì¡´ì¬í•´ì•¼ ê·¸ë£¹í•‘ ê°€ëŠ¥</li>
        <li><strong>ì„¸ë¯¸ì½œë¡  êµ¬ë¶„ì:</strong> SciMAT í‘œì¤€ êµ¬ë¶„ì ì—„ê²© ì¤€ìˆ˜</li>
    </ul>
</div>
""", unsafe_allow_html=True)

# --- íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ ---
st.markdown("""
<div class="section-header">
    <div class="section-title">ğŸ“ ë°ì´í„° ì—…ë¡œë“œ</div>
    <div class="section-subtitle">Web of Science Raw Data íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ SciMAT í˜¸í™˜ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.</div>
</div>
""", unsafe_allow_html=True)

st.markdown("""
<div class="upload-zone">
    <div style="font-size: 3rem; margin-bottom: 16px; color: #003875;">ğŸ“¤</div>
    <h3 style="color: #212529; margin-bottom: 8px;">íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”</h3>
    <p style="color: #6c757d; margin: 0;">Tab-delimited ë˜ëŠ” Plain Text í˜•ì‹ì˜ WOS ë°ì´í„° íŒŒì¼</p>
</div>
""", unsafe_allow_html=True)

uploaded_file = st.file_uploader(
    "íŒŒì¼ ì„ íƒ",
    type=['csv', 'txt'],
    label_visibility="collapsed"
)

if uploaded_file is not None:
    df = load_data(uploaded_file)
    if df is None:
        st.error("âš ï¸ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Web of Scienceì—ì„œ ë‹¤ìš´ë¡œë“œí•œ 'Tab-delimited' ë˜ëŠ” 'Plain Text' í˜•ì‹ì˜ íŒŒì¼ì´ ë§ëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
        st.stop()

    column_mapping = {
        'Authors': 'AU', 'Article Title': 'TI', 'Source Title': 'SO', 'Author Keywords': 'DE',
        'Keywords Plus': 'ID', 'Abstract': 'AB', 'Cited References': 'CR', 'Publication Year': 'PY',
        'Times Cited, All Databases': 'TC', 'Cited Reference Count': 'NR', 'Times Cited, WoS Core': 'Z9'
    }
    for old_name, new_name in column_mapping.items():
        if old_name in df.columns:
            df.rename(columns={old_name: new_name}, inplace=True)

    # í”„ë¡œê·¸ë ˆìŠ¤ ì¸ë””ì¼€ì´í„°
    st.markdown('<div class="progress-indicator"></div>', unsafe_allow_html=True)
    
    with st.spinner("ğŸ”„ SciMAT í˜¸í™˜ì„±ì„ ê³ ë ¤í•˜ì—¬ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
        # 1ë‹¨ê³„: ë…¼ë¬¸ ë¶„ë¥˜
        df['Classification'] = df.apply(classify_article, axis=1)

        # 2ë‹¨ê³„: ì›ë³¸ ë°±ì—…
        if 'DE' in df.columns: df['DE_Original'] = df['DE'].copy()
        if 'ID' in df.columns: df['ID_Original'] = df['ID'].copy()

        # 3ë‹¨ê³„: SciMAT í˜¸í™˜ í‚¤ì›Œë“œ ì²˜ë¦¬ (í¬í•¨ëœ ë…¼ë¬¸ë§Œ)
        include_mask = df['Classification'].str.contains('Include', na=False)

        if 'DE' in df.columns:
            df['DE_processed'] = df['DE'].copy()
            df.loc[include_mask, 'DE_processed'] = df.loc[include_mask, 'DE'].apply(scimat_compatible_keyword_processing)
        
        if 'ID' in df.columns:
            df['ID_processed'] = df['ID'].copy()
            df.loc[include_mask, 'ID_processed'] = df.loc[include_mask, 'ID'].apply(scimat_compatible_keyword_processing)

    st.success("âœ… SciMAT í˜¸í™˜ ì²˜ë¦¬ ì™„ë£Œ!")

    # --- SciMAT ì¤€ë¹„ë„ ì§„ë‹¨ ---
    st.markdown("""
    <div class="section-header">
        <div class="section-title">ğŸ” SciMAT ì¤€ë¹„ë„ ì§„ë‹¨</div>
        <div class="section-subtitle">SciMAT Word Group ê¸°ëŠ¥ ì‘ë™ ê°€ëŠ¥ì„± ê²€ì¦</div>
    </div>
    """, unsafe_allow_html=True)

    # ì§„ë‹¨ ì‹¤í–‰
    df_for_diagnosis = df.copy()
    if 'DE_processed' in df_for_diagnosis.columns:
        df_for_diagnosis['DE'] = df_for_diagnosis['DE_processed']
    if 'ID_processed' in df_for_diagnosis.columns:
        df_for_diagnosis['ID'] = df_for_diagnosis['ID_processed']

    issues, recommendations = diagnose_scimat_readiness(df_for_diagnosis)

    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown('<div class="chart-container">', unsafe_allow_html=True)
        st.markdown('<div class="chart-title">âš ï¸ ë°œê²¬ëœ ë¬¸ì œì </div>', unsafe_allow_html=True)
        
        if issues:
            for issue in issues:
                st.markdown(f"- {issue}")
        else:
            st.markdown("âœ… **ë¬¸ì œì  ì—†ìŒ** - SciMATì—ì„œ ì •ìƒ ì‘ë™ ì˜ˆìƒ")
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    with col2:
        st.markdown('<div class="chart-container">', unsafe_allow_html=True)
        st.markdown('<div class="chart-title">ğŸ’¡ ê°œì„  ê¶Œì¥ì‚¬í•­</div>', unsafe_allow_html=True)
        
        if recommendations:
            for rec in recommendations:
                st.markdown(f"- {rec}")
        else:
            st.markdown("ğŸ¯ **ì¶”ê°€ ê°œì„  ë¶ˆí•„ìš”** - í˜„ì¬ ìƒíƒœê°€ ìµœì ")
        
        st.markdown('</div>', unsafe_allow_html=True)

    # --- ë¶„ì„ ê²°ê³¼ ìš”ì•½ ---
    st.markdown("""
    <div class="section-header">
        <div class="section-title">ğŸ“ˆ ë¶„ì„ ê²°ê³¼ ìš”ì•½</div>
        <div class="section-subtitle">ì²˜ë¦¬ ê²°ê³¼ ë° SciMAT ì¤€ë¹„ í˜„í™©</div>
    </div>
    """, unsafe_allow_html=True)

    # ë©”íŠ¸ë¦­ ì¹´ë“œë“¤
    col1, col2, col3, col4 = st.columns(4)
    
    classification_counts = df['Classification'].value_counts()
    total_papers = len(df)
    include_papers = len(df[df['Classification'].str.contains('Include', na=False)])
    
    with col1:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon">ğŸ“‹</div>
            <div class="metric-value">{total_papers:,}</div>
            <div class="metric-label">Total Papers</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon">âœ…</div>
            <div class="metric-value">{include_papers:,}</div>
            <div class="metric-label">Included Studies</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        processing_rate = (include_papers / total_papers * 100) if total_papers > 0 else 0
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon">ğŸ“Š</div>
            <div class="metric-value">{processing_rate:.1f}%</div>
            <div class="metric-label">Inclusion Rate</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        # í‚¤ì›Œë“œ ë‹¤ì–‘ì„± ê³„ì‚°
        diversity_score = 0
        if 'DE_processed' in df.columns:
            all_keywords = []
            for text in df.loc[include_mask, 'DE_processed'].dropna():
                keywords = [kw.strip().lower() for kw in text.split(';') if kw.strip()]
                all_keywords.extend(keywords)
            
            if all_keywords:
                unique_count = len(set(all_keywords))
                total_count = len(all_keywords)
                diversity_score = (unique_count / total_count * 100) if total_count > 0 else 0
        
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon">ğŸ¯</div>
            <div class="metric-value">{diversity_score:.1f}%</div>
            <div class="metric-label">Keyword Diversity</div>
        </div>
        """, unsafe_allow_html=True)

    # --- ë…¼ë¬¸ ë¶„ë¥˜ í˜„í™© ---
    st.markdown("""
    <div class="chart-container">
        <div class="chart-title">Research Classification Distribution</div>
    """, unsafe_allow_html=True)

    classification_counts_df = df['Classification'].value_counts().reset_index()
    classification_counts_df.columns = ['ë¶„ë¥˜', 'ë…¼ë¬¸ ìˆ˜']

    col1, col2 = st.columns([0.4, 0.6])
    with col1:
        st.dataframe(classification_counts_df, use_container_width=True, hide_index=True)

    with col2:
        # ë„ë„› ì°¨íŠ¸
        selection = alt.selection_point(fields=['ë¶„ë¥˜'], on='mouseover', nearest=True)

        base = alt.Chart(classification_counts_df).encode(
            theta=alt.Theta(field="ë…¼ë¬¸ ìˆ˜", type="quantitative", stack=True),
            color=alt.Color(field="ë¶„ë¥˜", type="nominal", title="Classification",
                           scale=alt.Scale(range=['#003875', '#0056b3', '#17a2b8', '#ffc107', '#dc3545']),
                           legend=alt.Legend(orient="right", titleColor="#212529", labelColor="#495057")),
            opacity=alt.condition(selection, alt.value(1), alt.value(0.8))
        ).add_params(selection)

        pie = base.mark_arc(outerRadius=120, innerRadius=70)
        text_total = alt.Chart(pd.DataFrame([{'value': f'{total_papers}'}])).mark_text(
            align='center', baseline='middle', fontSize=35, fontWeight='bold', color='#003875'
        ).encode(text='value:N')
        text_label = alt.Chart(pd.DataFrame([{'value': 'Total Papers'}])).mark_text(
            align='center', baseline='middle', fontSize=14, dy=-25, color='#495057'
        ).encode(text='value:N')

        chart = (pie + text_total + text_label).properties(
            title=alt.TitleParams(text='ë…¼ë¬¸ ë¶„ë¥˜ ë¶„í¬', anchor='middle', fontSize=16, fontWeight=500, color="#212529"),
            width=300, height=300
        ).configure_view(strokeWidth=0)
        st.altair_chart(chart, use_container_width=True)

    st.markdown("</div>", unsafe_allow_html=True)

    # --- í‚¤ì›Œë“œ ì²˜ë¦¬ ì „í›„ ë¹„êµ ---
    st.markdown("""
    <div class="chart-container">
        <div class="chart-title">Keyword Processing Comparison (SciMAT Compatibility Focus)</div>
    """, unsafe_allow_html=True)
    
    if st.checkbox("ğŸ” í‚¤ì›Œë“œ ì²˜ë¦¬ ì „í›„ ë¹„êµ ë³´ê¸° (ìƒ˜í”Œ)", key="comparison_check"):
        sample_data = []
        sample_rows = df.loc[include_mask].head(5)
        
        for idx, row in sample_rows.iterrows():
            if 'DE_Original' in df.columns and pd.notna(row.get('DE_Original')):
                original = str(row['DE_Original'])[:100] + "..." if len(str(row['DE_Original'])) > 100 else str(row['DE_Original'])
                processed = str(row.get('DE_processed', ''))[:100] + "..." if len(str(row.get('DE_processed', ''))) > 100 else str(row.get('DE_processed', ''))
                
                # í‚¤ì›Œë“œ ìˆ˜ ê³„ì‚°
                original_count = len([k.strip() for k in str(row['DE_Original']).split(';') if k.strip()]) if pd.notna(row['DE_Original']) else 0
                processed_count = len([k.strip() for k in str(row.get('DE_processed', '')).split(';') if k.strip()]) if row.get('DE_processed') else 0
                
                sample_data.append({
                    'ë…¼ë¬¸ ID': f"#{idx}",
                    'í•„ë“œ': 'DE (Author Keywords)',
                    'ì›ë³¸ í‚¤ì›Œë“œ': original,
                    'ì²˜ë¦¬ í›„ í‚¤ì›Œë“œ': processed,
                    'ì›ë³¸ ìˆ˜': original_count,
                    'ì²˜ë¦¬ í›„ ìˆ˜': processed_count,
                    'ë³´ì¡´ìœ¨': f"{(processed_count/original_count*100):.1f}%" if original_count > 0 else "0%"
                })
        
        if sample_data:
            comparison_df = pd.DataFrame(sample_data)
            st.dataframe(comparison_df, use_container_width=True, hide_index=True)
            
            # ë³´ì¡´ìœ¨ í†µê³„
            preservation_rates = [float(d['ë³´ì¡´ìœ¨'].replace('%', '')) for d in sample_data if d['ë³´ì¡´ìœ¨'] != '0%']
            if preservation_rates:
                avg_preservation = sum(preservation_rates) / len(preservation_rates)
                
                if avg_preservation >= 90:
                    st.success(f"âœ… ìš°ìˆ˜í•œ í‚¤ì›Œë“œ ë³´ì¡´ìœ¨: í‰ê·  {avg_preservation:.1f}% (SciMAT Word Group ì •ìƒ ì‘ë™ ì˜ˆìƒ)")
                elif avg_preservation >= 70:
                    st.warning(f"âš ï¸ ì–‘í˜¸í•œ í‚¤ì›Œë“œ ë³´ì¡´ìœ¨: í‰ê·  {avg_preservation:.1f}% (SciMATì—ì„œ ì¼ë¶€ ê·¸ë£¹í•‘ ì œí•œ ê°€ëŠ¥)")
                else:
                    st.error(f"âŒ ë‚®ì€ í‚¤ì›Œë“œ ë³´ì¡´ìœ¨: í‰ê·  {avg_preservation:.1f}% (Word Group ê¸°ëŠ¥ ì œí•œì )")

    st.markdown("</div>", unsafe_allow_html=True)

    # --- ì—°ë„ë³„ ì—°êµ¬ ë™í–¥ ---
    st.markdown("""
    <div class="chart-container">
        <div class="chart-title">Research Trend Analysis (1996-2024)</div>
    """, unsafe_allow_html=True)
    
    df_trend = df.copy()
    if 'PY' in df_trend.columns:
        df_trend['PY'] = pd.to_numeric(df_trend['PY'], errors='coerce')
        df_trend.dropna(subset=['PY'], inplace=True)
        df_trend['PY'] = df_trend['PY'].astype(int)
        
        yearly_counts = df_trend['PY'].value_counts().reset_index()
        yearly_counts.columns = ['Year', 'Count']
        yearly_counts = yearly_counts[yearly_counts['Year'] <= 2025].sort_values('Year')

        selection_trend = alt.selection_point(fields=['Year'], on='mouseover', nearest=True, empty='none')
        
        line_chart = alt.Chart(yearly_counts).mark_line(
            point={'size': 80, 'filled': True}, strokeWidth=3, color='#003875'
        ).encode(
            x=alt.X('Year:O', title='ë°œí–‰ ì—°ë„'),
            y=alt.Y('Count:Q', title='ë…¼ë¬¸ ìˆ˜'),
            tooltip=['Year', 'Count'],
            opacity=alt.condition(selection_trend, alt.value(1), alt.value(0.8))
        ).add_params(selection_trend)
        
        trend_chart = line_chart.properties(height=350)
        st.altair_chart(trend_chart, use_container_width=True)
        
        # ë³€ê³¡ì  ë¶„ì„
        if len(yearly_counts) >= 10:
            st.markdown("""
            <div class="info-panel">
                <h4 style="color: #003875; margin-bottom: 12px;">ğŸ“ˆ 29ë…„ ì—°êµ¬ ì§„í™” íŒ¨í„´</h4>
                <p style="margin: 4px 0; color: #495057;">â€¢ <strong>1996-2006 (íƒœë™ê¸°):</strong> ê¸°ìˆ ì  ê¸°ë°˜ ì—°êµ¬ ì¤‘ì‹¬</p>
                <p style="margin: 4px 0; color: #495057;">â€¢ <strong>2007-2016 (í˜•ì„±ê¸°):</strong> í”Œë«í¼ ë“±ì¥ê³¼ ì‚¬ìš©ì ì—°êµ¬ ì‹œì‘</p>
                <p style="margin: 4px 0; color: #495057;">â€¢ <strong>2017-2021 (í™•ì‚°ê¸°):</strong> ì†Œì…œ ë¯¸ë””ì–´ì™€ ìƒì—…ì  í™œìš© ê¸‰ì¦</p>
                <p style="margin: 4px 0; color: #495057;">â€¢ <strong>2022-2024 (ì„±ìˆ™ê¸°):</strong> ë¼ì´ë¸Œ ì»¤ë¨¸ìŠ¤ì™€ ë©”íƒ€ë²„ìŠ¤ ìœµí•©</p>
            </div>
            """, unsafe_allow_html=True)
    else:
        st.warning("âš ï¸ ë°œí–‰ ì—°ë„(PY) ë°ì´í„°ê°€ ì—†ì–´ ì—°êµ¬ ë™í–¥ì„ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    st.markdown("</div>", unsafe_allow_html=True)

    # --- ìµœì¢… ë°ì´í„°ì…‹ ì¤€ë¹„ ---
    st.markdown("""
    <div class="section-header">
        <div class="section-title">ğŸ’¾ SciMAT í˜¸í™˜ íŒŒì¼ ë‹¤ìš´ë¡œë“œ</div>
        <div class="section-subtitle">Word Group ê¸°ëŠ¥ ìµœì í™”ëœ ìµœì¢… ë°ì´í„°ì…‹</div>
    </div>
    """, unsafe_allow_html=True)

    # ìµœì¢… ë°ì´í„°ì…‹ ì¤€ë¹„
    df_final = df[~df['Classification'].str.contains('Exclude', na=False)].copy()
    
    # ì²˜ë¦¬ëœ í‚¤ì›Œë“œ ì ìš©
    if 'DE_processed' in df_final.columns:
        df_final['DE'] = df_final['DE_processed']
    if 'ID_processed' in df_final.columns:
        df_final['ID'] = df_final['ID_processed']
    
    # ë¶ˆí•„ìš”í•œ ì»¬ëŸ¼ ì œê±°
    cols_to_drop = ['Classification', 'DE_processed', 'ID_processed', 'DE_Original', 'ID_Original']
    df_final_output = df_final.drop(columns=[col for col in cols_to_drop if col in df_final.columns], errors='ignore')

    # ìµœì¢… í†µê³„
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon">ğŸ“‹</div>
            <div class="metric-value">{len(df_final_output):,}</div>
            <div class="metric-label">ìµœì¢… ë¶„ì„ ëŒ€ìƒ</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        include_count = len(df[df['Classification'].str.contains('Include', na=False)])
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon">âœ…</div>
            <div class="metric-value">{include_count:,}</div>
            <div class="metric-label">í•µì‹¬ + ê¸°ìˆ ê¸°ë°˜</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        review_count = len(df[df['Classification'].str.contains('Review', na=False)])
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon">ğŸ“</div>
            <div class="metric-value">{review_count:,}</div>
            <div class="metric-label">ê²€í†  ëŒ€ìƒ</div>
        </div>
        """, unsafe_allow_html=True)

    # SciMAT í˜¸í™˜ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    text_data = convert_df_to_scimat_format(df_final_output)
    
    col1, col2 = st.columns([0.7, 0.3])
    
    with col1:
        st.download_button(
            label="ğŸ”¥ SciMAT í˜¸í™˜ íŒŒì¼ ë‹¤ìš´ë¡œë“œ (.txt)",
            data=text_data,
            file_name="live_streaming_scimat_compatible.txt",
            mime="text/plain",
            type="primary",
            use_container_width=True
        )
    
    with col2:
        # í…ŒìŠ¤íŠ¸ íŒŒì¼ ë‹¤ìš´ë¡œë“œ (50ê°œ ìƒ˜í”Œ)
        df_test = df_final_output.head(50)
        test_data = convert_df_to_scimat_format(df_test)
        
        st.download_button(
            label="ğŸ§ª í…ŒìŠ¤íŠ¸ íŒŒì¼ (50ê°œ)",
            data=test_data,
            file_name="test_scimat_50papers.txt",
            mime="text/plain",
            use_container_width=True
        )

    # SciMAT ì‚¬ìš© ê°€ì´ë“œ
    st.markdown("""
    <div class="info-panel">
        <h4 style="color: #003875; margin-bottom: 16px;">ğŸ¯ SciMAT ì‚¬ìš© ê°€ì´ë“œ (í˜¸í™˜ì„± ìš°ì„ )</h4>
        <ol style="line-height: 1.8; color: #495057;">
            <li><strong>í…ŒìŠ¤íŠ¸ ìš°ì„ :</strong> ë¨¼ì € <code>test_scimat_50papers.txt</code> íŒŒì¼ë¡œ SciMATì—ì„œ ì •ìƒ ì‘ë™ í™•ì¸</li>
            <li><strong>Word Group í™•ì¸:</strong> <code>Group set â†’ Words groups manager</code>ì—ì„œ í‚¤ì›Œë“œ ëª©ë¡ì´ ë‚˜íƒ€ë‚˜ëŠ”ì§€ ê²€ì¦</li>
            <li><strong>ìë™ ê·¸ë£¹í•‘:</strong> Levenshtein distanceë¡œ ìœ ì‚¬ í‚¤ì›Œë“œ ìë™ ê·¸ë£¹í™” ì‹œë„</li>
            <li><strong>ìˆ˜ë™ ì¡°ì •:</strong> ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° íŠ¹í™” í‚¤ì›Œë“œ ê·¸ë£¹ ìˆ˜ë™ ìƒì„±</li>
            <li><strong>ì „ì²´ ë¶„ì„:</strong> í…ŒìŠ¤íŠ¸ ì„±ê³µ ì‹œ ì „ì²´ íŒŒì¼ë¡œ 29ë…„ ì§„í™” ë¶„ì„ ì‹¤í–‰</li>
        </ol>
        
        <div style="margin-top: 16px; padding: 12px; background: #d1ecf1; border-left: 4px solid #17a2b8; border-radius: 4px;">
            <strong>ğŸ’¡ í•µì‹¬ í¬ì¸íŠ¸:</strong> ì´ íŒŒì¼ì€ í‚¤ì›Œë“œ ë‹¤ì–‘ì„±ì„ ìµœëŒ€í•œ ë³´ì¡´í•˜ì—¬ SciMAT Word Group ê¸°ëŠ¥ì´ ì •ìƒ ì‘ë™í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.
        </div>
        
        <div style="margin-top: 12px; padding: 12px; background: #d4edda; border-left: 4px solid #28a745; border-radius: 4px;">
            <strong>ğŸ¯ ì˜ˆìƒ ê²°ê³¼:</strong> ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ ë¶„ì•¼ ìµœì´ˆì˜ ì¢…í•©ì  ì§€ì‹ êµ¬ì¡° ì§„í™” ë¶„ì„ (1996-2024)
        </div>
    </div>
    """, unsafe_allow_html=True)

# --- í•˜ë‹¨ ì—¬ë°± ---
st.markdown("<br><br>", unsafe_allow_html=True)
