import streamlit as st
import pandas as pd
import altair as alt
import io
import re
from collections import Counter

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="WOS Multi-File Merger | SCIMAT Edition",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# --- í† ìŠ¤ ìŠ¤íƒ€ì¼ CSS ---
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Pretendard:wght@400;500;600;700&display=swap');
    
    .main-container {
        background: #f2f4f6;
        min-height: 100vh;
        font-family: 'Pretendard', -apple-system, BlinkMacSystemFont, system-ui, sans-serif;
    }
    
    .metric-card {
        background: white;
        border-radius: 8px;
        padding: 20px;
        box-shadow: none;
        border: 1px solid #e5e8eb;
        margin-bottom: 12px;
        transition: all 0.2s ease;
    }
    
    .metric-card:hover {
        box-shadow: 0 2px 8px rgba(0,0,0,0.08);
        transform: translateY(-1px);
        border-color: #3182f6;
    }
    
    .metric-value {
        font-size: 2.2rem;
        font-weight: 700;
        color: #191f28;
        margin: 0;
        line-height: 1.2;
        letter-spacing: -0.02em;
    }
    
    .metric-label {
        font-size: 13px;
        color: #8b95a1;
        margin: 6px 0 0 0;
        font-weight: 500;
        letter-spacing: -0.01em;
    }
    
    .metric-icon {
        background: #3182f6;
        color: white;
        width: 32px;
        height: 32px;
        border-radius: 6px;
        display: flex;
        align-items: center;
        justify-content: center;
        font-size: 16px;
        margin-bottom: 12px;
    }
    
    .chart-container {
        background: white;
        border-radius: 8px;
        padding: 24px;
        box-shadow: none;
        border: 1px solid #e5e8eb;
        margin: 16px 0;
    }
    
    .chart-title {
        font-size: 16px;
        font-weight: 600;
        color: #191f28;
        margin-bottom: 16px;
        letter-spacing: -0.01em;
    }
    
    .section-header {
        background: white;
        color: #191f28;
        padding: 16px 20px;
        border-radius: 8px;
        margin: 20px 0 12px 0;
        box-shadow: none;
        border: 1px solid #e5e8eb;
        position: relative;
        overflow: hidden;
    }
    
    .section-header::before {
        content: '';
        position: absolute;
        top: 0;
        left: 0;
        width: 4px;
        height: 100%;
        background: #3182f6;
    }
    
    .section-title {
        font-size: 16px;
        font-weight: 600;
        margin: 0;
        letter-spacing: -0.01em;
        color: #191f28;
    }
    
    .section-subtitle {
        font-size: 13px;
        color: #8b95a1;
        margin: 4px 0 0 0;
        font-weight: 400;
        letter-spacing: 0;
    }
    
    .info-panel {
        background: #f8fafe;
        border: 1px solid #e1f2ff;
        border-radius: 8px;
        padding: 16px;
        margin: 12px 0;
        position: relative;
    }
    
    .success-panel {
        background: #f0fdf4;
        border: 1px solid #dcfce7;
        border-radius: 8px;
        padding: 16px;
        margin: 12px 0;
        position: relative;
    }
    
    .warning-panel {
        background: #fffbeb;
        border: 1px solid #fed7aa;
        border-radius: 8px;
        padding: 16px;
        margin: 12px 0;
        position: relative;
    }
    
    .feature-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
        gap: 12px;
        margin: 20px 0;
    }
    
    .feature-card {
        background: white;
        border-radius: 8px;
        padding: 20px;
        text-align: center;
        box-shadow: none;
        border: 1px solid #e5e8eb;
        transition: all 0.2s ease;
        position: relative;
        overflow: hidden;
    }
    
    .feature-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(0,0,0,0.08);
        border-color: #3182f6;
    }
    
    .feature-icon {
        font-size: 32px;
        margin-bottom: 12px;
        color: #3182f6;
    }
    
    .feature-title {
        font-size: 15px;
        font-weight: 600;
        color: #191f28;
        margin-bottom: 8px;
        letter-spacing: -0.01em;
    }
    
    .feature-desc {
        font-size: 13px;
        color: #8b95a1;
        line-height: 1.5;
        letter-spacing: 0;
    }
    
    .upload-zone {
        background: white;
        border: 1px dashed #d1d5db;
        border-radius: 8px;
        padding: 24px;
        text-align: center;
        margin: 16px 0;
        transition: all 0.2s ease;
    }
    
    .upload-zone:hover {
        background: #f8fafe;
        border-color: #3182f6;
    }
    
    .progress-indicator {
        background: #3182f6;
        height: 3px;
        border-radius: 2px;
        margin: 12px 0;
        animation: pulse 2s infinite;
    }
    
    .file-status {
        background: #f8fafe;
        border-radius: 6px;
        padding: 12px;
        margin: 8px 0;
        border-left: 3px solid #3182f6;
        font-family: 'Pretendard', sans-serif;
    }
    
    .stDownloadButton > button {
        background: #3182f6 !important;
        color: white !important;
        border: none !important;
        border-radius: 8px !important;
        padding: 12px 24px !important;
        font-weight: 600 !important;
        font-size: 14px !important;
        letter-spacing: -0.01em !important;
        transition: all 0.2s ease !important;
        box-shadow: 0 1px 3px rgba(0,0,0,0.1) !important;
        font-family: 'Pretendard', sans-serif !important;
    }
    
    .stDownloadButton > button:hover {
        background: #1c64f2 !important;
        transform: translateY(-1px) !important;
        box-shadow: 0 2px 6px rgba(0,0,0,0.15) !important;
    }
    
    .streamlit-expanderHeader {
        background: white !important;
        border-radius: 8px !important;
        border: 1px solid #e5e8eb !important;
        font-weight: 500 !important;
        color: #191f28 !important;
        font-family: 'Pretendard', sans-serif !important;
        font-size: 14px !important;
    }
    
    .stDataFrame {
        border-radius: 8px !important;
        overflow: hidden !important;
        border: 1px solid #e5e8eb !important;
    }
    
    .stSpinner {
        color: #3182f6 !important;
    }
    
    @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.6; }
    }
    
    .main .block-container {
        padding-top: 1.5rem;
        padding-bottom: 1.5rem;
        max-width: 1200px;
    }
    
    .stAlert {
        border-radius: 8px !important;
        border: none !important;
        font-family: 'Pretendard', sans-serif !important;
        font-size: 14px !important;
    }
    
    .stSuccess {
        background: #f0fdf4 !important;
        color: #15803d !important;
    }
    
    .stInfo {
        background: #f8fafe !important;
        color: #1d4ed8 !important;
    }
    
    .stWarning {
        background: #fffbeb !important;
        color: #d97706 !important;
    }
    
    .stError {
        background: #fef2f2 !important;
        color: #dc2626 !important;
    }
    
    .main-text {
        font-size: 14px;
        color: #191f28;
        line-height: 1.5;
    }
    
    .sub-text {
        font-size: 13px;
        color: #8b95a1;
        line-height: 1.4;
    }
    
    .small-text {
        font-size: 12px;
        color: #8b95a1;
        line-height: 1.3;
    }
</style>
""", unsafe_allow_html=True)

# --- ë‹¤ì¤‘ WOS Plain Text íŒŒì¼ ë¡œë”© ë° ë³‘í•© í•¨ìˆ˜ ---
def load_and_merge_wos_files(uploaded_files):
    """ë‹¤ì¤‘ WOS Plain Text íŒŒì¼ì„ ë¡œë”©í•˜ê³  ë³‘í•© - ì¤‘ë³µ ì œê±° ì™„ì „ ìˆ˜ì •"""
    all_dataframes = []
    file_status = []
    
    for i, uploaded_file in enumerate(uploaded_files):
        try:
            file_bytes = uploaded_file.getvalue()
            encodings_to_try = ['utf-8-sig', 'utf-8', 'latin1', 'iso-8859-1']
            
            df = None
            encoding_used = None
            
            for encoding in encodings_to_try:
                try:
                    file_content = file_bytes.decode(encoding)
                    
                    # WOS ì›ë³¸ í˜•ì‹ ê²€ì¦ (FNìœ¼ë¡œ ì‹œì‘í•´ì•¼ í•¨)
                    if not file_content.strip().startswith('FN '):
                        continue
                        
                    # WOS í˜•ì‹ íŒŒì‹±
                    df = parse_wos_format(file_content)
                    if df is not None and len(df) > 0:
                        encoding_used = encoding
                        break
                        
                except Exception:
                    continue
            
            if df is not None:
                all_dataframes.append(df)
                file_status.append({
                    'filename': uploaded_file.name,
                    'status': 'SUCCESS',
                    'papers': len(df),
                    'encoding': encoding_used,
                    'message': f'âœ… {len(df)}í¸ ë…¼ë¬¸ ë¡œë”© ì„±ê³µ'
                })
            else:
                file_status.append({
                    'filename': uploaded_file.name,
                    'status': 'ERROR',
                    'papers': 0,
                    'encoding': 'N/A',
                    'message': 'âŒ WOS Plain Text í˜•ì‹ì´ ì•„ë‹˜'
                })
                
        except Exception as e:
            file_status.append({
                'filename': uploaded_file.name,
                'status': 'ERROR',
                'papers': 0,
                'encoding': 'N/A',
                'message': f'âŒ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)[:50]}'
            })
    
    # ëª¨ë“  ë°ì´í„°í”„ë ˆì„ ë³‘í•©
    if all_dataframes:
        merged_df = pd.concat(all_dataframes, ignore_index=True)
        original_count = len(merged_df)
        
        # ì¤‘ë³µ ì œê±° ë¡œì§ - ì™„ì „íˆ ìƒˆë¡œ ì‘ì„±
        duplicates_removed = 0
        
        if 'UT' in merged_df.columns:
            # UT í•„ë“œì˜ ì‹¤ì œ ê°’ë“¤ í™•ì¸
            ut_series = merged_df['UT'].copy()
            
            # ìœ íš¨í•œ UT ê°’ë§Œ í•„í„°ë§ (ë” ì—„ê²©í•œ ì¡°ê±´)
            def is_meaningful_ut(value):
                if pd.isna(value):
                    return False
                str_value = str(value).strip()
                # ë¹ˆ ë¬¸ìì—´, 'nan', 'None', ë§¤ìš° ì§§ì€ ê°’ë“¤ ì œì™¸
                if len(str_value) == 0 or str_value.lower() in ['nan', 'none', 'null', '']:
                    return False
                # WOS UTëŠ” ì¼ë°˜ì ìœ¼ë¡œ 'WOS:' ë˜ëŠ” ë¬¸ì+ìˆ«ì ì¡°í•©
                # ìµœì†Œ 10ì ì´ìƒì˜ ì˜ë¯¸ìˆëŠ” ê°’ë§Œ ìœ íš¨í•œ ê²ƒìœ¼ë¡œ ê°„ì£¼
                if len(str_value) < 10:
                    return False
                # 'WOS:' ë¡œ ì‹œì‘í•˜ê±°ë‚˜ ì¶©ë¶„íˆ ê¸´ ì˜ìˆ«ì ì¡°í•©ì¸ ê²½ìš°ë§Œ ìœ íš¨
                if str_value.startswith('WOS:') or (len(str_value) >= 15 and any(c.isalnum() for c in str_value)):
                    return True
                return False
            
            # ìœ íš¨í•œ UTë¥¼ ê°€ì§„ í–‰ë“¤ë§Œ ì„ ë³„
            meaningful_ut_mask = ut_series.apply(is_meaningful_ut)
            rows_with_meaningful_ut = merged_df[meaningful_ut_mask]
            rows_without_meaningful_ut = merged_df[~meaningful_ut_mask]
            
            # ì‹¤ì œë¡œ ì˜ë¯¸ìˆëŠ” UTê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ ì¤‘ë³µ ê²€ì‚¬
            if len(rows_with_meaningful_ut) > 1:  # ìµœì†Œ 2ê°œ ì´ìƒ ìˆì–´ì•¼ ì¤‘ë³µ ê²€ì‚¬ ì˜ë¯¸
                # ì¤‘ë³µ ì œê±° ì „í›„ ë¹„êµ
                before_dedup = len(rows_with_meaningful_ut)
                deduplicated_meaningful = rows_with_meaningful_ut.drop_duplicates(subset=['UT'], keep='first')
                after_dedup = len(deduplicated_meaningful)
                
                actual_duplicates = before_dedup - after_dedup
                
                if actual_duplicates > 0:
                    duplicates_removed = actual_duplicates
                    
                    # ì¤‘ë³µ ì œê±°ëœ ê²°ê³¼ì™€ UT ì—†ëŠ” í–‰ë“¤ ì¬ê²°í•©
                    merged_df = pd.concat([deduplicated_meaningful, rows_without_meaningful_ut], ignore_index=True)
        
        # ëŒ€ì•ˆ: UTê°€ ì—†ê±°ë‚˜ ì‹ ë¢°í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ì œëª©+ì €ì ê¸°ì¤€ ì¤‘ë³µ ì œê±°
        if duplicates_removed == 0 and 'TI' in merged_df.columns:
            # ì œëª©ê³¼ ì²« ë²ˆì§¸ ì €ì ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ í™•ì¸ (ë§¤ìš° ë³´ìˆ˜ì )
            title_author_before = len(merged_df)
            
            # ì œëª©ì´ ìˆê³  ì €ìê°€ ìˆëŠ” í–‰ë“¤ë§Œ ëŒ€ìƒ
            has_title = merged_df['TI'].notna() & (merged_df['TI'].str.strip() != '')
            has_author = merged_df.get('AU', pd.Series()).notna() if 'AU' in merged_df.columns else pd.Series([False] * len(merged_df))
            
            complete_rows = merged_df[has_title & has_author] if 'AU' in merged_df.columns else merged_df[has_title]
            incomplete_rows = merged_df[~(has_title & has_author)] if 'AU' in merged_df.columns else merged_df[~has_title]
            
            if len(complete_rows) > 1:
                dedup_columns = ['TI', 'AU'] if 'AU' in merged_df.columns else ['TI']
                deduplicated_complete = complete_rows.drop_duplicates(subset=dedup_columns, keep='first')
                title_author_removed = len(complete_rows) - len(deduplicated_complete)
                
                if title_author_removed > 0:
                    duplicates_removed = title_author_removed
                    merged_df = pd.concat([deduplicated_complete, incomplete_rows], ignore_index=True)
        
        return merged_df, file_status, duplicates_removed
    else:
        return None, file_status, 0

def parse_wos_format(content):
    """WOS Plain Text í˜•ì‹ì„ DataFrameìœ¼ë¡œ ë³€í™˜"""
    lines = content.split('\n')
    records = []
    current_record = {}
    current_field = None
    
    for line in lines:
        line = line.rstrip()
        
        if not line:
            continue
            
        # ë ˆì½”ë“œ ì¢…ë£Œ
        if line == 'ER':
            if current_record:
                records.append(current_record.copy())
                current_record = {}
                current_field = None
            continue
            
        # í—¤ë” ë¼ì¸ ê±´ë„ˆë›°ê¸°
        if line.startswith(('FN ', 'VR ')):
            continue
            
        # ìƒˆ í•„ë“œ ì‹œì‘
        if not line.startswith('   ') and ' ' in line:
            parts = line.split(' ', 1)
            if len(parts) == 2:
                field_tag, field_value = parts
                current_field = field_tag
                current_record[field_tag] = field_value.strip()
        
        # ê¸°ì¡´ í•„ë“œ ì—°ì†
        elif line.startswith('   ') and current_field and current_field in current_record:
            continuation_value = line[3:].strip()
            if continuation_value:
                current_record[current_field] += '; ' + continuation_value
    
    # ë§ˆì§€ë§‰ ë ˆì½”ë“œ ì²˜ë¦¬
    if current_record:
        records.append(current_record)
    
    if not records:
        return None
        
    return pd.DataFrame(records)

# --- ê°œì„ ëœ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° íŠ¹í™” ë¶„ë¥˜ í•¨ìˆ˜ ---
def classify_article(row):
    """PRISMA 2020 ê¸°ë°˜ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ ë¶„ë¥˜ - EC1-EC8 ê°•í™” ë° ëª…í™•í•œ í¬í•¨ê¸°ì¤€ ì ìš©"""
    
    # === PRISMA ìµœì¢… í¬í•¨ê¸°ì¤€ (IC: Inclusion Criteria) ===
    
    # IC1: ì‚¬íšŒ-ê¸°ìˆ  ì‹œìŠ¤í…œìœ¼ë¡œì„œì˜ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬
    core_livestreaming_keywords = [
        'live streaming', 'livestreaming', 'live stream', 'live broadcast', 'live video',
        'real time streaming', 'real-time streaming', 'streaming platform', 'streaming service',
        'live webcast', 'webcasting', 'live transmission', 'interactive broadcasting',
        'live commerce', 'live shopping', 'live selling', 'livestream commerce',
        'live e-commerce', 'social commerce', 'live marketing', 'streaming monetization',
        'streamer', 'viewer', 'audience engagement', 'streaming audience', 'live audience',
        'streaming behavior', 'viewer behavior', 'streaming experience', 'live interaction',
        'streaming community', 'online community', 'digital community', 'virtual community',
        'parasocial relationship', 'streamer-viewer', 'live chat', 'chat interaction',
        'twitch', 'youtube live', 'facebook live', 'instagram live', 'tiktok live',
        'periscope', 'douyin', 'kuaishou', 'taobao live', 'amazon live', 'shopee live'
    ]
    
    # IC2: ì‹¤ì‹œê°„ ì–‘ë°©í–¥ ìƒí˜¸ì‘ìš© í•„ìˆ˜ í‚¤ì›Œë“œ
    interactive_realtime_keywords = [
        'real-time interaction', 'real time interaction', 'interactive', 'bidirectional',
        'two-way communication', 'audience participation', 'user engagement',
        'live feedback', 'instant response', 'synchronous', 'chat', 'comment',
        'like', 'share', 'donate', 'gift', 'emoji reaction', 'viewer response',
        'interactive media', 'user participation', 'audience interaction'
    ]
    
    # IC3: í”Œë«í¼ ìƒíƒœê³„ ë§¥ë½ í‚¤ì›Œë“œ
    platform_ecosystem_keywords = [
        'platform', 'ecosystem', 'digital platform', 'online platform',
        'platform economy', 'network effects', 'multi-sided market',
        'platform governance', 'platform design', 'platform strategy'
    ]
    
    # === ì—„ê²©í•œ ë°°ì œê¸°ì¤€ (EC) ===
    
    # EC1: ë¹„í•™ìˆ  ë¬¸ì„œ
    excluded_document_types = [
        'editorial', 'letter', 'proceedings paper', 'book chapter', 'review',
        'correction', 'erratum', 'retracted publication', 'meeting abstract',
        'conference paper', 'conference review', 'note', 'short survey',
        'correspondence', 'commentary', 'opinion'
    ]
    
    # EC2: ì¤‘ë³µ ê²Œì¬
    duplicate_indicators = [
        'extended version', 'preliminary version', 'conference version',
        'short version', 'extended abstract', 'brief version',
        'expanded study', 'follow-up study', 'updated analysis'
    ]
    
    # EC3: ìˆœìˆ˜ í•˜ë“œì›¨ì–´ êµ¬í˜„ (ì‘ìš© ë§¥ë½ ì—†ìŒ)
    pure_hardware_exclusions = [
        'vlsi design', 'circuit design', 'antenna design', 'rf circuit',
        'hardware implementation', 'fpga implementation', 'asic design',
        'chip design', 'integrated circuit', 'semiconductor design'
    ]
    
    # EC4: ë¯¸ë˜ ì—°êµ¬ ì œì•ˆì—ë§Œ ì–¸ê¸‰
    future_only_patterns = [
        'future work', 'future research', 'future study', 'future direction',
        'recommendation', 'suggestion', 'further research', 'next step'
    ]
    
    # EC5: í”¼ìƒì  ì–¸ê¸‰ ì§€í‘œ
    superficial_mention_indicators = [
        'for example', 'such as', 'including', 'among others',
        'could be applied', 'might be useful', 'has potential', 'may benefit'
    ]
    
    # EC6: VOD/ì¼ë°˜ ë¹„ë””ì˜¤ (ì‹¤ì‹œê°„ì„± ì—†ìŒ)
    vod_general_video_indicators = [
        'video on demand', 'vod', 'recorded video', 'offline video',
        'pre-recorded content', 'stored video', 'archived content',
        'downloaded video', 'cached video', 'static content',
        'non-live content', 'traditional media', 'conventional broadcasting'
    ]
    
    # === í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì „ì²˜ë¦¬ ===
    def extract_text(value):
        if pd.isna(value) or value is None:
            return ""
        return str(value).lower().strip()
    
    title = extract_text(row.get('TI', ''))
    source_title = extract_text(row.get('SO', ''))
    author_keywords = extract_text(row.get('DE', ''))
    keywords_plus = extract_text(row.get('ID', ''))
    abstract = extract_text(row.get('AB', ''))
    document_type = extract_text(row.get('DT', ''))
    
    full_text = ' '.join([title, source_title, author_keywords, keywords_plus, abstract])
    
    # === 1ë‹¨ê³„: ì—„ê²©í•œ ë°°ì œê¸°ì¤€ ì ìš© (ìš°ì„ ìˆœìœ„) ===
    
    # EC1: ë¹„í•™ìˆ  ë¬¸ì„œ ë°°ì œ
    if any(doc_type in document_type for doc_type in excluded_document_types):
        return 'EC1 - ë¹„í•™ìˆ  ë¬¸ì„œ'
    
    # EC2: ì¤‘ë³µ ê²Œì¬ ë…¼ë¬¸ ë°°ì œ
    if any(indicator in full_text for indicator in duplicate_indicators):
        return 'EC2 - ì¤‘ë³µ ê²Œì¬'
    
    # ê³µí†µ ë³€ìˆ˜ ì •ì˜ (EC3, EC6ì—ì„œ ê³µí†µ ì‚¬ìš©)
    has_core_livestreaming = any(keyword in full_text for keyword in core_livestreaming_keywords)
    
    # EC6: VOD/ì¼ë°˜ ë¹„ë””ì˜¤ ë°°ì œ (ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° í‚¤ì›Œë“œ ì—†ìœ¼ë©´ì„œ VOD ì§€í‘œ ìˆìœ¼ë©´)
    has_vod_indicators = any(indicator in full_text for indicator in vod_general_video_indicators)
    if has_vod_indicators and not has_core_livestreaming:
        return 'EC6 - VOD/ì¼ë°˜ë¹„ë””ì˜¤ (ì‹¤ì‹œê°„ì„± ë¶€ì¬)'
    
    # EC3: ìˆœìˆ˜ í•˜ë“œì›¨ì–´ êµ¬í˜„ (ì‚¬íšŒ-ê¸°ìˆ  ë§¥ë½ ì „í˜€ ì—†ìŒ)
    has_hardware_only = any(keyword in full_text for keyword in pure_hardware_exclusions)
    has_social_tech_context = any(keyword in full_text for keyword in social_tech_system_keywords)
    if has_hardware_only and not (has_core_livestreaming or has_social_tech_context):
        return 'EC3 - ìˆœìˆ˜ í•˜ë“œì›¨ì–´ êµ¬í˜„'
    
    # === 2ë‹¨ê³„: í•µì‹¬ í¬í•¨ê¸°ì¤€ ê²€ì¦ (AND ì¡°ê±´) ===
    
    # ì£¼ìš” ë³€ìˆ˜ë“¤ ë¨¼ì € ì •ì˜
    has_extended_livestreaming = any(keyword in full_text for keyword in extended_livestreaming_keywords)
    has_interactive_element = any(keyword in full_text for keyword in interactive_realtime_keywords)
    has_social_tech_system = any(keyword in full_text for keyword in social_tech_system_keywords)
    
    # === Tier 1: í•µì‹¬ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ (ê°€ì¥ ë†’ì€ ìš°ì„ ìˆœìœ„) ===
    if has_core_livestreaming and has_interactive_element and has_social_tech_system:
        # EC4, EC5 ì¶”ê°€ ê²€ì¦
        future_mentions = sum(1 for pattern in future_only_patterns if pattern in full_text)
        superficial_mentions = sum(1 for indicator in superficial_mention_indicators if indicator in full_text)
        
        if future_mentions > 0 and 'method' not in full_text and 'analysis' not in full_text:
            return 'EC4 - ë¯¸ë˜ì—°êµ¬ ì œì•ˆì—ë§Œ ì–¸ê¸‰'
        
        if superficial_mentions >= 2:  # í”¼ìƒì  ì–¸ê¸‰ì´ ë§ì€ ê²½ìš°
            return 'EC5 - í”¼ìƒì  ì–¸ê¸‰'
        
        return 'Include - Tier 1 í•µì‹¬ì—°êµ¬ (ë¼ì´ë¸ŒìŠ¤íŠ¸ë¦¬ë°+ìƒí˜¸ì‘ìš©+ì‚¬íšŒê¸°ìˆ )'
    
    # === Tier 2: í™•ì¥ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ ===
    elif has_extended_livestreaming and (has_interactive_element or has_social_tech_system):
        # ë¼ì´ë¸Œ ì»¤ë¨¸ìŠ¤, êµìœ¡, ì—”í„°í…Œì¸ë¨¼íŠ¸ ë“±ì˜ í™•ì¥ ë§¥ë½
        return 'Include - Tier 2 í™•ì¥ì—°êµ¬ (ë¼ì´ë¸ŒìŠ¤íŠ¸ë¦¬ë° í™•ì¥ë§¥ë½)'
    
    # === Tier 3: ê°„ì ‘ ê´€ë ¨ ì—°êµ¬ (ì œí•œì  í¬í•¨) ===
    elif has_core_livestreaming and (has_interactive_element or has_social_tech_system):
        # í•µì‹¬ í‚¤ì›Œë“œëŠ” ìˆìœ¼ë‚˜ í•œ ìš”ì†Œ ë¶€ì¡±
        return 'Review - Tier 3 ë¶€ë¶„ì¶©ì¡± (ì¶”ê°€ê²€í†  í•„ìš”)'
    
    # === ê¸°íƒ€ ê²½ê³„ ì‚¬ë¡€ ===
    elif has_core_livestreaming:
        # í•µì‹¬ í‚¤ì›Œë“œë§Œ ìˆëŠ” ê²½ìš°
        return 'Review - ë¼ì´ë¸ŒìŠ¤íŠ¸ë¦¬ë° ì–¸ê¸‰ (ë§¥ë½ ê²€í†  í•„ìš”)'
    
    elif has_extended_livestreaming:
        # í™•ì¥ í‚¤ì›Œë“œë§Œ ìˆëŠ” ê²½ìš°  
        return 'Review - í™•ì¥ë§¥ë½ ì–¸ê¸‰ (ê´€ë ¨ì„± ê²€í†  í•„ìš”)'
    
    # === ìµœì¢…: ê´€ë ¨ì„± ì—†ìŒ ===
    else:
        return 'Exclude - ë¼ì´ë¸ŒìŠ¤íŠ¸ë¦¬ë° ê´€ë ¨ì„± ì—†ìŒ'
        if has_vod_indicators and not has_interactive_element:
            return 'EC5 - VOD/ì¼ë°˜ë¹„ë””ì˜¤ì™€ êµ¬ë¶„ë¶ˆê°€'
        
        # ìµœì¢… í¬í•¨ íŒì •
        if has_interactive_element and (has_platform_context or 'platform' in full_text):
            return 'Include - í•µì‹¬ì—°êµ¬ (IC1+IC2+IC3 ì¶©ì¡±)'
        elif has_interactive_element:
            return 'Include - í•µì‹¬ì—°êµ¬ (IC1+IC2 ì¶©ì¡±)'
        else:
            return 'Review - ìƒí˜¸ì‘ìš©ì„± ì¶”ê°€ê²€í†  í•„ìš”'
    
    # === 3ë‹¨ê³„: í™•ì¥ í¬í•¨ê¸°ì¤€ (ê°„ì ‘ì  ê´€ë ¨ì„±) ===
    
    # ë¹„ì¦ˆë‹ˆìŠ¤/ì»¤ë¨¸ìŠ¤ + ë””ì§€í„¸/ì‹¤ì‹œê°„ ì§€í‘œ
    business_keywords = [
        'e-commerce', 'online shopping', 'digital commerce', 'social commerce',
        'influencer marketing', 'content creator', 'digital marketing',
        'consumer behavior', 'purchase intention', 'social influence',
        'brand engagement', 'customer engagement', 'social selling'
    ]
    
    if any(keyword in full_text for keyword in business_keywords):
        digital_live_indicators = [
            'digital', 'online', 'real-time', 'live', 'streaming', 
            'interactive', 'platform', 'social media', 'virtual'
        ]
        if any(indicator in full_text for indicator in digital_live_indicators):
            # EC2 ê²€ì¦: í”¼ìƒì  ì–¸ê¸‰ì¸ì§€ í™•ì¸
            meaningful_mentions = sum(1 for kw in business_keywords if kw in full_text)
            superficial_mentions = sum(1 for ind in superficial_mention_indicators if ind in full_text)
            
            if superficial_mentions >= meaningful_mentions:
                return 'EC2 - í”¼ìƒì  ì–¸ê¸‰ (í˜•ìš©ì‚¬ ìˆ˜ì¤€)'
            else:
                return 'Include - ë¹„ì¦ˆë‹ˆìŠ¤ ê´€ë ¨ (ê°„ì ‘ì  ê´€ë ¨ì„±)'
    
    # êµìœ¡ + ì˜¨ë¼ì¸/ì‹¤ì‹œê°„ ì§€í‘œ
    education_keywords = [
        'online education', 'e-learning', 'distance learning', 'remote learning',
        'virtual classroom', 'online teaching', 'digital learning',
        'educational technology', 'interactive learning', 'synchronous learning'
    ]
    
    if any(keyword in full_text for keyword in education_keywords):
        realtime_indicators = [
            'real-time', 'synchronous', 'live', 'interactive', 
            'immediate', 'instant', 'streaming'
        ]
        if any(indicator in full_text for indicator in realtime_indicators):
            return 'Include - êµìœ¡ ê´€ë ¨ (ê°„ì ‘ì  ê´€ë ¨ì„±)'
    
    # ì†Œì…œë¯¸ë””ì–´ + ìƒí˜¸ì‘ìš© ì§€í‘œ
    social_media_keywords = [
        'social media', 'social network', 'online platform', 'digital platform',
        'user behavior', 'online behavior', 'social interaction', 'online interaction',
        'user engagement', 'digital engagement', 'online community'
    ]
    
    if any(keyword in full_text for keyword in social_media_keywords):
        interaction_indicators = [
            'interaction', 'engagement', 'community', 'participation',
            'sharing', 'content creator', 'influencer', 'real-time'
        ]
        if any(indicator in full_text for indicator in interaction_indicators):
            return 'Include - ì†Œì…œë¯¸ë””ì–´ ê´€ë ¨ (ê°„ì ‘ì  ê´€ë ¨ì„±)'
        else:
            return 'Review - ì†Œì…œë¯¸ë””ì–´ ë§¥ë½ê²€í†  í•„ìš”'
    
    # === 4ë‹¨ê³„: ë‚˜ë¨¸ì§€ ë°°ì œê¸°ì¤€ ì ìš© ===
    
    # EC3: ë¯¸ë˜ ì—°êµ¬ ì œì•ˆì—ë§Œ ì–¸ê¸‰
    if any(pattern in full_text for pattern in future_only_patterns):
        # ì‹¤ì œ ì—°êµ¬ ë‚´ìš©ì—ì„œëŠ” ë‹¤ë£¨ì§€ ì•Šê³  ë¯¸ë˜ ì—°êµ¬ì—ì„œë§Œ ì–¸ê¸‰í•˜ëŠ” ê²½ìš°
        has_actual_research_content = (
            'method' in full_text or 'analysis' in full_text or 
            'result' in full_text or 'finding' in full_text or 
            'data' in full_text or 'experiment' in full_text
        )
        if not has_actual_research_content:
            return 'EC3 - ë¯¸ë˜ì—°êµ¬ ì œì•ˆì—ë§Œ ì–¸ê¸‰'
    
    # ìµœì¢… - ë¶„ë¥˜ ë¶ˆí™•ì‹¤
    return 'Review - í¬í•¨ì—¬ë¶€ ìˆ˜ë™ê²€í†  í•„ìš”'


# --- ë°ì´í„° í’ˆì§ˆ ì§„ë‹¨ í•¨ìˆ˜ ---
def diagnose_merged_quality(df, file_count, duplicates_removed):
    """ë³‘í•©ëœ WOS ë°ì´í„°ì˜ í’ˆì§ˆ ì§„ë‹¨ - ìˆ˜ì •ëœ ë²„ì „"""
    issues = []
    recommendations = []
    
    # í•„ìˆ˜ í•„ë“œ í™•ì¸
    required_fields = ['TI', 'AU', 'SO', 'PY']
    keyword_fields = ['DE', 'ID']
    
    for field in required_fields:
        if field not in df.columns:
            issues.append(f"âŒ í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}")
        else:
            valid_count = df[field].notna().sum()
            total_count = len(df)
            missing_rate = (total_count - valid_count) / total_count * 100
            
            if missing_rate > 10:
                issues.append(f"âš ï¸ {field} í•„ë“œì˜ {missing_rate:.1f}%ê°€ ëˆ„ë½ë¨")
    
    # í‚¤ì›Œë“œ í•„ë“œ í’ˆì§ˆ í™•ì¸
    has_keywords = False
    for field in keyword_fields:
        if field in df.columns:
            has_keywords = True
            valid_keywords = df[field].notna() & (df[field] != '') & (df[field] != 'nan')
            valid_count = valid_keywords.sum()
            total_count = len(df)
            
            if valid_count < total_count * 0.7:
                issues.append(f"âš ï¸ {field} í•„ë“œì˜ {((total_count-valid_count)/total_count*100):.1f}%ê°€ ë¹„ì–´ìˆìŒ")
    
    if not has_keywords:
        issues.append("âŒ í‚¤ì›Œë“œ í•„ë“œ ì—†ìŒ: DE ë˜ëŠ” ID í•„ë“œ í•„ìš”")
    
    # ë³‘í•© ê´€ë ¨ ì •ë³´ - ì‹¤ì œ ê²°ê³¼ë§Œ ë°˜ì˜ (ì™„ì „ ìˆ˜ì •)
    recommendations.append(f"âœ… {file_count}ê°œ íŒŒì¼ ì„±ê³µì ìœ¼ë¡œ ë³‘í•©ë¨")
    
    # ì¤‘ë³µ ì œê±° ê²°ê³¼ë§Œ ì‹¤ì œ ë°ì´í„°ì— ë”°ë¼ í‘œì‹œ
    if duplicates_removed > 0:
        recommendations.append(f"ğŸ”„ ì¤‘ë³µ ë…¼ë¬¸ {duplicates_removed}í¸ ìë™ ì œê±°ë¨")
    else:
        recommendations.append("âœ… ì¤‘ë³µ ë…¼ë¬¸ ì—†ìŒ - ëª¨ë“  ë…¼ë¬¸ì´ ê³ ìœ  ë°ì´í„°")
    
    recommendations.append("âœ… WOS Plain Text í˜•ì‹ - SCIMAT ìµœì  í˜¸í™˜ì„± í™•ë³´")
    
    return issues, recommendations

# --- WOS Plain Text í˜•ì‹ ë³€í™˜ í•¨ìˆ˜ ---
def convert_to_scimat_wos_format(df_to_convert):
    """SCIMAT ì™„ì „ í˜¸í™˜ WOS Plain Text í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    wos_field_order = [
        'PT', 'AU', 'AF', 'TI', 'SO', 'LA', 'DT', 'DE', 'ID', 'AB', 'C1', 'C3', 'RP',
        'EM', 'RI', 'OI', 'FU', 'FX', 'CR', 'NR', 'TC', 'Z9', 'U1', 'U2', 'PU', 'PI', 'PA',
        'SN', 'EI', 'J9', 'JI', 'PD', 'PY', 'VL', 'IS', 'BP', 'EP', 'DI', 'EA', 'PG',
        'WC', 'WE', 'SC', 'GA', 'UT', 'PM', 'OA', 'DA'
    ]
    
    file_content = ["FN Clarivate Analytics Web of Science", "VR 1.0"]
    multi_line_fields = ['AU', 'AF', 'DE', 'ID', 'C1', 'C3', 'CR']

    for _, row in df_to_convert.iterrows():
        if len(file_content) > 2:
            file_content.append("")
        
        for tag in wos_field_order:
            if tag in row.index and pd.notna(row[tag]) and str(row[tag]).strip() and str(row[tag]).strip().lower() != 'nan':
                value = str(row[tag]).strip()
                
                if tag in multi_line_fields:
                    items = [item.strip() for item in value.split(';') if item.strip()]
                    if items:
                        file_content.append(f"{tag} {items[0]}")
                        for item in items[1:]:
                            file_content.append(f"   {item}")
                else:
                    file_content.append(f"{tag} {value}")
        
        file_content.append("ER")
    
    return "\n".join(file_content).encode('utf-8-sig')

# --- ë©”ì¸ í—¤ë” ---
st.markdown("""
<div style="position: relative; text-align: center; padding: 2.5rem 0 3rem 0; background: linear-gradient(135deg, #3182f6, #1c64f2); color: white; border-radius: 8px; margin-bottom: 1.5rem; box-shadow: 0 2px 8px rgba(49,130,246,0.15); overflow: hidden;">
    <div style="position: absolute; top: 1rem; left: 1.5rem; color: white;">
        <div style="font-size: 12px; font-weight: 600; margin-bottom: 3px; letter-spacing: 0.3px;">HANYANG UNIVERSITY</div>
        <div style="font-size: 11px; opacity: 0.9; font-weight: 500;">Technology Management Research</div>
        <div style="font-size: 10px; opacity: 0.8; margin-top: 4px; font-weight: 400;">mot.hanyang.ac.kr</div>
    </div>
    <div style="position: absolute; top: 1rem; right: 1.5rem; text-align: right; color: rgba(255,255,255,0.9); font-size: 11px;">
        <p style="margin: 0; font-weight: 500;">Developed by: ì„íƒœê²½ (Teddy Lym)</p>
    </div>
    <h1 style="font-size: 3rem; font-weight: 700; margin-bottom: 0.3rem; letter-spacing: -0.02em;">
        WOS PREP
    </h1>
    <p style="font-size: 1.1rem; margin: 0; font-weight: 500; opacity: 0.95; letter-spacing: -0.01em;">
        SCIMAT Edition - PRISMA 2020 Enhanced
    </p>
    <div style="width: 80px; height: 3px; background-color: rgba(255,255,255,0.3); margin: 1.5rem auto; border-radius: 2px;"></div>
</div>
""", unsafe_allow_html=True)

# --- í•µì‹¬ ê¸°ëŠ¥ ì†Œê°œ ---
st.markdown("""
<div class="feature-grid">
    <div class="feature-card">
        <div class="feature-icon">ğŸ”—</div>
        <div class="feature-title">ë‹¤ì¤‘ íŒŒì¼ ìë™ ë³‘í•©</div>
        <div class="feature-desc">ì—¬ëŸ¬ WOS íŒŒì¼ì„ í•œ ë²ˆì— ë³‘í•© ì²˜ë¦¬</div>
    </div>
    <div class="feature-card">
        <div class="feature-icon">ğŸš«</div>
        <div class="feature-title">ìŠ¤ë§ˆíŠ¸ ì¤‘ë³µ ì œê±°</div>
        <div class="feature-desc">UT ê¸°ì¤€ ìë™ ì¤‘ë³µ ë…¼ë¬¸ ê°ì§€ ë° ì œê±°</div>
    </div>
    <div class="feature-card">
        <div class="feature-icon">ğŸ¯</div>
        <div class="feature-title">PRISMA ê¸°ì¤€ ì ìš©</div>
        <div class="feature-desc">IC1-IC3 í¬í•¨ê¸°ì¤€ + EC1-EC8 ë°°ì œê¸°ì¤€ ì²´ê³„ì  ì ìš©</div>
    </div>
    <div class="feature-card">
        <div class="feature-title">í•™ìˆ ì  ì—„ë°€ì„± ê°•í™”</div>
        <div class="feature-desc">ì‚¬íšŒ-ê¸°ìˆ  ì‹œìŠ¤í…œ ê´€ì  + ì‹¤ì‹œê°„ ì–‘ë°©í–¥ ìƒí˜¸ì‘ìš© í•„ìˆ˜ ê²€ì¦</div>
    </div>
</div>
""", unsafe_allow_html=True)

# --- íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ ---
st.markdown("""
<div class="section-header">
    <div class="section-title">ğŸ“‚ ë‹¤ì¤‘ WOS Plain Text íŒŒì¼ ì—…ë¡œë“œ</div>
    <div class="section-subtitle">500ê°œ ë‹¨ìœ„ë¡œ ë‚˜ë‰œ ì—¬ëŸ¬ WOS íŒŒì¼ì„ ëª¨ë‘ ì„ íƒí•˜ì—¬ ì—…ë¡œë“œí•˜ì„¸ìš”</div>
</div>
""", unsafe_allow_html=True)

uploaded_files = st.file_uploader(
    "WOS Plain Text íŒŒì¼ ì„ íƒ (ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)",
    type=['txt'],
    accept_multiple_files=True,
    label_visibility="collapsed",
    help="WOS Plain Text íŒŒì¼ë“¤ì„ ë“œë˜ê·¸í•˜ì—¬ ë†“ê±°ë‚˜ í´ë¦­í•˜ì—¬ ì„ íƒí•˜ì„¸ìš”"
)

if uploaded_files:
    st.markdown(f"ğŸ“‹ **ì„ íƒëœ íŒŒì¼ ê°œìˆ˜:** {len(uploaded_files)}ê°œ")
    
    # í”„ë¡œê·¸ë ˆìŠ¤ ì¸ë””ì¼€ì´í„°
    st.markdown('<div class="progress-indicator"></div>', unsafe_allow_html=True)
    
    with st.spinner(f"ğŸ”„ {len(uploaded_files)}ê°œ WOS íŒŒì¼ ë³‘í•© ë° PRISMA ê¸°ì¤€ ì ìš© ì¤‘..."):
        # íŒŒì¼ ë³‘í•©
        merged_df, file_status, duplicates_removed = load_and_merge_wos_files(uploaded_files)
        
        if merged_df is None:
            st.error("âš ï¸ ì²˜ë¦¬ ê°€ëŠ¥í•œ WOS Plain Text íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ë“¤ì´ Web of Scienceì—ì„œ ë‹¤ìš´ë¡œë“œí•œ ì •í’ˆ Plain Text íŒŒì¼ì¸ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
            
            # íŒŒì¼ë³„ ìƒíƒœ í‘œì‹œ
            st.markdown("### ğŸ“„ íŒŒì¼ë³„ ì²˜ë¦¬ ìƒíƒœ")
            for status in file_status:
                st.markdown(f"""
                <div class="file-status">
                    <strong>{status['filename']}</strong><br>
                    {status['message']}
                </div>
                """, unsafe_allow_html=True)
            st.stop()
        
        # ë…¼ë¬¸ ë¶„ë¥˜ ìˆ˜í–‰ - PRISMA ê¸°ì¤€ ì ìš©
        merged_df['Classification'] = merged_df.apply(classify_article, axis=1)

    # ì„±ê³µì ì¸ íŒŒì¼ ê°œìˆ˜ ê³„ì‚°
    successful_files = len([s for s in file_status if s['status'] == 'SUCCESS'])
    total_papers = len(merged_df)
    
    st.success(f"âœ… ë³‘í•© ë° PRISMA ê¸°ì¤€ ì ìš© ì™„ë£Œ! {successful_files}ê°œ íŒŒì¼ì—ì„œ {total_papers:,}í¸ì˜ ë…¼ë¬¸ì„ ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬í–ˆìŠµë‹ˆë‹¤.")
    
    # ì¤‘ë³µ ì œê±° ê²°ê³¼ í‘œì‹œ - ì‹¤ì œ ê²°ê³¼ë§Œ
    if duplicates_removed > 0:
        st.info(f"ğŸ”„ ì¤‘ë³µ ë…¼ë¬¸ {duplicates_removed}í¸ì´ ìë™ìœ¼ë¡œ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤. (ì›ë³¸ ì´ {total_papers + duplicates_removed:,}í¸ â†’ ì •ì œ í›„ {total_papers:,}í¸)")
    else:
        st.info("âœ… ì¤‘ë³µ ë…¼ë¬¸ ì—†ìŒ - ëª¨ë“  ë…¼ë¬¸ì´ ê³ ìœ í•œ ë°ì´í„°ì…ë‹ˆë‹¤.")

    # --- íŒŒì¼ë³„ ì²˜ë¦¬ ìƒíƒœ ---
    st.markdown("""
    <div class="section-header">
        <div class="section-title">ğŸ“„ íŒŒì¼ë³„ ì²˜ë¦¬ ìƒíƒœ</div>
        <div class="section-subtitle">ì—…ë¡œë“œëœ ê° íŒŒì¼ì˜ ì²˜ë¦¬ ê²°ê³¼</div>
    </div>
    """, unsafe_allow_html=True)

    st.markdown("""
    <div class="chart-container">
        <div class="chart-title">ğŸ“‹ íŒŒì¼ë³„ ìƒì„¸ ìƒíƒœ</div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns([0.6, 0.4])
    
    with col1:        
        for status in file_status:
            color = "#10b981" if status['status'] == 'SUCCESS' else "#ef4444"
            icon = "âœ…" if status['status'] == 'SUCCESS' else "âŒ"
            
            st.markdown(f"""
            <div style="margin: 12px 0; padding: 16px; background: white; border-left: 4px solid {color}; border-radius: 12px; box-shadow: 0 1px 3px rgba(0,0,0,0.04);">
                <strong>{icon} {status['filename']}</strong><br>
                <small style="color: #8b95a1;">{status['message']}</small>
                {f" | ì¸ì½”ë”©: {status['encoding']}" if status['encoding'] != 'N/A' else ""}
            </div>
            """, unsafe_allow_html=True)
    
    with col2:
        # íŒŒì¼ ì²˜ë¦¬ í†µê³„
        success_count = len([s for s in file_status if s['status'] == 'SUCCESS'])
        error_count = len([s for s in file_status if s['status'] == 'ERROR'])
        
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon">âœ…</div>
            <div class="metric-value">{success_count}</div>
            <div class="metric-label">ì„±ê³µí•œ íŒŒì¼</div>
        </div>
        """, unsafe_allow_html=True)
        
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon">âŒ</div>
            <div class="metric-value">{error_count}</div>
            <div class="metric-label">ì‹¤íŒ¨í•œ íŒŒì¼</div>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("</div>", unsafe_allow_html=True)

    # --- ë°ì´í„° í’ˆì§ˆ ì§„ë‹¨ ê²°ê³¼ ---
    st.markdown("""
    <div class="section-header">
        <div class="section-title">ğŸ” ë³‘í•© ë°ì´í„° í’ˆì§ˆ ì§„ë‹¨</div>
        <div class="section-subtitle">ë³‘í•©ëœ WOS ë°ì´í„°ì˜ í’ˆì§ˆê³¼ SCIMAT í˜¸í™˜ì„± ê²€ì¦</div>
    </div>
    """, unsafe_allow_html=True)

    with st.spinner("ğŸ” ë³‘í•© ë°ì´í„° í’ˆì§ˆ ë¶„ì„ ì¤‘..."):
        issues, recommendations = diagnose_merged_quality(merged_df, successful_files, duplicates_removed)

    st.markdown("""
    <div class="chart-container">
        <div class="chart-title">ğŸ” ë³‘í•© ë°ì´í„° í’ˆì§ˆ ì§„ë‹¨ ê²°ê³¼</div>
    """, unsafe_allow_html=True)
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown('<h5 style="color: #ef4444; margin-bottom: 16px;">ğŸš¨ ë°œê²¬ëœ ë¬¸ì œì </h5>', unsafe_allow_html=True)
        
        if issues:
            for issue in issues:
                st.markdown(f"- {issue}")
        else:
            st.markdown("âœ… **ë¬¸ì œì  ì—†ìŒ** - ë³‘í•© ë°ì´í„° í’ˆì§ˆ ìš°ìˆ˜")
    
    with col2:
        st.markdown('<h5 style="color: #10b981; margin-bottom: 16px;">ğŸ’¡ ë³‘í•© ê²°ê³¼</h5>', unsafe_allow_html=True)
        
        if recommendations:
            for rec in recommendations:
                st.markdown(f"- {rec}")
        else:
            st.markdown("ğŸ¯ **ìµœì  ìƒíƒœ** - SCIMAT ì™„ë²½ í˜¸í™˜")
    
    st.markdown("</div>", unsafe_allow_html=True)

    # PRISMA ì ìš© ì„±ê³µ ì•Œë¦¼
    st.markdown("""
    <div class="success-panel">
        <h4 style="color: #065f46; margin-bottom: 20px; font-weight: 700;">ğŸ¯ PRISMA 2020 ê¸°ì¤€ ì ìš© ì™„ë£Œ!</h4>
        <p style="color: #065f46; margin: 6px 0; font-weight: 500;">ë‹¤ì¤‘ WOS Plain Text íŒŒì¼ì´ ì„±ê³µì ìœ¼ë¡œ í•˜ë‚˜ë¡œ ë³‘í•©ë˜ì—ˆìŠµë‹ˆë‹¤.</p>
        <p style="color: #065f46; margin: 6px 0; font-weight: 500;"><strong>í¬í•¨ê¸°ì¤€ (IC):</strong> IC1(ì‚¬íšŒ-ê¸°ìˆ ì‹œìŠ¤í…œ) + IC2(ì‹¤ì‹œê°„ ì–‘ë°©í–¥ ìƒí˜¸ì‘ìš©) + IC3(í”Œë«í¼ ìƒíƒœê³„) ì²´ê³„ì  ê²€ì¦</p>
        <p style="color: #065f46; margin: 6px 0; font-weight: 500;"><strong>ë°°ì œê¸°ì¤€ (EC):</strong> EC1-EC8 ë°°ì œê¸°ì¤€ì„ ì²´ê³„ì ìœ¼ë¡œ ì ìš©í•˜ì—¬ ì—°êµ¬ì˜ ì‹ ë¢°ì„±ì„ í™•ë³´í–ˆìŠµë‹ˆë‹¤.</p>
        <p style="color: #065f46; margin: 6px 0; font-weight: 500;"><strong>SCIMAT í˜¸í™˜ì„±:</strong> ë³‘í•©ëœ íŒŒì¼ì€ SCIMATì—ì„œ 100% ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.</p>
    </div>
    """, unsafe_allow_html=True)

    # --- PRISMA ì ìš© ê²°ê³¼ ìš”ì•½ ---
    st.markdown("""
    <div class="section-header">
        <div class="section-title">ğŸ“ˆ PRISMA 2020 ê¸°ì¤€ ì ìš© ê²°ê³¼</div>
        <div class="section-subtitle">IC1-IC3 í¬í•¨ê¸°ì¤€ + EC1-EC8 ë°°ì œê¸°ì¤€ ì ìš© í›„ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ ë¶„ë¥˜ ê²°ê³¼</div>
    </div>
    """, unsafe_allow_html=True)

    # ìµœì¢… ë°ì´í„°ì…‹ ì¤€ë¹„ - ì—„ê²©í•œ ë°°ì œê¸°ì¤€ ë°˜ì˜
    # EC ì½”ë“œë¡œ ì‹œì‘í•˜ëŠ” ë…¼ë¬¸ë“¤ì€ ì™„ì „íˆ ì œì™¸
    df_excluded_strict = merged_df[merged_df['Classification'].str.startswith('EC', na=False)]
    df_for_analysis = merged_df[~merged_df['Classification'].str.startswith('EC', na=False)].copy()
    
    # ì´ ë°°ì œëœ ë…¼ë¬¸ ìˆ˜ ê³„ì‚°
    total_excluded = len(df_excluded_strict)
    
    # Classification ì»¬ëŸ¼ë§Œ ì œê±° (ì›ë³¸ WOS í˜•ì‹ ìœ ì§€)
    df_final_output = df_for_analysis.drop(columns=['Classification'], errors='ignore')
    
    # ë©”íŠ¸ë¦­ ì¹´ë“œë“¤
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon">ğŸ“‹</div>
            <div class="metric-value">{len(df_final_output):,}</div>
            <div class="metric-label">ìµœì¢… ë¶„ì„ ëŒ€ìƒ<br><small style="color: #8b95a1;">(PRISMA ì ìš©í›„)</small></div>
        </div>
        """, unsafe_allow_html=True)
    
    include_papers = len(df_for_analysis[df_for_analysis['Classification'].str.contains('Include', na=False)])
    
    with col2:
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon">âœ…</div>
            <div class="metric-value">{include_papers:,}</div>
            <div class="metric-label">í•µì‹¬ í¬í•¨ ì—°êµ¬<br><small style="color: #8b95a1;">(IC1+IC2 ì¶©ì¡±)</small></div>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        processing_rate = (include_papers / len(df_final_output) * 100) if len(df_final_output) > 0 else 0
        st.markdown(f"""
        <div class="metric-card">
            <div class="metric-icon">ğŸ“Š</div>
            <div class="metric-value">{processing_rate:.1f}%</div>
            <div class="metric-label">í•µì‹¬ì—°êµ¬ ë¹„ìœ¨</div>
        </div>
        """, unsafe_allow_html=True)
    
    with col4:
        # ë°°ì œëœ ë…¼ë¬¸ë“¤ì„ ìœ„í•œ í† ê¸€ ë²„íŠ¼ì´ ìˆëŠ” ë°•ìŠ¤
        col4_inner1, col4_inner2 = st.columns([3, 1])
        
        with col4_inner1:
            st.markdown(f"""
            <div class="metric-card">
                <div class="metric-icon">â›”</div>
                <div class="metric-value">{total_excluded:,}</div>
                <div class="metric-label">PRISMA ë°°ì œ<br><small style="color: #8b95a1;">(EC1-EC8)</small></div>
            </div>
            """, unsafe_allow_html=True)
        
        with col4_inner2:
            st.markdown("<div style='height: 20px;'></div>", unsafe_allow_html=True)
            if st.button(
                "ğŸ“‹", 
                key="exclude_details_button",
                help="ë°°ì œëœ ë…¼ë¬¸ ìƒì„¸ ë³´ê¸°"
            ):
                st.session_state['show_exclude_details'] = not st.session_state.get('show_exclude_details', False)

    # ë°°ì œëœ ë…¼ë¬¸ ìƒì„¸ ì •ë³´ í† ê¸€ í‘œì‹œ
    if st.session_state.get('show_exclude_details', False) and total_excluded > 0:
        st.markdown("""
        <div style="background: #fef2f2; padding: 20px; border-radius: 16px; margin: 20px 0; border: 1px solid #ef4444;">
            <h4 style="color: #dc2626; margin-bottom: 16px; font-weight: 700;">â›” PRISMA ë°°ì œê¸°ì¤€ì— ë”°ë¥¸ ì œì™¸ ë…¼ë¬¸ (EC1-EC8)</h4>
        </div>
        """, unsafe_allow_html=True)
        
        # ë°°ì œ ê¸°ì¤€ë³„ ë¶„ë¥˜ ë° í‘œì‹œ
        exclusion_categories = {
            'EC1': 'ìˆœìˆ˜ê¸°ìˆ ì—°êµ¬ (ì‚¬íšŒ-ê¸°ìˆ ë§¥ë½ ë¶€ì¬)',
            'EC2': 'í”¼ìƒì  ì–¸ê¸‰ (í˜•ìš©ì‚¬ ìˆ˜ì¤€)',
            'EC3': 'ë¯¸ë˜ì—°êµ¬ ì œì•ˆì—ë§Œ ì–¸ê¸‰',
            'EC4': 'ì‹¤ì‹œê°„ ì–‘ë°©í–¥ ìƒí˜¸ì‘ìš© ë¯¸ê³ ë ¤',
            'EC5': 'VOD/ì¼ë°˜ë¹„ë””ì˜¤ì™€ êµ¬ë¶„ë¶ˆê°€',
            'EC6': 'ë¬¸ì„œìœ í˜• ë°°ì œ (ë¹„í•™ìˆ ë…¼ë¬¸)',
            'EC7': 'ì¤‘ë³µê²Œì¬ ì˜ì‹¬',
            'EC8': 'ì‹¤í—˜ì‹¤í™˜ê²½ê²€ì¦ (ì‹¤ì‚¬ìš©ë§¥ë½ ë¶€ì¬)'
        }
        
        # EC ê¸°ì¤€ë³„ ë°°ì œ í˜„í™©
        for ec_code, description in exclusion_categories.items():
            ec_papers = merged_df[merged_df['Classification'].str.startswith(ec_code, na=False)]
            if len(ec_papers) > 0:
                st.markdown(f"""
                <div style="margin: 12px 0; padding: 16px; background: white; border-left: 4px solid #ef4444; border-radius: 12px;">
                    <strong style="color: #dc2626;">{ec_code}: {description}</strong> 
                    <span style="color: #8b95a1;">({len(ec_papers)}í¸)</span>
                </div>
                """, unsafe_allow_html=True)
                
                # ìƒìœ„ 5í¸ë§Œ ìƒ˜í”Œë¡œ í‘œì‹œ
                for idx, (_, paper) in enumerate(ec_papers.head(5).iterrows(), 1):
                    title = str(paper.get('TI', 'N/A'))[:80] + "..." if len(str(paper.get('TI', 'N/A'))) > 80 else str(paper.get('TI', 'N/A'))
                    year = str(paper.get('PY', 'N/A'))
                    source = str(paper.get('SO', 'N/A'))[:40] + "..." if len(str(paper.get('SO', 'N/A'))) > 40 else str(paper.get('SO', 'N/A'))
                    
                    st.markdown(f"""
                    <div style="margin: 8px 0 8px 20px; padding: 12px; background: #f9fafb; border-radius: 8px; font-size: 14px;">
                        <div style="font-weight: 500; color: #374151; margin-bottom: 4px;">{title}</div>
                        <div style="color: #6b7280; font-size: 12px;">{year} | {source}</div>
                    </div>
                    """, unsafe_allow_html=True)
                
                if len(ec_papers) > 5:
                    st.markdown(f"<p style='color: #8b95a1; text-align: right; margin: 8px 20px 16px 20px; font-size: 12px;'>... ì™¸ {len(ec_papers) - 5}í¸ ë”</p>", unsafe_allow_html=True)

    # PRISMA ì ìš© ê²°ê³¼ ìš”ì•½
    st.markdown(f"""
    <div class="info-panel">
        <h4 style="color: #0064ff; margin-bottom: 16px; font-weight: 700;">ğŸ“Š PRISMA 2020 ê¸°ì¤€ ì ìš© ê²°ê³¼</h4>
        <p style="color: #0064ff; margin: 6px 0; font-weight: 500;"><strong>ì´ ì…ë ¥:</strong> {total_papers:,}í¸ì˜ ë…¼ë¬¸</p>
        <p style="color: #0064ff; margin: 6px 0; font-weight: 500;"><strong>PRISMA ë°°ì œ:</strong> {total_excluded:,}í¸ ì œì™¸ ({(total_excluded/total_papers*100):.1f}%)</p>
        <p style="color: #0064ff; margin: 6px 0; font-weight: 500;"><strong>ìµœì¢… ë¶„ì„:</strong> {len(df_final_output):,}í¸ìœ¼ë¡œ ì •ì œëœ ê³ í’ˆì§ˆ ë°ì´í„°ì…‹</p>
        <p style="color: #0064ff; margin: 6px 0; font-weight: 500;"><strong>í•µì‹¬ ì—°êµ¬:</strong> {include_papers:,}í¸ì˜ ì§ì ‘ ê´€ë ¨ ë¼ì´ë¸ŒìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ í™•ë³´</p>
        <div style="margin-top: 16px; padding: 12px; background: rgba(0,100,255,0.1); border-radius: 8px;">
            <p style='color: #0064ff; margin: 0; font-weight: 600; font-size: 14px;'>
            ğŸ’¡ <strong>IC1(ì‚¬íšŒ-ê¸°ìˆ ì‹œìŠ¤í…œ)</strong> + <strong>IC2(ì‹¤ì‹œê°„ ì–‘ë°©í–¥ ìƒí˜¸ì‘ìš©)</strong> + <strong>IC3(í”Œë«í¼ ìƒíƒœê³„)</strong> í¬í•¨ê¸°ì¤€ê³¼ 
            <strong>EC1-EC8 ë°°ì œê¸°ì¤€</strong>ì„ ì²´ê³„ì ìœ¼ë¡œ ì ìš©í•˜ì—¬ ì—°êµ¬ì˜ í•™ìˆ ì  ì—„ë°€ì„±ì„ í™•ë³´í–ˆìŠµë‹ˆë‹¤.
            </p>
        </div>
    </div>
    """, unsafe_allow_html=True)

    # --- ë…¼ë¬¸ ë¶„ë¥˜ í˜„í™© ---
    st.markdown("""
    <div class="chart-container">
        <div class="chart-title">PRISMA ì ìš© í›„ ì—°êµ¬ ë¶„ë¥˜ ë¶„í¬</div>
    """, unsafe_allow_html=True)

    classification_counts_df = df_for_analysis['Classification'].value_counts().reset_index()
    classification_counts_df.columns = ['ë¶„ë¥˜', 'ë…¼ë¬¸ ìˆ˜']

    col1, col2 = st.columns([0.4, 0.6])
    with col1:
        st.dataframe(classification_counts_df, use_container_width=True, hide_index=True)

    with col2:
        # ë„ë„› ì°¨íŠ¸
        selection = alt.selection_point(fields=['ë¶„ë¥˜'], on='mouseover', nearest=True)

        base = alt.Chart(classification_counts_df).encode(
            theta=alt.Theta(field="ë…¼ë¬¸ ìˆ˜", type="quantitative", stack=True),
            color=alt.Color(field="ë¶„ë¥˜", type="nominal", title="Classification",
                           scale=alt.Scale(range=['#0064ff', '#0050cc', '#10b981', '#f59e0b', '#8b5cf6']),
                           legend=alt.Legend(orient="right", titleColor="#191f28", labelColor="#8b95a1")),
            opacity=alt.condition(selection, alt.value(1), alt.value(0.8))
        ).add_params(selection)

        pie = base.mark_arc(outerRadius=150, innerRadius=90)
        text_total = alt.Chart(pd.DataFrame([{'value': f'{len(df_final_output)}'}])).mark_text(
            align='center', baseline='middle', fontSize=45, fontWeight='bold', color='#0064ff'
        ).encode(text='value:N')
        text_label = alt.Chart(pd.DataFrame([{'value': 'PRISMA Papers'}])).mark_text(
            align='center', baseline='middle', fontSize=16, dy=30, color='#8b95a1'
        ).encode(text='value:N')

        chart = (pie + text_total + text_label).properties(
            width=350, height=350
        ).configure_view(strokeWidth=0)
        st.altair_chart(chart, use_container_width=True)

    st.markdown("</div>", unsafe_allow_html=True)

    # --- ë¶„ë¥˜ ìƒì„¸ ê²°ê³¼ ---
    st.markdown("""
    <div class="chart-container">
        <div class="chart-title">ë¶„ë¥˜ë³„ ìƒì„¸ ë¶„í¬ (PRISMA ê¸°ì¤€ ì ìš© í›„)</div>
    """, unsafe_allow_html=True)
    
    # ë¶„ë¥˜ë³„ ìƒì„¸ í†µê³„ (EC ì œì™¸)
    for classification in df_for_analysis['Classification'].unique():
        count = len(df_for_analysis[df_for_analysis['Classification'] == classification])
        percentage = (count / len(df_final_output) * 100) if len(df_final_output) > 0 else 0
        
        if classification.startswith('Include'):
            color = "#10b981"
            icon = "âœ…"
            desc = "PRISMA í¬í•¨ê¸°ì¤€ ì¶©ì¡±"
        elif classification.startswith('Review'):
            color = "#f59e0b"
            icon = "ğŸ”"
            desc = "ì¶”ê°€ ê²€í†  í•„ìš”"
        else:
            color = "#8b5cf6"
            icon = "â“"
            desc = "ê¸°íƒ€ ë¶„ë¥˜"
        
        st.markdown(f"""
        <div style="margin: 16px 0; padding: 20px; background: white; border-left: 4px solid {color}; border-radius: 12px; font-size: 16px; box-shadow: 0 1px 3px rgba(0,0,0,0.04);">
            <strong>{icon} {classification}:</strong> {count:,}í¸ ({percentage:.1f}%)
            <br><small style="color: #8b95a1;">{desc}</small>
        </div>
        """, unsafe_allow_html=True)
    
    st.markdown("</div>", unsafe_allow_html=True)

    # --- ì—°ë„ë³„ ì—°êµ¬ ë™í–¥ ---
    if 'PY' in df_final_output.columns:
        st.markdown("""
        <div class="chart-container">
            <div class="chart-title">ì •ì œëœ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ ë™í–¥ (PRISMA ì ìš© í›„)</div>
        """, unsafe_allow_html=True)
        
        df_trend = df_final_output.copy()
        df_trend['PY'] = pd.to_numeric(df_trend['PY'], errors='coerce')
        df_trend.dropna(subset=['PY'], inplace=True)
        df_trend['PY'] = df_trend['PY'].astype(int)
        
        yearly_counts = df_trend['PY'].value_counts().reset_index()
        yearly_counts.columns = ['Year', 'Count']
        yearly_counts = yearly_counts[yearly_counts['Year'] <= 2025].sort_values('Year')

        if len(yearly_counts) > 0:
            line_chart = alt.Chart(yearly_counts).mark_line(
                point={'size': 80, 'filled': True}, strokeWidth=3, color='#0064ff'
            ).encode(
                x=alt.X('Year:O', title='ë°œí–‰ ì—°ë„'),
                y=alt.Y('Count:Q', title='ë…¼ë¬¸ ìˆ˜'),
                tooltip=['Year', 'Count']
            ).properties(height=300)
            
            st.altair_chart(line_chart, use_container_width=True)
        
        st.markdown("</div>", unsafe_allow_html=True)

    # --- í‚¤ì›Œë“œ ìƒ˜í”Œ í™•ì¸ ---
    st.markdown("""
    <div class="chart-container">
        <div class="chart-title">ì •ì œëœ ë°ì´í„° í‚¤ì›Œë“œ í’ˆì§ˆ í™•ì¸</div>
    """, unsafe_allow_html=True)
    
    sample_data = []
    sample_rows = df_for_analysis[df_for_analysis['Classification'].str.contains('Include', na=False)].head(3)
    
    for idx, row in sample_rows.iterrows():
        title = str(row.get('TI', 'N/A'))[:80] + "..." if len(str(row.get('TI', 'N/A'))) > 80 else str(row.get('TI', 'N/A'))
        de_keywords = str(row.get('DE', 'N/A')) if pd.notna(row.get('DE')) else 'N/A'
        id_keywords = str(row.get('ID', 'N/A')) if pd.notna(row.get('ID')) else 'N/A'
        
        # í‚¤ì›Œë“œ ê°œìˆ˜ ê³„ì‚°
        de_count = len([k.strip() for k in de_keywords.split(';') if k.strip()]) if de_keywords != 'N/A' else 0
        id_count = len([k.strip() for k in id_keywords.split(';') if k.strip()]) if id_keywords != 'N/A' else 0
        
        sample_data.append({
            'ë…¼ë¬¸ ì œëª©': title,
            'DE í‚¤ì›Œë“œ': de_keywords[:100] + "..." if len(de_keywords) > 100 else de_keywords,
            'ID í‚¤ì›Œë“œ': id_keywords[:100] + "..." if len(id_keywords) > 100 else id_keywords,
            'DE ê°œìˆ˜': de_count,
            'ID ê°œìˆ˜': id_count
        })
    
    if sample_data:
        sample_df = pd.DataFrame(sample_data)
        st.dataframe(sample_df, use_container_width=True, hide_index=True)
        
        # í‚¤ì›Œë“œ í’ˆì§ˆ í‰ê°€
        avg_de = sum([d['DE ê°œìˆ˜'] for d in sample_data]) / len(sample_data) if sample_data else 0
        avg_id = sum([d['ID ê°œìˆ˜'] for d in sample_data]) / len(sample_data) if sample_data else 0
        
        if avg_de >= 3 and avg_id >= 3:
            st.success("âœ… í‚¤ì›Œë“œ í’ˆì§ˆ ìš°ìˆ˜ - SCIMATì—ì„œ ì›í™œí•œ ê·¸ë£¨í•‘ ì˜ˆìƒ")
        elif avg_de >= 2 or avg_id >= 2:
            st.warning("âš ï¸ í‚¤ì›Œë“œ í’ˆì§ˆ ë³´í†µ - SCIMATì—ì„œ ì¼ë¶€ ì œí•œ ê°€ëŠ¥")
        else:
            st.error("âŒ í‚¤ì›Œë“œ í’ˆì§ˆ ë¶€ì¡± - ì›ë³¸ WOS ë‹¤ìš´ë¡œë“œ ì„¤ì • í™•ì¸ í•„ìš”")

    st.markdown("</div>", unsafe_allow_html=True)

    # ë¶„ë¥˜ë³„ ë…¼ë¬¸ ìƒì„¸ ëª©ë¡ - Reviewë§Œ í† ê¸€ë¡œ ìœ ì§€
    review_papers = df_for_analysis[df_for_analysis['Classification'].str.contains('Review', na=False)]
    
    if len(review_papers) > 0:
        with st.expander(f"ğŸ” Review (ê²€í†  í•„ìš”) - ë…¼ë¬¸ ëª©ë¡ ({len(review_papers)}í¸)", expanded=False):
            st.markdown("""
            <div style="background: #fffbeb; padding: 16px; border-radius: 12px; margin-bottom: 20px; border: 1px solid #f59e0b;">
                <strong style="color: #92400e;">ğŸ“‹ ê²€í†  ì•ˆë‚´:</strong> ì•„ë˜ ë…¼ë¬¸ë“¤ì€ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ì™€ì˜ ê´€ë ¨ì„±ì„ ì¶”ê°€ ê²€í† ê°€ í•„ìš”í•œ ë…¼ë¬¸ë“¤ì…ë‹ˆë‹¤.
                ì œëª©ê³¼ ì¶œíŒ ì •ë³´ë¥¼ í™•ì¸í•˜ì—¬ ì—°êµ¬ ë²”ìœ„ì— í¬í•¨í• ì§€ ê²°ì •í•˜ì„¸ìš”. ì—„ê²©í•œ PRISMA ë°°ì œê¸°ì¤€(EC1-EC8)ì€ ì´ë¯¸ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.
            </div>
            """, unsafe_allow_html=True)
            
            # Review ë…¼ë¬¸ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
            review_excel_data = []
            for idx, (_, paper) in enumerate(review_papers.iterrows(), 1):
                review_excel_data.append({
                    'ë²ˆí˜¸': idx,
                    'ë…¼ë¬¸ ì œëª©': str(paper.get('TI', 'N/A')),
                    'ì¶œê°„ì—°ë„': str(paper.get('PY', 'N/A')),
                    'ì €ë„ëª…': str(paper.get('SO', 'N/A')),
                    'ì €ì': str(paper.get('AU', 'N/A')),
                    'ë¶„ë¥˜': str(paper.get('Classification', 'N/A')),
                    'ì €ì í‚¤ì›Œë“œ': str(paper.get('DE', 'N/A')),
                    'WOS í‚¤ì›Œë“œ': str(paper.get('ID', 'N/A')),
                    'ì´ˆë¡': str(paper.get('AB', 'N/A')),
                    'ë¬¸ì„œìœ í˜•': str(paper.get('DT', 'N/A'))
                })
            
            review_excel_df = pd.DataFrame(review_excel_data)
            
            # ì—‘ì…€ íŒŒì¼ ìƒì„±
            excel_buffer = io.BytesIO()
            with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
                review_excel_df.to_excel(writer, sheet_name='Review_Papers', index=False)
            excel_data = excel_buffer.getvalue()
            
            st.download_button(
                label="ğŸ“Š ê²€í†  ë…¼ë¬¸ ëª©ë¡ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
                data=excel_data,
                file_name=f"review_papers_prisma_filtered_{len(review_papers)}í¸.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                type="secondary",
                use_container_width=True
            )
            
            st.markdown("<br>", unsafe_allow_html=True)
            
            for idx, (_, paper) in enumerate(review_papers.iterrows(), 1):
                title = str(paper.get('TI', 'N/A'))
                year = str(paper.get('PY', 'N/A'))
                source = str(paper.get('SO', 'N/A'))
                classification = str(paper.get('Classification', 'N/A'))
                doc_type = str(paper.get('DT', 'N/A'))
                
                # ë¶„ë¥˜ë³„ ìƒ‰ìƒ ì„¤ì •
                if 'ë¶ˆí™•ì‹¤' in classification:
                    badge_color = "#8b5cf6"
                    badge_text = "ë¶„ë¥˜ ë¶ˆí™•ì‹¤"
                elif 'ì†Œì…œë¯¸ë””ì–´' in classification:
                    badge_color = "#06b6d4"
                    badge_text = "ì†Œì…œë¯¸ë””ì–´"
                elif 'ìƒí˜¸ì‘ìš©ì„±' in classification:
                    badge_color = "#f97316"
                    badge_text = "ìƒí˜¸ì‘ìš©ì„± ê²€í† "
                else:
                    badge_color = "#f59e0b"
                    badge_text = "ê¸°íƒ€ ê²€í† "
                
                st.markdown(f"""
                <div style="margin: 12px 0; padding: 16px; background: white; border-left: 4px solid #f59e0b; border-radius: 12px; box-shadow: 0 1px 3px rgba(0,0,0,0.04);">
                    <div style="display: flex; align-items: center; margin-bottom: 8px;">
                        <span style="background: {badge_color}; color: white; padding: 4px 12px; border-radius: 16px; font-size: 12px; margin-right: 12px; font-weight: 600;">{badge_text}</span>
                        <span style="color: #8b95a1; font-size: 14px;">#{idx}</span>
                        <span style="color: #8b95a1; font-size: 12px; margin-left: 8px;">[{doc_type}]</span>
                    </div>
                    <div style="font-weight: 600; color: #191f28; margin-bottom: 6px; line-height: 1.5;">
                        {title}
                    </div>
                    <div style="font-size: 14px; color: #8b95a1;">
                        <strong>ì—°ë„:</strong> {year} | <strong>ì €ë„:</strong> {source}
                    </div>
                </div>
                """, unsafe_allow_html=True)

    # PRISMA ì„±ê³¼ ê°•ì¡°
    success_info = []
    success_info.append(f"<strong>íŒŒì¼ í†µí•©:</strong> {successful_files}ê°œì˜ WOS íŒŒì¼ì„ í•˜ë‚˜ë¡œ ë³‘í•©")
    
    if duplicates_removed > 0:
        success_info.append(f"<strong>ì¤‘ë³µ ì œê±°:</strong> {duplicates_removed}í¸ì˜ ì¤‘ë³µ ë…¼ë¬¸ ìë™ ê°ì§€ ë° ì œê±°")
    
    success_info.append(f"<strong>PRISMA ì ìš©:</strong> IC1-IC3 í¬í•¨ê¸°ì¤€ + EC1-EC8 ë°°ì œê¸°ì¤€ìœ¼ë¡œ {total_excluded}í¸ ì œì™¸")
    success_info.append(f"<strong>ìµœì¢… ê·œëª¨:</strong> {len(df_final_output):,}í¸ì˜ ê³ í’ˆì§ˆ ë…¼ë¬¸ìœ¼ë¡œ ì •ì œëœ ë°ì´í„°ì…‹")
    success_info.append(f"<strong>í•µì‹¬ ì—°êµ¬:</strong> {include_papers}í¸ì˜ ì§ì ‘ ê´€ë ¨ ë¼ì´ë¸ŒìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ í™•ë³´")
    success_info.append("<strong>SCIMAT í˜¸í™˜:</strong> ì™„ë²½í•œ WOS Plain Text í˜•ì‹ìœ¼ë¡œ 100% í˜¸í™˜ì„± ë³´ì¥")
    
    success_content = "".join([f"<p style='color: #0064ff; margin: 6px 0; font-weight: 500;'>{info}</p>" for info in success_info])
    
    st.markdown(f"""
    <div class="info-panel">
        <h4 style="color: #0064ff; margin-bottom: 16px; font-weight: 700;">ğŸ¯ PRISMA 2020 ë°ì´í„° ì •ì œ ì™„ë£Œ</h4>
        {success_content}
        <div style="margin-top: 16px; padding: 12px; background: rgba(0,100,255,0.1); border-radius: 8px;">
            <p style='color: #0064ff; margin: 0; font-weight: 600; font-size: 14px;'>
            ğŸ’¡ <strong>PRISMA ì ìš©ë¥ :</strong> {(total_excluded/total_papers*100):.1f}% 
            - í”¼ìƒì  ì–¸ê¸‰, ìˆœìˆ˜ ê¸°ìˆ ì—°êµ¬, ë¹„í•™ìˆ  ë¬¸ì„œ ë“±ì„ ì²´ê³„ì ìœ¼ë¡œ ì œê±°í•˜ì—¬ ì—°êµ¬ì˜ í•™ìˆ ì  ì—„ë°€ì„±ì„ í™•ë³´í–ˆìŠµë‹ˆë‹¤.
            </p>
        </div>
    </div>
    """, unsafe_allow_html=True)

    # --- ìµœì¢… íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì„¹ì…˜ ---
    st.markdown("""
    <div class="section-header">
        <div class="section-title">ğŸ“¥ PRISMA 2020 ì ìš© ì™„ë£Œ - SCIMAT ë¶„ì„ìš© íŒŒì¼ ë‹¤ìš´ë¡œë“œ</div>
        <div class="section-subtitle">IC1-IC3 í¬í•¨ê¸°ì¤€ + EC1-EC8 ë°°ì œê¸°ì¤€ ì ìš© í›„ ì •ì œëœ ê³ í’ˆì§ˆ WOS Plain Text íŒŒì¼</div>
    </div>
    """, unsafe_allow_html=True)
    
    # SCIMAT í˜¸í™˜ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    text_data = convert_to_scimat_wos_format(df_final_output)
    
    download_clicked = st.download_button(
        label="ğŸ“¥ ë‹¤ìš´ë¡œë“œ",
        data=text_data,
        file_name=f"live_streaming_prisma2020_filtered_scimat_{len(df_final_output)}papers.txt",
        mime="text/plain",
        type="primary",
        use_container_width=True,
        key="download_final_file",
        help="PRISMA 2020 ê¸°ì¤€ ì ìš© í›„ SCIMATì—ì„œ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ WOS Plain Text íŒŒì¼"
    )

# --- í•˜ë‹¨ ì—¬ë°± ë° ì¶”ê°€ ì •ë³´ ---
st.markdown("<br>", unsafe_allow_html=True)

# ë„ì›€ë§ ì„¹ì…˜ - í•­ìƒ í‘œì‹œ
with st.expander("â“ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ (FAQ)", expanded=False):
    st.markdown("""
    **Q: PRISMA 2020 ê¸°ì¤€ì´ë€ ë¬´ì—‡ì¸ê°€ìš”?**
    A: ì²´ê³„ì  ë¬¸í—Œê³ ì°°ì˜ êµ­ì œí‘œì¤€ìœ¼ë¡œ, ë³¸ ë„êµ¬ëŠ” ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ì— íŠ¹í™”ëœ IC1-IC3 í¬í•¨ê¸°ì¤€ê³¼ EC1-EC8 ë°°ì œê¸°ì¤€ì„ ì ìš©í•©ë‹ˆë‹¤.
    
    **Q: IC1-IC3 í¬í•¨ê¸°ì¤€ì€ ë¬´ì—‡ì¸ê°€ìš”?**
    A: IC1(ì‚¬íšŒ-ê¸°ìˆ ì‹œìŠ¤í…œìœ¼ë¡œì„œì˜ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë°), IC2(ì‹¤ì‹œê°„ ì–‘ë°©í–¥ ìƒí˜¸ì‘ìš© í•„ìˆ˜), IC3(í”Œë«í¼ ìƒíƒœê³„ ë§¥ë½) - ì—°êµ¬ì˜ í•µì‹¬ íŠ¹ì„±ì„ ì •ì˜í•©ë‹ˆë‹¤.
    
    **Q: EC1-EC8 ë°°ì œê¸°ì¤€ì€ ë¬´ì—‡ì¸ê°€ìš”?**
    A: EC1(ìˆœìˆ˜ê¸°ìˆ ì—°êµ¬), EC2(í”¼ìƒì  ì–¸ê¸‰), EC3(ë¯¸ë˜ì—°êµ¬ ì œì•ˆë§Œ), EC4(ìƒí˜¸ì‘ìš© ë¯¸ê³ ë ¤), EC5(VODì™€ êµ¬ë¶„ë¶ˆê°€), EC6(ë¹„í•™ìˆ ë¬¸ì„œ), EC7(ì¤‘ë³µê²Œì¬), EC8(ì‹¤í—˜ì‹¤í™˜ê²½ë§Œ) - í•™ìˆ ì  ì—„ë°€ì„±ì„ ìœ„í•œ ì²´ê³„ì  ë°°ì œê¸°ì¤€ì…ë‹ˆë‹¤.
    
    **Q: ì—¬ëŸ¬ WOS íŒŒì¼ì„ ì–´ë–»ê²Œ í•œ ë²ˆì— ì²˜ë¦¬í•˜ë‚˜ìš”?**
    A: WOSì—ì„œ ì—¬ëŸ¬ ë²ˆ Plain Text ë‹¤ìš´ë¡œë“œí•œ í›„, ëª¨ë“  .txt íŒŒì¼ì„ í•œ ë²ˆì— ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ ë³‘í•©ë˜ë©° PRISMA ê¸°ì¤€ì´ ì ìš©ë©ë‹ˆë‹¤.
    
    **Q: ì¤‘ë³µëœ ë…¼ë¬¸ì´ ìˆì„ê¹Œë´ ê±±ì •ë©ë‹ˆë‹¤.**
    A: UT(Unique Article Identifier) ê¸°ì¤€ìœ¼ë¡œ ìë™ ì¤‘ë³µ ì œê±°ë˜ë©°, UTê°€ ì—†ìœ¼ë©´ ì œëª©+ì €ì ì¡°í•©ìœ¼ë¡œ ì¤‘ë³µì„ ê°ì§€í•©ë‹ˆë‹¤.
    
    **Q: WOSì—ì„œ ì–´ë–¤ ì„¤ì •ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•´ì•¼ í•˜ë‚˜ìš”?**
    A: Export â†’ Record Content: "Full Record and Cited References", File Format: "Plain Text"ë¡œ ì„¤ì •í•˜ì„¸ìš”. ì¸ìš© ê´€ê³„ ë¶„ì„ì„ ìœ„í•´ ì°¸ê³ ë¬¸í—Œ ì •ë³´ê°€ í•„ìˆ˜ì…ë‹ˆë‹¤.
    
    **Q: Review ë…¼ë¬¸ë“¤ì€ ì–´ë–»ê²Œ ì²˜ë¦¬í•´ì•¼ í•˜ë‚˜ìš”?**
    A: Reviewë¡œ ë¶„ë¥˜ëœ ë…¼ë¬¸ë“¤ì€ ì¶”ê°€ ìˆ˜ë™ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤. ì—‘ì…€ ë‹¤ìš´ë¡œë“œ í›„ ì œëª©ê³¼ ì´ˆë¡ì„ í™•ì¸í•˜ì—¬ ì—°êµ¬ ë²”ìœ„ í¬í•¨ ì—¬ë¶€ë¥¼ ê²°ì •í•˜ì„¸ìš”.
    
    **Q: SCIMATì—ì„œ í‚¤ì›Œë“œ ì •ë¦¬ë¥¼ ì–´ë–»ê²Œ í•˜ë‚˜ìš”?**
    A: Group set â†’ Word â†’ Find similar words by distances (Maximum distance: 1)ë¡œ ìœ ì‚¬ í‚¤ì›Œë“œë¥¼ ìë™ í†µí•©í•˜ê³ , Word Group manual setì—ì„œ ìˆ˜ë™ìœ¼ë¡œ ê´€ë ¨ í‚¤ì›Œë“œë“¤ì„ ê·¸ë£¹í™”í•˜ì„¸ìš”.
    
    **Q: ë³‘í•©ëœ íŒŒì¼ì´ SCIMATì—ì„œ ì œëŒ€ë¡œ ë¡œë”©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.**
    A: ì›ë³¸ WOS íŒŒì¼ë“¤ì´ 'FN Clarivate Analytics Web of Science'ë¡œ ì‹œì‘í•˜ëŠ” ì •í’ˆ Plain Text íŒŒì¼ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.
    
    **Q: ëª‡ ê°œì˜ íŒŒì¼ê¹Œì§€ ë™ì‹œì— ì—…ë¡œë“œí•  ìˆ˜ ìˆë‚˜ìš”?**
    A: ê¸°ìˆ ì ìœ¼ë¡œëŠ” ì œí•œì´ ì—†ì§€ë§Œ, ì•ˆì •ì„±ì„ ìœ„í•´ 10ê°œ ì´í•˜ì˜ íŒŒì¼ì„ ê¶Œì¥í•©ë‹ˆë‹¤. ë§¤ìš° í° ë°ì´í„°ì…‹ì˜ ê²½ìš° ë‚˜ëˆ„ì–´ì„œ ì²˜ë¦¬í•˜ì„¸ìš”.
    """)

# SciMAT ë¶„ì„ ê°€ì´ë“œ - í•­ìƒ í‘œì‹œ
with st.expander("ğŸ“Š WOS â†’ SciMAT ë¶„ì„ ì‹¤í–‰ ê°€ì´ë“œ", expanded=False):
    st.markdown("""
    ### í•„ìš”í•œ ê²ƒ
    - SciMAT ì†Œí”„íŠ¸ì›¨ì–´ (ë¬´ë£Œ ë‹¤ìš´ë¡œë“œ)
    - ë‹¤ìš´ë¡œë“œëœ WOS Plain Text íŒŒì¼
    - Java 1.8 ì´ìƒ
    
    ### 1ë‹¨ê³„: SciMAT ì‹œì‘í•˜ê¸°
    
    **ìƒˆ í”„ë¡œì íŠ¸ ìƒì„±**
    ```
    1. SciMAT ì‹¤í–‰ (SciMAT.jar ë”ë¸”í´ë¦­)
    2. File â†’ New Project
    3. Path: ì €ì¥í•  í´ë” ì„ íƒ
    4. File name: í”„ë¡œì íŠ¸ ì´ë¦„ ì…ë ¥
    5. Accept
    ```
    
    **ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°**
    ```
    1. File â†’ Add Files
    2. "ISI WoS" ì„ íƒ
    3. ë‹¤ìš´ë¡œë“œí•œ txt íŒŒì¼ ì„ íƒ
    4. ë¡œë”© ì™„ë£Œê¹Œì§€ ëŒ€ê¸°
    ```
    
    ### 2ë‹¨ê³„: í‚¤ì›Œë“œ ì •ë¦¬í•˜ê¸°
    
    **ìœ ì‚¬ í‚¤ì›Œë“œ ìë™ í†µí•©**
    ```
    1. Group set â†’ Word â†’ Find similar words by distances
    2. Maximum distance: 1 (í•œ ê¸€ì ì°¨ì´)
    3. ê°™ì€ ì˜ë¯¸ ë‹¨ì–´ë“¤ í™•ì¸í•˜ê³  Moveë¡œ í†µí•©
    ```
    ì˜ë¯¸: ì² ìê°€ 1ê¸€ìë§Œ ë‹¤ë¥¸ ë‹¨ì–´ë“¤ì„ ì°¾ì•„ì„œ ì œì•ˆ (ì˜ˆ: "platform" â†” "platforms")
    
    **ìˆ˜ë™ìœ¼ë¡œ í‚¤ì›Œë“œ ì •ë¦¬**
    ```
    1. Group set â†’ Word â†’ Word Group manual set
    2. Words without group ëª©ë¡ í™•ì¸
    3. ê´€ë ¨ í‚¤ì›Œë“œë“¤ ì„ íƒ í›„ New groupìœ¼ë¡œ ë¬¶ê¸°
    4. ë¶ˆí•„ìš”í•œ í‚¤ì›Œë“œ ì œê±°
    ```
    ëª©ì : ë°ì´í„° í’ˆì§ˆ í–¥ìƒ, ì˜ë¯¸ ìˆëŠ” í´ëŸ¬ìŠ¤í„° í˜•ì„±
    
    ### 3ë‹¨ê³„: ì‹œê°„ êµ¬ê°„ ì„¤ì •
    
    **Period ë§Œë“¤ê¸°**
    ```
    1. Knowledge base â†’ Periods â†’ Periods manager
    2. Add ë²„íŠ¼ìœ¼ë¡œ ì‹œê°„ êµ¬ê°„ ìƒì„±:
       - Period 1: 1996-2006 (íƒœë™ê¸°)
       - Period 2: 2007-2016 (í˜•ì„±ê¸°)
       - Period 3: 2017-2021 (í™•ì‚°ê¸°)
       - Period 4: 2022-2024 (ì„±ìˆ™ê¸°)
    ```
    ì›ë¦¬: ì—°êµ¬ ë¶„ì•¼ì˜ ì§„í™” ë‹¨ê³„ë¥¼ ë°˜ì˜í•œ ì˜ë¯¸ ìˆëŠ” êµ¬ë¶„
    
    **ê° Periodì— ë…¼ë¬¸ í• ë‹¹**
    ```
    1. Period 1 í´ë¦­ â†’ Add
    2. í•´ë‹¹ ì—°ë„ ë…¼ë¬¸ë“¤ ì„ íƒ
    3. ì˜¤ë¥¸ìª½ í™”ì‚´í‘œë¡œ ì´ë™
    4. ë‹¤ë¥¸ Periodë“¤ë„ ë™ì¼í•˜ê²Œ ë°˜ë³µ
    ```
    
    ### 4ë‹¨ê³„: ë¶„ì„ ì‹¤í–‰
    
    **ë¶„ì„ ë§ˆë²•ì‚¬ ì‹œì‘**
    ```
    1. Analysis â†’ Make Analysis
    2. ëª¨ë“  Period ì„ íƒ â†’ Next
    ```
    
    **Step 1-8: ë¶„ì„ ì„¤ì •**
    - Unit of Analysis: "Author's words + Source's words"
    - Data Reduction: Minimum frequency 2
    - Network Type: "Co-occurrence"
    - Normalization: "Equivalence Index"
    - Clustering: "Simple Centers Algorithm" (Max network size: 50)
    - Document Mapper: "Core Mapper"
    - Performance Measures: G-index, Sum Citations
    - Evolution Map: "Jaccard Index"
    
    **ë¶„ì„ ì‹¤í–‰**
    ```
    - Finish í´ë¦­
    - ì™„ë£Œê¹Œì§€ ëŒ€ê¸° (10-30ë¶„)
    ```
    
    ### 5ë‹¨ê³„: ê²°ê³¼ í•´ì„
    
    **ì „ëµì  ë‹¤ì´ì–´ê·¸ë¨ 4ì‚¬ë¶„ë©´**
    - ìš°ìƒë‹¨: Motor Themes (í•µì‹¬ ì£¼ì œ)
    - ì¢Œìƒë‹¨: Specialized Themes (ì „ë¬¸í™”ëœ ì£¼ì œ)
    - ì¢Œí•˜ë‹¨: Emerging/Declining Themes (ì‹ í¥/ì‡ í‡´ ì£¼ì œ)
    - ìš°í•˜ë‹¨: Basic Themes (ê¸°ì´ˆ ì£¼ì œ)
    
    **ì§„í™” ë§µ ë¶„ì„**
    - ë…¸ë“œ í¬ê¸° = ë…¼ë¬¸ ìˆ˜
    - ì—°ê²°ì„  ë‘ê»˜ = Jaccard ìœ ì‚¬ë„
    - ì‹œê°„ì— ë”°ë¥¸ ì£¼ì œ ë³€í™” ì¶”ì 
    
    ### ë¬¸ì œ í•´ê²°
    - í‚¤ì›Œë“œ ì •ë¦¬ë¥¼ ê¼¼ê¼¼íˆ (ë¶„ì„í’ˆì§ˆì˜ í•µì‹¬)
    - Periodë³„ ìµœì†Œ 50í¸ ì´ìƒ ê¶Œì¥
    - Java ë©”ëª¨ë¦¬ ë¶€ì¡±ì‹œ ì¬ì‹œì‘
    - ì¸ì½”ë”© ë¬¸ì œì‹œ UTF-8ë¡œ ë³€ê²½
    """)

# PRISMA ê¸°ì¤€ ìƒì„¸ ê°€ì´ë“œ - ìƒˆë¡œ ì¶”ê°€
with st.expander("ğŸ“‹ PRISMA 2020 í¬í•¨/ë°°ì œ ê¸°ì¤€ ìƒì„¸ ê°€ì´ë“œ", expanded=False):
    st.markdown("""
    ### í¬í•¨ê¸°ì¤€ (Inclusion Criteria)
    
    **IC1: ì‚¬íšŒ-ê¸°ìˆ  ì‹œìŠ¤í…œìœ¼ë¡œì„œì˜ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬**
    ```
    âœ… í¬í•¨ë˜ëŠ” ì—°êµ¬:
    - ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° í”Œë«í¼ì˜ ì‚¬ìš©ì í–‰ë™ ë¶„ì„
    - ìŠ¤íŠ¸ë¦¬ë¨¸-ì‹œì²­ì ê°„ ìƒí˜¸ì‘ìš© ì—°êµ¬
    - ë¼ì´ë¸Œ ì»¤ë¨¸ìŠ¤ì˜ ì†Œë¹„ì êµ¬ë§¤ í–‰ë™
    - êµìœ¡ìš© ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë°ì˜ í•™ìŠµ íš¨ê³¼
    
    âŒ ì œì™¸ë˜ëŠ” ì—°êµ¬:
    - ë‹¨ìˆœ ê¸°ìˆ ì  ì„±ëŠ¥ ì¸¡ì • (ì‚¬ìš©ì ë§¥ë½ ì—†ìŒ)
    - ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì–¸ê¸‰ë§Œ ìˆëŠ” ì¼ë°˜ ì†Œì…œë¯¸ë””ì–´ ì—°êµ¬
    ```
    
    **IC2: ì‹¤ì‹œê°„ ì–‘ë°©í–¥ ìƒí˜¸ì‘ìš© í•„ìˆ˜**
    ```
    âœ… í¬í•¨ë˜ëŠ” ì—°êµ¬:
    - ì‹¤ì‹œê°„ ì±„íŒ…, ëŒ“ê¸€, ë¦¬ì•¡ì…˜ ë¶„ì„
    - ë¼ì´ë¸Œ ë°©ì†¡ ì¤‘ ì¦‰ì„ í”¼ë“œë°± ì—°êµ¬
    - ë™ê¸°ì‹(synchronous) ìƒí˜¸ì‘ìš© ë¶„ì„
    - ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë°ì˜ ì¦‰ì‹œì„±(immediacy) ì—°êµ¬
    
    âŒ ì œì™¸ë˜ëŠ” ì—°êµ¬:
    - ì¼ë°©í–¥ ë°©ì†¡ë§Œ ë‹¤ë£¨ëŠ” ì—°êµ¬
    - ë¹„ë™ê¸° ìƒí˜¸ì‘ìš©ë§Œ ë¶„ì„í•˜ëŠ” ì—°êµ¬
    - VOD(ì£¼ë¬¸í˜• ë¹„ë””ì˜¤)ì™€ êµ¬ë¶„ë˜ì§€ ì•ŠëŠ” ì—°êµ¬
    ```
    
    **IC3: í”Œë«í¼ ìƒíƒœê³„ ë§¥ë½**
    ```
    âœ… í¬í•¨ë˜ëŠ” ì—°êµ¬:
    - í”Œë«í¼ ê²½ì œí•™ ê´€ì ì˜ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë°
    - ë‹¤ë©´ì‹œì¥(multi-sided market)ìœ¼ë¡œì„œì˜ ë¶„ì„
    - í”Œë«í¼ ê±°ë²„ë„ŒìŠ¤ì™€ ì •ì±… ì—°êµ¬
    - ë„¤íŠ¸ì›Œí¬ íš¨ê³¼ ë¶„ì„
    
    âŒ ì œì™¸ë˜ëŠ” ì—°êµ¬:
    - í”Œë«í¼ ë§¥ë½ ì—†ëŠ” ê°œë³„ì  ê¸°ìˆ  ì—°êµ¬
    - ìƒíƒœê³„ ê´€ì ì´ ë¶€ì¡±í•œ ë‹¨í¸ì  ë¶„ì„
    ```
    
    ### ë°°ì œê¸°ì¤€ (Exclusion Criteria)
    
    **EC1: ìˆœìˆ˜ê¸°ìˆ ì—°êµ¬ (ì‚¬íšŒ-ê¸°ìˆ ë§¥ë½ ë¶€ì¬)**
    ```
    ì œì™¸ë˜ëŠ” ì—°êµ¬:
    - ë„¤íŠ¸ì›Œí¬ í”„ë¡œí† ì½œ ìµœì í™”ë§Œ ë‹¤ë£¨ëŠ” ì—°êµ¬
    - ë¹„ë””ì˜¤ ì½”ë± ì„±ëŠ¥ í–¥ìƒ ì—°êµ¬
    - ì„œë²„ ì¸í”„ë¼ êµ¬ì¡° ì„¤ê³„ ì—°êµ¬
    - í•˜ë“œì›¨ì–´ êµ¬í˜„ ìµœì í™” ì—°êµ¬
    ```
    
    **EC2: í”¼ìƒì  ì–¸ê¸‰ (í˜•ìš©ì‚¬ ìˆ˜ì¤€)**
    ```
    ì œì™¸ë˜ëŠ” ì—°êµ¬:
    - ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë°ì„ ì˜ˆì‹œë¡œë§Œ ì–¸ê¸‰
    - "í–¥í›„ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë°ì— ì ìš© ê°€ëŠ¥" ì •ë„ì˜ ì–¸ê¸‰
    - ì—°êµ¬ ë°©ë²•ë¡ ì—ì„œ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë°ê³¼ ì¼ë°˜ ë¯¸ë””ì–´ êµ¬ë¶„ ì—†ìŒ
    ```
    
    **EC3: ë¯¸ë˜ì—°êµ¬ ì œì•ˆì—ë§Œ ì–¸ê¸‰**
    ```
    ì œì™¸ë˜ëŠ” ì—°êµ¬:
    - ê²°ë¡ ë¶€ì—ì„œë§Œ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì–¸ê¸‰
    - ì‹¤ì œ ë°ì´í„°ë‚˜ ë¶„ì„ì—ëŠ” í¬í•¨ë˜ì§€ ì•ŠìŒ
    - "future work"ì—ì„œë§Œ ê°€ëŠ¥ì„± ì œì‹œ
    ```
    
    **EC4: ì‹¤ì‹œê°„ ì–‘ë°©í–¥ ìƒí˜¸ì‘ìš© ë¯¸ê³ ë ¤**
    ```
    ì œì™¸ë˜ëŠ” ì—°êµ¬:
    - ì¼ë°©í–¥ ë°©ì†¡ë§Œ ë¶„ì„
    - ë¹„ë™ê¸°ì  ìƒí˜¸ì‘ìš©ë§Œ ê³ ë ¤
    - ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë°ì˜ ì‹¤ì‹œê°„ì„± ë¬´ì‹œ
    ```
    
    **EC5: VOD/ì¼ë°˜ë¹„ë””ì˜¤ì™€ êµ¬ë¶„ë¶ˆê°€**
    ```
    ì œì™¸ë˜ëŠ” ì—°êµ¬:
    - ì£¼ë¬¸í˜• ë¹„ë””ì˜¤(VOD) ì—°êµ¬ì™€ êµ¬ë¶„ë˜ì§€ ì•ŠìŒ
    - ì‚¬ì „ ë…¹í™” ì½˜í…ì¸  ë¶„ì„
    - ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ê³ ìœ  íŠ¹ì„± ë¯¸ë°˜ì˜
    ```
    
    **EC6: ë¬¸ì„œìœ í˜• ë°°ì œ (ë¹„í•™ìˆ ë…¼ë¬¸)**
    ```
    ì œì™¸ë˜ëŠ” ë¬¸ì„œ:
    - í¸ì§‘ì ì„œì‹ , ì‚¬ì„¤
    - í•™íšŒ í”„ë¡œì‹œë”© ì´ˆë¡
    - ë„ì„œ ì±•í„°
    - ë¦¬ë·° ë…¼ë¬¸ (ê°œë³„ ì—°êµ¬ ë™í–¥ ë¶„ì„ì´ ëª©ì ì´ë¯€ë¡œ)
    ```
    
    **EC7: ì¤‘ë³µê²Œì¬ ì˜ì‹¬**
    ```
    ì œì™¸ë˜ëŠ” ì—°êµ¬:
    - ë™ì¼ ì—°êµ¬ì˜ í™•ì¥íŒ/ì¶•ì•½íŒ
    - í•™íšŒë°œí‘œë¥¼ ì €ë„ë¡œ ì¬ê²Œì¬í•œ ê²½ìš°
    - ì‹¤ì§ˆì ìœ¼ë¡œ ë™ì¼í•œ ë‚´ìš©ì˜ ì¤‘ë³µ ì¶œê°„
    ```
    
    **EC8: ì‹¤í—˜ì‹¤í™˜ê²½ê²€ì¦ (ì‹¤ì‚¬ìš©ë§¥ë½ ë¶€ì¬)**
    ```
    ì œì™¸ë˜ëŠ” ì—°êµ¬:
    - ì‹¤ì œ í”Œë«í¼ ì—†ëŠ” í”„ë¡œí† íƒ€ì… í…ŒìŠ¤íŠ¸
    - ì‹¤ì‚¬ìš©ì ì—†ëŠ” ì„±ëŠ¥ ê²€ì¦
    - í˜„ì‹¤ ë§¥ë½ì„ ê³ ë ¤í•˜ì§€ ì•Šì€ ê¸°ìˆ ì  ê²€ì¦
    ```
    
    ### ê²½ê³„ì‚¬ë¡€ íŒë‹¨ ê°€ì´ë“œ
    
    **ì• ë§¤í•œ ê²½ìš° â†’ Reviewë¡œ ë¶„ë¥˜**
    ```
    - ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ê´€ë ¨ì„±ì€ ìˆìœ¼ë‚˜ IC ì¡°ê±´ ë¶ˆë¶„ëª…
    - ê°„ì ‘ì  ê´€ë ¨ì„±ë§Œ ìˆëŠ” ì—°êµ¬
    - ìˆ˜ë™ ê²€í† ë¥¼ í†µí•´ ìµœì¢… í¬í•¨ ì—¬ë¶€ ê²°ì •
    ```
    
    **ì ìš© ìˆœì„œ**
    ```
    1. EC6 (ë¬¸ì„œìœ í˜•) ìµœìš°ì„  ê²€ì‚¬
    2. EC1-EC8 ë°°ì œê¸°ì¤€ ìˆœì°¨ ì ìš©
    3. IC1-IC3 í¬í•¨ê¸°ì¤€ ê²€ì¦
    4. ì• ë§¤í•œ ê²½ìš° Reviewë¡œ ë¶„ë¥˜í•˜ì—¬ ìˆ˜ë™ ê²€í† 
    ```
    """)

st.markdown("<br><br>", unsafe_allow_html=True)
