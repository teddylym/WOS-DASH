import streamlit as st
import pandas as pd
import altair as alt
import io
import re
from collections import Counter

# --- í˜ì´ì§€ ì„¤ì • ---
st.set_page_config(
    page_title="WOS Multi-File Merger | SCIMAT Edition",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# --- í† ìŠ¤ ìŠ¤íƒ€ì¼ CSS ---
st.markdown("""
<style>
    @import url('https://fonts.googleapis.com/css2?family=Pretendard:wght@400;500;600;700&display=swap');
    
    .main-container {
        background: #f2f4f6;
        min-height: 100vh;
        font-family: 'Pretendard', -apple-system, BlinkMacSystemFont, system-ui, sans-serif;
    }
    
    .metric-card {
        background: white;
        border-radius: 8px;
        padding: 20px;
        box-shadow: none;
        border: 1px solid #e5e8eb;
        margin-bottom: 12px;
        transition: all 0.2s ease;
    }
    
    .metric-card:hover {
        box-shadow: 0 2px 8px rgba(0,0,0,0.08);
        transform: translateY(-1px);
        border-color: #3182f6;
    }
    
    .metric-value {
        font-size: 2.2rem;
        font-weight: 700;
        color: #191f28;
        margin: 0;
        line-height: 1.2;
        letter-spacing: -0.02em;
    }
    
    .metric-label {
        font-size: 13px;
        color: #8b95a1;
        margin: 6px 0 0 0;
        font-weight: 500;
        letter-spacing: -0.01em;
    }
    
    .metric-icon {
        background: #3182f6;
        color: white;
        width: 32px;
        height: 32px;
        border-radius: 6px;
        display: flex;
        align-items: center;
        justify-content: center;
        font-size: 16px;
        margin-bottom: 12px;
    }
    
    .chart-container {
        background: white;
        border-radius: 8px;
        padding: 24px;
        box-shadow: none;
        border: 1px solid #e5e8eb;
        margin: 16px 0;
    }
    
    .chart-title {
        font-size: 16px;
        font-weight: 600;
        color: #191f28;
        margin-bottom: 16px;
        letter-spacing: -0.01em;
    }
    
    .section-header {
        background: white;
        color: #191f28;
        padding: 16px 20px;
        border-radius: 8px;
        margin: 20px 0 12px 0;
        box-shadow: none;
        border: 1px solid #e5e8eb;
        position: relative;
        overflow: hidden;
    }
    
    .section-header::before {
        content: '';
        position: absolute;
        top: 0;
        left: 0;
        width: 4px;
        height: 100%;
        background: #3182f6;
    }
    
    .section-title {
        font-size: 16px;
        font-weight: 600;
        margin: 0;
        letter-spacing: -0.01em;
        color: #191f28;
    }
    
    .section-subtitle {
        font-size: 13px;
        color: #8b95a1;
        margin: 4px 0 0 0;
        font-weight: 400;
        letter-spacing: 0;
    }
    
    .info-panel {
        background: #f8fafe;
        border: 1px solid #e1f2ff;
        border-radius: 8px;
        padding: 16px;
        margin: 12px 0;
        position: relative;
    }
    
    .success-panel {
        background: #f0fdf4;
        border: 1px solid #dcfce7;
        border-radius: 8px;
        padding: 16px;
        margin: 12px 0;
        position: relative;
    }
    
    .warning-panel {
        background: #fffbeb;
        border: 1px solid #fed7aa;
        border-radius: 8px;
        padding: 16px;
        margin: 12px 0;
        position: relative;
    }
    
    .feature-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
        gap: 12px;
        margin: 20px 0;
    }
    
    .feature-card {
        background: white;
        border-radius: 8px;
        padding: 20px;
        text-align: center;
        box-shadow: none;
        border: 1px solid #e5e8eb;
        transition: all 0.2s ease;
        position: relative;
        overflow: hidden;
    }
    
    .feature-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 12px rgba(0,0,0,0.08);
        border-color: #3182f6;
    }
    
    .feature-icon {
        font-size: 32px;
        margin-bottom: 12px;
        color: #3182f6;
    }
    
    .feature-title {
        font-size: 15px;
        font-weight: 600;
        color: #191f28;
        margin-bottom: 8px;
        letter-spacing: -0.01em;
    }
    
    .feature-desc {
        font-size: 13px;
        color: #8b95a1;
        line-height: 1.5;
        letter-spacing: 0;
    }
    
    .upload-zone {
        background: white;
        border: 1px dashed #d1d5db;
        border-radius: 8px;
        padding: 24px;
        text-align: center;
        margin: 16px 0;
        transition: all 0.2s ease;
    }
    
    .upload-zone:hover {
        background: #f8fafe;
        border-color: #3182f6;
    }
    
    .progress-indicator {
        background: #3182f6;
        height: 3px;
        border-radius: 2px;
        margin: 12px 0;
        animation: pulse 2s infinite;
    }
    
    .file-status {
        background: #f8fafe;
        border-radius: 6px;
        padding: 12px;
        margin: 8px 0;
        border-left: 3px solid #3182f6;
        font-family: 'Pretendard', sans-serif;
    }
    
    .stDownloadButton > button {
        background: #3182f6 !important;
        color: white !important;
        border: none !important;
        border-radius: 8px !important;
        padding: 12px 24px !important;
        font-weight: 600 !important;
        font-size: 14px !important;
        letter-spacing: -0.01em !important;
        transition: all 0.2s ease !important;
        box-shadow: 0 1px 3px rgba(0,0,0,0.1) !important;
        font-family: 'Pretendard', sans-serif !important;
    }
    
    .stDownloadButton > button:hover {
        background: #1c64f2 !important;
        transform: translateY(-1px) !important;
        box-shadow: 0 2px 6px rgba(0,0,0,0.15) !important;
    }
    
    .streamlit-expanderHeader {
        background: white !important;
        border-radius: 8px !important;
        border: 1px solid #e5e8eb !important;
        font-weight: 500 !important;
        color: #191f28 !important;
        font-family: 'Pretendard', sans-serif !important;
        font-size: 14px !important;
    }
    
    .stDataFrame {
        border-radius: 8px !important;
        overflow: hidden !important;
        border: 1px solid #e5e8eb !important;
    }
    
    .stSpinner {
        color: #3182f6 !important;
    }
    
    @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.6; }
    }
    
    .main .block-container {
        padding-top: 1.5rem;
        padding-bottom: 1.5rem;
        max-width: 1200px;
    }
    
    .stAlert {
        border-radius: 8px !important;
        border: none !important;
        font-family: 'Pretendard', sans-serif !important;
        font-size: 14px !important;
    }
    
    .stSuccess {
        background: #f0fdf4 !important;
        color: #15803d !important;
    }
    
    .stInfo {
        background: #f8fafe !important;
        color: #1d4ed8 !important;
    }
    
    .stWarning {
        background: #fffbeb !important;
        color: #d97706 !important;
    }
    
    .stError {
        background: #fef2f2 !important;
        color: #dc2626 !important;
    }
    
    .main-text {
        font-size: 14px;
        color: #191f28;
        line-height: 1.5;
    }
    
    .sub-text {
        font-size: 13px;
        color: #8b95a1;
        line-height: 1.4;
    }
    
    .small-text {
        font-size: 12px;
        color: #8b95a1;
        line-height: 1.3;
    }
</style>
""", unsafe_allow_html=True)

# --- ë‹¤ì¤‘ WOS Plain Text íŒŒì¼ ë¡œë”© ë° ë³‘í•© í•¨ìˆ˜ ---
def load_and_merge_wos_files(uploaded_files):
    """ë‹¤ì¤‘ WOS Plain Text íŒŒì¼ì„ ë¡œë”©í•˜ê³  ë³‘í•©í•©ë‹ˆë‹¤."""
    all_dataframes = []
    file_status = []
    
    for uploaded_file in uploaded_files:
        try:
            file_bytes = uploaded_file.getvalue()
            encodings_to_try = ['utf-8-sig', 'utf-8', 'latin1']
            df = None
            encoding_used = None
            
            for encoding in encodings_to_try:
                try:
                    file_content = file_bytes.decode(encoding)
                    if file_content.strip().startswith('FN '):
                        df = parse_wos_format(file_content)
                        if df is not None and not df.empty:
                            encoding_used = encoding
                            break
                except Exception:
                    continue
            
            if df is not None:
                all_dataframes.append(df)
                file_status.append({
                    'filename': uploaded_file.name,
                    'status': 'SUCCESS',
                    'papers': len(df),
                    'encoding': encoding_used,
                    'message': f'âœ… {len(df)}í¸ ë…¼ë¬¸ ë¡œë”© ì„±ê³µ'
                })
            else:
                file_status.append({
                    'filename': uploaded_file.name, 'status': 'ERROR', 'papers': 0, 'encoding': 'N/A',
                    'message': 'âŒ WOS Plain Text í˜•ì‹ì´ ì•„ë‹ˆê±°ë‚˜ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.'
                })
        except Exception as e:
            file_status.append({
                'filename': uploaded_file.name, 'status': 'ERROR', 'papers': 0, 'encoding': 'N/A',
                'message': f'âŒ íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {e}'
            })
    
    if all_dataframes:
        merged_df = pd.concat(all_dataframes, ignore_index=True)
        original_count = len(merged_df)
        
        duplicates_removed = 0
        if 'UT' in merged_df.columns:
            ut_not_na = merged_df[merged_df['UT'].notna()]
            ut_is_na = merged_df[merged_df['UT'].isna()]
            
            ut_not_na_dedup = ut_not_na.drop_duplicates(subset=['UT'], keep='first')
            
            merged_df = pd.concat([ut_not_na_dedup, ut_is_na], ignore_index=True)
            duplicates_removed = original_count - len(merged_df)
            
        return merged_df, file_status, duplicates_removed
    else:
        return None, file_status, 0

def parse_wos_format(content):
    """WOS Plain Text í˜•ì‹ì„ DataFrameìœ¼ë¡œ ë³€í™˜"""
    lines = content.split('\n')
    records = []
    current_record = {}
    current_field = None
    
    for line in lines:
        line = line.rstrip()
        
        if not line:
            continue
            
        if line == 'ER':
            if current_record:
                records.append(current_record.copy())
                current_record = {}
                current_field = None
            continue
            
        if line.startswith(('FN ', 'VR ')):
            continue
            
        if not line.startswith('   ') and ' ' in line:
            parts = line.split(' ', 1)
            if len(parts) == 2 and len(parts[0]) == 2 and parts[0].isalpha():
                field_tag, field_value = parts
                current_field = field_tag
                if field_tag in current_record:
                     current_record[field_tag] += '; ' + field_value.strip()
                else:
                    current_record[field_tag] = field_value.strip()
        
        elif line.startswith('   ') and current_field and current_field in current_record:
            continuation_value = line[3:].strip()
            if continuation_value:
                current_record[current_field] += '; ' + continuation_value
    
    if current_record:
        records.append(current_record)
    
    if not records:
        return None
        
    return pd.DataFrame(records)

# --- ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° íŠ¹í™” ë¶„ë¥˜ í•¨ìˆ˜ (ìƒˆë¡œìš´ IC/EC ê¸°ì¤€ ì ìš©) ---
def classify_article(row):
    """ìƒˆë¡œìš´ IC/EC ê¸°ì¤€ì— ë”°ë¼ ë…¼ë¬¸ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤."""
    title = str(row.get('TI', '')).lower()
    abstract = str(row.get('AB', '')).lower()
    author_keywords = str(row.get('DE', '')).lower()
    keywords_plus = str(row.get('ID', '')).lower()
    doc_type = str(row.get('DT', '')).lower()
    
    full_text = ' '.join([title, abstract, author_keywords, keywords_plus])

    # EC4: í•™ìˆ ì  ì—„ë°€ì„± ë¶€ì¡± (ê°€ì¥ ë¨¼ì € í•„í„°ë§)
    non_academic_types = ['editorial material', 'letter', 'meeting abstract', 'correction', 'book review', 'note']
    if any(doc_type_kw in doc_type for doc_type_kw in non_academic_types):
         return 'EC4: í•™ìˆ ì  ì—„ë°€ì„± ë¶€ì¡± (Lack of Academic Rigor)'

    # IC2 (í•™ìˆ ì  í˜•íƒœ) - article, reviewê°€ ì•„ë‹Œ ê²½ìš° EC4ë¡œ ì²˜ë¦¬
    if 'article' not in doc_type and 'review' not in doc_type:
        return 'EC4: í•™ìˆ ì  ì—„ë°€ì„± ë¶€ì¡± (Lack of Academic Rigor)'

    # EC1: ì£¼ì œ ê´€ë ¨ì„± ë¶€ì¡± (ë¶€ì°¨ì  ì–¸ê¸‰)
    core_keywords = ['live stream', 'livestream', 'live commerce', 'game streaming', 'virtual influencer', 'streamer', 'twitch', 'youtube live']
    if not any(kw in full_text for kw in core_keywords):
        return 'EC1: ì£¼ì œ ê´€ë ¨ì„± ë¶€ì¡± (Topic Irrelevance)'

    # EC2: ì‚¬íšŒ-ê¸°ìˆ ì  ë§¥ë½ ë¶€ì¬ (ìˆœìˆ˜ ê¸°ìˆ )
    pure_tech_keywords = ['protocol', 'codec', 'latency optimization', 'bandwidth allocation', 'network topology', 'signal processing', 'video compression', 'qos']
    socio_tech_keywords = ['user', 'behavior', 'social', 'economic', 'community', 'motivation', 'engagement', 'psychology', 'culture']
    if any(kw in full_text for kw in pure_tech_keywords) and not any(kw in full_text for kw in socio_tech_keywords):
        return 'EC2: ì‚¬íšŒ-ê¸°ìˆ ì  ë§¥ë½ ë¶€ì¬ (Lack of Socio-Technical Context)'

    # EC3: ìƒí˜¸ì‘ìš©ì„± ë¶€ì¬ (ë‹¨ë°©í–¥ ë°©ì†¡)
    oneway_keywords = ['vod', 'video on demand', 'traditional broadcast', 'non-interactive']
    interactive_keywords = ['interactive', 'chat', 'real-time', 'community', 'engagement', 'synchronous', 'parasocial']
    if any(kw in full_text for kw in oneway_keywords) and not any(kw in full_text for kw in interactive_keywords):
        return 'EC3: ìƒí˜¸ì‘ìš©ì„± ë¶€ì¬ (Lack of Interactivity)'
    
    return 'í¬í•¨ (Included)'

# --- ë°ì´í„° í’ˆì§ˆ ì§„ë‹¨ í•¨ìˆ˜ ---
def diagnose_merged_quality(df, file_count, duplicates_removed):
    """ë³‘í•©ëœ WOS ë°ì´í„°ì˜ í’ˆì§ˆ ì§„ë‹¨"""
    issues = []
    recommendations = []
    
    required_fields = ['TI', 'AU', 'SO', 'PY']
    keyword_fields = ['DE', 'ID']
    
    for field in required_fields:
        if field not in df.columns or (not df.empty and df[field].isnull().sum() > len(df) * 0.1):
            missing_rate = df[field].isnull().sum() / len(df) * 100 if field in df.columns and not df.empty else 100
            issues.append(f"âš ï¸ {field} í•„ë“œì˜ {missing_rate:.1f}%ê°€ ëˆ„ë½ë¨")
    
    has_keywords = any(field in df.columns for field in keyword_fields)
    if not has_keywords:
        issues.append("âŒ í‚¤ì›Œë“œ í•„ë“œ ì—†ìŒ (DE ë˜ëŠ” ID)")
    
    recommendations.append(f"âœ… {file_count}ê°œ íŒŒì¼ ì„±ê³µì ìœ¼ë¡œ ë³‘í•©ë¨")
    if duplicates_removed > 0:
        recommendations.append(f"ğŸ”„ ì¤‘ë³µ ë…¼ë¬¸ {duplicates_removed}í¸ ìë™ ì œê±°ë¨")
    
    return issues, recommendations

# --- WOS Plain Text í˜•ì‹ ë³€í™˜ í•¨ìˆ˜ (SciMAT í˜¸í™˜) ---
def convert_to_scimat_wos_format(df_to_convert):
    """SCIMAT ì™„ì „ í˜¸í™˜ WOS Plain Text í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    wos_field_order = [
        'PT', 'AU', 'AF', 'TI', 'SO', 'LA', 'DT', 'DE', 'ID', 'AB', 'C1', 'C3', 'RP',
        'EM', 'RI', 'OI', 'FU', 'FX', 'CR', 'NR', 'TC', 'Z9', 'U1', 'U2', 'PU', 'PI', 'PA',
        'SN', 'EI', 'J9', 'JI', 'PD', 'PY', 'VL', 'IS', 'BP', 'EP', 'DI', 'EA', 'PG',
        'WC', 'WE', 'SC', 'GA', 'UT', 'PM', 'OA', 'DA'
    ]
    
    file_content = ["FN Clarivate Analytics Web of Science", "VR 1.0"]
    multi_line_fields = ['AU', 'AF', 'DE', 'ID', 'C1', 'C3', 'CR']

    for _, row in df_to_convert.iterrows():
        if len(file_content) > 2:
            file_content.append("")
        
        for tag in wos_field_order:
            if tag in row.index and pd.notna(row[tag]) and str(row[tag]).strip() and str(row[tag]).strip().lower() != 'nan':
                value = str(row[tag]).strip()
                
                if tag in multi_line_fields:
                    items = [item.strip() for item in value.split(';') if item.strip()]
                    if items:
                        file_content.append(f"{tag} {items[0]}")
                        for item in items[1:]:
                            file_content.append(f"   {item}")
                else:
                    file_content.append(f"{tag} {value}")
        
        file_content.append("ER")
    
    return "\n".join(file_content).encode('utf-8-sig')

def to_excel(df):
    """DataFrameì„ Excel íŒŒì¼ ë°”ì´íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
    output = io.BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='Sheet1')
    return output.getvalue()

# --- ë©”ì¸ í—¤ë” ---
st.markdown("""
<div style="position: relative; text-align: center; padding: 2.5rem 0 3rem 0; background: linear-gradient(135deg, #3182f6, #1c64f2); color: white; border-radius: 8px; margin-bottom: 1.5rem; box-shadow: 0 2px 8px rgba(49,130,246,0.15); overflow: hidden;">
    <div style="position: absolute; top: 1rem; left: 1.5rem; color: white;">
        <div style="font-size: 12px; font-weight: 600; margin-bottom: 3px; letter-spacing: 0.3px;">HANYANG UNIVERSITY</div>
        <div style="font-size: 11px; opacity: 0.9; font-weight: 500;">Technology Management Research</div>
        <div style="font-size: 10px; opacity: 0.8; margin-top: 4px; font-weight: 400;">mot.hanyang.ac.kr</div>
    </div>
    <div style="position: absolute; top: 1rem; right: 1.5rem; text-align: right; color: rgba(255,255,255,0.9); font-size: 11px;">
        <p style="margin: 0; font-weight: 500;">Developed by: ì„íƒœê²½ (Teddy Lym)</p>
    </div>
    <h1 style="font-size: 3rem; font-weight: 700; margin-bottom: 0.3rem; letter-spacing: -0.02em;">
        WOS PREP
    </h1>
    <p style="font-size: 1.1rem; margin: 0; font-weight: 500; opacity: 0.95; letter-spacing: -0.01em;">
        SCIMAT Edition
    </p>
    <div style="width: 80px; height: 3px; background-color: rgba(255,255,255,0.3); margin: 1.5rem auto; border-radius: 2px;"></div>
</div>
""", unsafe_allow_html=True)

# --- í•µì‹¬ ê¸°ëŠ¥ ì†Œê°œ ---
st.markdown("""
<div class="feature-grid">
    <div class="feature-card">
        <div class="feature-icon">ğŸ”—</div>
        <div class="feature-title">ë‹¤ì¤‘ íŒŒì¼ ìë™ ë³‘í•©</div>
        <div class="feature-desc">ì—¬ëŸ¬ WOS íŒŒì¼ì„ í•œ ë²ˆì— ë³‘í•© ì²˜ë¦¬</div>
    </div>
    <div class="feature-card">
        <div class="feature-icon">ğŸš«</div>
        <div class="feature-title">ìŠ¤ë§ˆíŠ¸ ì¤‘ë³µ ì œê±°</div>
        <div class="feature-desc">UT ê¸°ì¤€ ìë™ ì¤‘ë³µ ë…¼ë¬¸ ê°ì§€ ë° ì œê±°</div>
    </div>
    <div class="feature-card">
        <div class="feature-icon">ğŸ¯</div>
        <div class="feature-title">í•™ìˆ ì  ì—„ë°€ì„±</div>
        <div class="feature-desc">ê°œë… ê¸°ë°˜ í•™ìˆ ì  ì •ì œ ì ìš©</div>
    </div>
</div>
""", unsafe_allow_html=True)

# --- íŒŒì¼ ì—…ë¡œë“œ ì„¹ì…˜ ---
st.markdown("""
<div class="section-header">
    <div class="section-title">ğŸ“‚ ë‹¤ì¤‘ WOS Plain Text íŒŒì¼ ì—…ë¡œë“œ</div>
    <div class="section-subtitle">500ê°œ ë‹¨ìœ„ë¡œ ë‚˜ë‰œ ì—¬ëŸ¬ WOS íŒŒì¼ì„ ëª¨ë‘ ì„ íƒí•˜ì—¬ ì—…ë¡œë“œí•˜ì„¸ìš”</div>
</div>
""", unsafe_allow_html=True)

uploaded_files = st.file_uploader(
    "WOS Plain Text íŒŒì¼ ì„ íƒ (ë‹¤ì¤‘ ì„ íƒ ê°€ëŠ¥)",
    type=['txt'],
    accept_multiple_files=True,
    label_visibility="collapsed",
    help="WOS Plain Text íŒŒì¼ë“¤ì„ ë“œë˜ê·¸í•˜ì—¬ ë†“ê±°ë‚˜ í´ë¦­í•˜ì—¬ ì„ íƒí•˜ì„¸ìš”"
)

if 'show_exclude_details' not in st.session_state:
    st.session_state.show_exclude_details = False

if uploaded_files:
    st.markdown(f"ğŸ“‹ **ì„ íƒëœ íŒŒì¼ ê°œìˆ˜:** {len(uploaded_files)}ê°œ")
    
    st.markdown('<div class="progress-indicator"></div>', unsafe_allow_html=True)
    
    with st.spinner(f"ğŸ”„ {len(uploaded_files)}ê°œ WOS íŒŒì¼ ë³‘í•© ë° í•™ìˆ ì  ì •ì œ ì ìš© ì¤‘..."):
        merged_df, file_status, duplicates_removed = load_and_merge_wos_files(uploaded_files)
        
        if merged_df is None:
            st.error("âš ï¸ ì²˜ë¦¬ ê°€ëŠ¥í•œ WOS Plain Text íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
            st.stop()
        
        # ë…¼ë¬¸ ë¶„ë¥˜ ìˆ˜í–‰
        merged_df['Classification'] = merged_df.apply(classify_article, axis=1)

    successful_files = len([s for s in file_status if s['status'] == 'SUCCESS'])
    total_papers_before_filter = len(merged_df)
    
    df_included = merged_df[merged_df['Classification'] == 'í¬í•¨ (Included)'].copy()
    df_excluded = merged_df[merged_df['Classification'] != 'í¬í•¨ (Included)'].copy()
    
    st.success(f"âœ… ë³‘í•© ë° í•™ìˆ ì  ì •ì œ ì™„ë£Œ! ìµœì¢… {len(df_included):,}í¸ì˜ ë…¼ë¬¸ì„ ë¶„ì„ ëŒ€ìƒìœ¼ë¡œ ì„ ì •í–ˆìŠµë‹ˆë‹¤.")
    
    if duplicates_removed > 0:
        st.info(f"ğŸ”„ ì¤‘ë³µ ë…¼ë¬¸ {duplicates_removed}í¸ì´ ìë™ìœ¼ë¡œ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # --- ë¶„ì„ ê²°ê³¼ ìš”ì•½ ---
    st.markdown("""
    <div class="section-header">
        <div class="section-title">ğŸ“ˆ í•™ìˆ ì  ì •ì œ ê²°ê³¼</div>
        <div class="section-subtitle">í•™ìˆ ì  ì •ì œ ê¸°ì¤€ ì ìš© í›„ ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë° ì—°êµ¬ ë¶„ë¥˜ ê²°ê³¼</div>
    </div>
    """, unsafe_allow_html=True)

    col1, col2, col3 = st.columns(3)
    with col1:
        st.markdown(f'<div class="metric-card"><div class="metric-value">{total_papers_before_filter:,}</div><div class="metric-label">ì´ ê³ ìœ  ë…¼ë¬¸</div></div>', unsafe_allow_html=True)
    with col2:
        st.markdown(f'<div class="metric-card"><div class="metric-value" style="color:#10b981;">{len(df_included):,}</div><div class="metric-label">í¬í•¨ ëŒ€ìƒ ë…¼ë¬¸</div></div>', unsafe_allow_html=True)
    with col3:
        st.markdown(f'<div class="metric-card"><div class="metric-value" style="color:#ef4444;">{len(df_excluded):,}</div><div class="metric-label">ì œì™¸ ëŒ€ìƒ ë…¼ë¬¸</div></div>', unsafe_allow_html=True)
    
    with st.expander("â„¹ï¸ í¬í•¨/ì œì™¸(IC/EC) ê¸°ì¤€ ìƒì„¸ ì„¤ëª…", expanded=True):
        st.markdown("""
        #### í¬í•¨ ê¸°ì¤€ (Inclusion Criteria)
        - **IC1 (ì£¼ì œ ì¤‘ì‹¬ì„±):** ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë°ì˜ ê¸°ìˆ , í”Œë«í¼, ì‚¬ìš©ì, ì‚¬íšŒë¬¸í™”ì /ê²½ì œì  ì˜í–¥ì„ ì—°êµ¬ì˜ í•µì‹¬ ì£¼ì œ(primary subject)ë¡œ ë‹¤ë£¨ëŠ” ì—°êµ¬.
        - **IC2 (í•™ìˆ ì  í˜•íƒœ):** ë™ë£Œ ì‹¬ì‚¬(peer-review)ë¥¼ ê±°ì¹œ í•™ìˆ ì§€ ë…¼ë¬¸(Article) ë˜ëŠ” ë¦¬ë·°(Review).
        #### ì œì™¸ ê¸°ì¤€ (Exclusion Criteria)
        - **EC1 (ì£¼ì œ ê´€ë ¨ì„± ë¶€ì¡±):** ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë°ì„ ë‹¨ìˆœíˆ ë°ì´í„° ìˆ˜ì§‘ ë„êµ¬, ê¸°ìˆ ì  ì˜ˆì‹œ, ë˜ëŠ” ë¶€ì°¨ì  ë§¥ë½ìœ¼ë¡œë§Œ ì–¸ê¸‰í•œ ì—°êµ¬.
        - **EC2 (ì‚¬íšŒ-ê¸°ìˆ ì  ë§¥ë½ ë¶€ì¬):** ì‚¬íšŒì , ê²½ì œì , ì‚¬ìš©ì í–‰íƒœì  í•¨ì˜ì— ëŒ€í•œ ë¶„ì„ ì—†ì´, ìˆœìˆ˜í•˜ê²Œ ê¸°ìˆ  í”„ë¡œí† ì½œì˜ ê³µí•™ì  ì¸¡ë©´ë§Œ ë‹¤ë£¬ ì—°êµ¬.
        - **EC3 (ìƒí˜¸ì‘ìš©ì„± ë¶€ì¬):** ë¼ì´ë¸Œ ìŠ¤íŠ¸ë¦¬ë°ì˜ í•µì‹¬ íŠ¹ì§•ì¸ ì‹¤ì‹œê°„ ìƒí˜¸ì‘ìš© ê°œë…ì´ ê²°ì—¬ëœ ë‹¨ë°©í–¥ ë°©ì†¡(VOD)ì— ê´€í•œ ì—°êµ¬.
        - **EC4 (í•™ìˆ ì  ì—„ë°€ì„± ë¶€ì¡±):** ë™ë£Œ ì‹¬ì‚¬ë¥¼ ê±°ì¹˜ì§€ ì•Šì€ ì‚¬ì„¤, ì„œí‰, ì½˜í¼ëŸ°ìŠ¤ ì´ˆë¡ ë“±.
        """)

    st.markdown("""
    <div class="chart-container">
        <div class="chart-title">ë¶„ë¥˜ ê²°ê³¼ ë¶„í¬ (Classification Distribution)</div>
    """, unsafe_allow_html=True)
    classification_counts = merged_df['Classification'].value_counts().reset_index()
    classification_counts.columns = ['Classification', 'Count']
    
    chart = alt.Chart(classification_counts).mark_bar().encode(
        x=alt.X('Count:Q', title='ë…¼ë¬¸ ìˆ˜ (Number of Papers)'),
        y=alt.Y('Classification:N', title='ë¶„ë¥˜ (Classification)', sort='-x'),
        color=alt.condition(
            alt.datum.Classification == 'í¬í•¨ (Included)',
            alt.value('#10b981'),
            alt.value('#ef4444')
        ),
        tooltip=['Classification', 'Count']
    ).properties(height=300)
    st.altair_chart(chart, use_container_width=True)
    st.markdown("</div>", unsafe_allow_html=True)

    # --- ì œì™¸ ë…¼ë¬¸ ìƒì„¸ ë‹¤ìš´ë¡œë“œ ---
    if not df_excluded.empty:
        st.markdown("""
        <div class="chart-container">
            <div class="chart-title">âŒ ì œì™¸ ëŒ€ìƒ ë…¼ë¬¸ ìƒì„¸ (Excluded Papers Details)</div>
        """, unsafe_allow_html=True)
        st.warning(f"ì´ {len(df_excluded):,}í¸ì˜ ë…¼ë¬¸ì´ ê¸°ì¤€ì— ë”°ë¼ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒì„¸ ë‚´ìš©ì€ ì•„ë˜ ì—‘ì…€ íŒŒì¼ë¡œ ê²€í† í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        excel_data = to_excel(df_excluded[['TI', 'AU', 'PY', 'SO', 'Classification']].rename(columns={
            'TI': 'ì œëª© (Title)', 'AU': 'ì €ì (Authors)', 'PY': 'ì—°ë„ (Year)', 
            'SO': 'ì €ë„ (Journal)', 'Classification': 'ì œì™¸ì‚¬ìœ  (Exclusion Reason)'
        }))
        st.download_button(
           label=f"ğŸ“„ ì œì™¸ ë…¼ë¬¸ ì „ì²´ ëª©ë¡ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ ({len(df_excluded):,}í¸)",
           data=excel_data,
           file_name=f"Excluded_{len(df_excluded)}_papers.xlsx",
           mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
           use_container_width=True,
           type="secondary",
           key="download_excel_button"
        )
        st.markdown("</div>", unsafe_allow_html=True)


    # --- ìµœì¢… íŒŒì¼ ë‹¤ìš´ë¡œë“œ ì„¹ì…˜ ---
    st.markdown("""
    <div class="section-header">
        <div class="section-title">ğŸ“¥ ìµœì¢… íŒŒì¼ ë‹¤ìš´ë¡œë“œ</div>
        <div class="section-subtitle">SCIMAT ë¶„ì„ìš©ìœ¼ë¡œ ì •ì œëœ ìµœì¢… WOS Plain Text íŒŒì¼</div>
    </div>
    """, unsafe_allow_html=True)
    
    if not df_included.empty:
        df_included_for_download = df_included.drop(columns=['Classification'])
        text_data = convert_to_scimat_wos_format(df_included_for_download)
        st.download_button(
            label=f"ğŸ“¥ SCIMATìš© TXT ë‹¤ìš´ë¡œë“œ ({len(df_included):,}í¸)",
            data=text_data,
            file_name=f"SCIMAT_Included_{len(df_included)}_papers.txt",
            mime="text/plain",
            use_container_width=True,
            key="download_final_file"
        )

    st.markdown("<br><br>", unsafe_allow_html=True)
    
    # --- ì›ë³¸ UI ìš”ì†Œë“¤ (FAQ ë° ê°€ì´ë“œ) ---
    with st.expander("â“ ìì£¼ ë¬»ëŠ” ì§ˆë¬¸ (FAQ)", expanded=False):
        st.markdown("""
        **Q: ì—¬ëŸ¬ WOS íŒŒì¼ì„ ì–´ë–»ê²Œ í•œ ë²ˆì— ì²˜ë¦¬í•˜ë‚˜ìš”?**
        A: WOSì—ì„œ ì—¬ëŸ¬ ë²ˆ Plain Text ë‹¤ìš´ë¡œë“œí•œ í›„, ëª¨ë“  .txt íŒŒì¼ì„ í•œ ë²ˆì— ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ ë³‘í•©ë©ë‹ˆë‹¤.
        
        **Q: ì¤‘ë³µëœ ë…¼ë¬¸ì´ ìˆì„ê¹Œë´ ê±±ì •ë©ë‹ˆë‹¤.**
        A: UT(Unique Article Identifier) ê¸°ì¤€ìœ¼ë¡œ ìë™ ì¤‘ë³µ ì œê±°ë©ë‹ˆë‹¤.
        
        **Q: WOSì—ì„œ ì–´ë–¤ ì„¤ì •ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•´ì•¼ í•˜ë‚˜ìš”?**
        A: Export â†’ Record Content: "Full Record and Cited References", File Format: "Plain Text"ë¡œ ì„¤ì •í•˜ì„¸ìš”.
        
        **Q: ì–´ë–¤ ê¸°ì¤€ìœ¼ë¡œ ë…¼ë¬¸ì´ ë°°ì œë˜ë‚˜ìš”?**
        A: IC/EC ê¸°ì¤€ì— ë”°ë¼ ì£¼ì œ ê´€ë ¨ì„±, ì‚¬íšŒ-ê¸°ìˆ ì  ë§¥ë½, ìƒí˜¸ì‘ìš©ì„±, í•™ìˆ ì  í˜•íƒœ ë“±ì„ ì¢…í•©ì ìœ¼ë¡œ íŒë‹¨í•˜ì—¬ ì •ì œí•©ë‹ˆë‹¤.
        """)

    with st.expander("ğŸ“Š WOS â†’ SciMAT ë¶„ì„ ì‹¤í–‰ ê°€ì´ë“œ", expanded=False):
        st.markdown("""
        ### í•„ìš”í•œ ê²ƒ
        - SciMAT ì†Œí”„íŠ¸ì›¨ì–´ (ë¬´ë£Œ ë‹¤ìš´ë¡œë“œ)
        - ë‹¤ìš´ë¡œë“œëœ WOS Plain Text íŒŒì¼
        - Java 1.8 ì´ìƒ
        
        ### 1ë‹¨ê³„: SciMAT ì‹œì‘í•˜ê¸°
        
        **ìƒˆ í”„ë¡œì íŠ¸ ìƒì„±**
        ```
        1. SciMAT ì‹¤í–‰ (SciMAT.jar ë”ë¸”í´ë¦­)
        2. File â†’ New Project
        3. Path: ì €ì¥í•  í´ë” ì„ íƒ
        4. File name: í”„ë¡œì íŠ¸ ì´ë¦„ ì…ë ¥
        5. Accept
        ```
        
        **ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°**
        ```
        1. File â†’ Add Files
        2. "ISI WoS" ì„ íƒ
        3. ë‹¤ìš´ë¡œë“œí•œ txt íŒŒì¼ ì„ íƒ
        4. ë¡œë”© ì™„ë£Œê¹Œì§€ ëŒ€ê¸°
        ```
        
        ### 2ë‹¨ê³„: í‚¤ì›Œë“œ ì •ë¦¬í•˜ê¸°
        
        **ìœ ì‚¬ í‚¤ì›Œë“œ ìë™ í†µí•©**
        ```
        1. Group set â†’ Word â†’ Find similar words by distances
        2. Maximum distance: 1 (í•œ ê¸€ì ì°¨ì´)
        3. ê°™ì€ ì˜ë¯¸ ë‹¨ì–´ë“¤ í™•ì¸í•˜ê³  Moveë¡œ í†µí•©
        ```
        ì˜ë¯¸: ì² ìê°€ 1ê¸€ìë§Œ ë‹¤ë¥¸ ë‹¨ì–´ë“¤ì„ ì°¾ì•„ì„œ ì œì•ˆ (ì˜ˆ: "platform" â†” "platforms")
        
        **ìˆ˜ë™ìœ¼ë¡œ í‚¤ì›Œë“œ ì •ë¦¬**
        ```
        1. Group set â†’ Word â†’ Word Group manual set
        2. Words without group ëª©ë¡ í™•ì¸
        3. ê´€ë ¨ í‚¤ì›Œë“œë“¤ ì„ íƒ í›„ New groupìœ¼ë¡œ ë¬¶ê¸°
        4. ë¶ˆí•„ìš”í•œ í‚¤ì›Œë“œ ì œê±°
        ```
        ëª©ì : ë°ì´í„° í’ˆì§ˆ í–¥ìƒ, ì˜ë¯¸ ìˆëŠ” í´ëŸ¬ìŠ¤í„° í˜•ì„±
        
        ### 3ë‹¨ê³„: ì‹œê°„ êµ¬ê°„ ì„¤ì •
        
        **Period ë§Œë“¤ê¸°**
        ```
        1. Knowledge base â†’ Periods â†’ Periods manager
        2. Add ë²„íŠ¼ìœ¼ë¡œ ì‹œê°„ êµ¬ê°„ ìƒì„±:
           - Period 1: 1996-2006 (íƒœë™ê¸°)
           - Period 2: 2007-2016 (í˜•ì„±ê¸°)
           - Period 3: 2017-2021 (í™•ì‚°ê¸°)
           - Period 4: 2022-2024 (ì„±ìˆ™ê¸°)
        ```
        ì›ë¦¬: ì—°êµ¬ ë¶„ì•¼ì˜ ì§„í™” ë‹¨ê³„ë¥¼ ë°˜ì˜í•œ ì˜ë¯¸ ìˆëŠ” êµ¬ë¶„
        
        **ê° Periodì— ë…¼ë¬¸ í• ë‹¹**
        ```
        1. Period 1 í´ë¦­ â†’ Add
        2. í•´ë‹¹ ì—°ë„ ë…¼ë¬¸ë“¤ ì„ íƒ
        3. ì˜¤ë¥¸ìª½ í™”ì‚´í‘œë¡œ ì´ë™
        4. ë‹¤ë¥¸ Periodë“¤ë„ ë™ì¼í•˜ê²Œ ë°˜ë³µ
        ```
        
        ### 4ë‹¨ê³„: ë¶„ì„ ì‹¤í–‰
        
        **ë¶„ì„ ë§ˆë²•ì‚¬ ì‹œì‘**
        ```
        1. Analysis â†’ Make Analysis
        2. ëª¨ë“  Period ì„ íƒ â†’ Next
        ```
        
        **Step 1-8: ë¶„ì„ ì„¤ì •**
        - Unit of Analysis: "Author's words + Source's words"
        - Data Reduction: Minimum frequency 2
        - Network Type: "Co-occurrence"
        - Normalization: "Equivalence Index"
        - Clustering: "Simple Centers Algorithm" (Max network size: 50)
        - Document Mapper: "Core Mapper"
        - Performance Measures: G-index, Sum Citations
        - Evolution Map: "Jaccard Index"
        
        **ë¶„ì„ ì‹¤í–‰**
        ```
        - Finish í´ë¦­
        - ì™„ë£Œê¹Œì§€ ëŒ€ê¸° (10-30ë¶„)
        ```
        
        ### 5ë‹¨ê³„: ê²°ê³¼ í•´ì„
        
        **ì „ëµì  ë‹¤ì´ì–´ê·¸ë¨ 4ì‚¬ë¶„ë©´**
        - ìš°ìƒë‹¨: Motor Themes (í•µì‹¬ ì£¼ì œ)
        - ì¢Œìƒë‹¨: Specialized Themes (ì „ë¬¸í™”ëœ ì£¼ì œ)
        - ì¢Œí•˜ë‹¨: Emerging/Declining Themes (ì‹ í¥/ì‡ í‡´ ì£¼ì œ)
        - ìš°í•˜ë‹¨: Basic Themes (ê¸°ì´ˆ ì£¼ì œ)
        
        **ì§„í™” ë§µ ë¶„ì„**
        - ë…¸ë“œ í¬ê¸° = ë…¼ë¬¸ ìˆ˜
        - ì—°ê²°ì„  ë‘ê»˜ = Jaccard ìœ ì‚¬ë„
        - ì‹œê°„ì— ë”°ë¥¸ ì£¼ì œ ë³€í™” ì¶”ì 
        
        ### ë¬¸ì œ í•´ê²°
        - í‚¤ì›Œë“œ ì •ë¦¬ë¥¼ ê¼¼ê¼¼íˆ (ë¶„ì„í’ˆì§ˆì˜ í•µì‹¬)
        - Periodë³„ ìµœì†Œ 50í¸ ì´ìƒ ê¶Œì¥
        - Java ë©”ëª¨ë¦¬ ë¶€ì¡±ì‹œ ì¬ì‹œì‘
        - ì¸ì½”ë”© ë¬¸ì œì‹œ UTF-8ë¡œ ë³€ê²½
        """)

    st.markdown("<br><br>", unsafe_allow_html=True)

